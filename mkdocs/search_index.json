{
    "docs": [
        {
            "location": "/",
            "text": "Machine Learning engineer Training Program(MLTP)\n\n\nMLTP\u306f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4e00\u304b\u3089\u66f8\u304f\u3053\u3068\u306b\u3088\u3063\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u52c9\u5f37\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059\u3002\n\u5143\u3005\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u5411\u3051\u306e\u793e\u5185\u6559\u80b2\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u3057\u3066\u59cb\u307e\u308a\u307e\u3057\u305f\u3002\n\u3057\u304b\u3057\u3001\u3088\u308a\u591a\u304f\u306e\u65b9\u306e\u5f79\u306b\u7acb\u3061\u305f\u3044\u3068\u3044\u3046\u601d\u3044\u304b\u3089\u3001\u5916\u90e8\u306b\u516c\u958b\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\n\n\n\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u5185\u5bb9\n\n\nTraditional Machine Learning\n\n\npython\u3068numpy\u3092\u4f7f\u3063\u3066mini scikit-learn library\u3092\u4f5c\u308a\u307e\u3059\u3002\u8272\u3005\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u52c9\u5f37\u3057\u3066\u304f\u4e2d\u3067\u540c\u6642\u306b\u6a5f\u68b0\u5b66\u7fd2\u306e\u57fa\u672c\u7684\u306a\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u8eab\u306b\u4ed8\u3051\u307e\u3059\u3002\n\n\nUnit1\n\n\nIntroduction\n\n\nk-Nearest Neighbors\n\n\nUnit2\n\n\nSupervised Learning\n\n\nUnit3\n\n\nNaive Bayes\n\n\nUnit4\n\n\nK-Means Clustering\n\n\nUnit5\n\n\nLinear Regression\n\n\nUnit6\n\n\nLogistic Regression\n\n\nDeep Learning(WIP, \u5b8c\u6210\u4e88\u5b9a\uff1a2017\u5e745\u6708)\n\n\nPyTorch\u3092\u4f7f\u3063\u3066Deep Learning\u3092\u52c9\u5f37\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n\nUnit7\n\nLogistic Regression2\n\n\nUnit8\n\nNeural Network\n\n\nUnit9\n\nRecurrent Neural Network\uff08\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\uff09\n\n\nUnit10\n\nConvolutional Neural Network\uff08\u753b\u50cf\u8a8d\u8b58\uff09\n\n\n\u8b1b\u5e2b\u7d39\u4ecb\n\n\n\n\n\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u3000\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8\n\n\n\u9ad8\u6a4b\u5efa\u4e09\n  kenzo@itandi.co.jp\n\n\n1990\u5e74\u751f\u307e\u308c\u3002\u30a2\u30e1\u30ea\u30ab\u306eUniversity of Northern Iowa \u2013 Computer Science major\u5352\u696d\u3002\n\u5728\u5b66\u4e2d\u306b\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306b\u76ee\u899a\u3081\u3001Web\u958b\u767a\u3068\u6a5f\u68b0\u5b66\u7fd2\u3092\u72ec\u5b66\u3067\u7fd2\u5f97\u3002\n\u5352\u696d\u5f8c\u306b\u82f1\u8a9e\u8b1b\u5e2b\u3092\u7d4c\u30662016\u5e745\u6708\u306b\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u306b\u5165\u793e\u3002\n\u540c\u793e\u3067\u9867\u5ba2\u5206\u6790\u3001\u30c1\u30e3\u30c3\u30c8\u306e\u81ea\u52d5\u8fd4\u4fe1\u3001\u753b\u50cf\u8a8d\u8b58\u306a\u3069\u6a5f\u68b0\u5b66\u7fd2\u3092\u4f7f\u3063\u305f\u696d\u52d9\u5168\u822c\u306b\u643a\u308f\u308b\u3002\n\u307e\u305f\u3001\u3069\u3093\u306a\u4e0d\u52d5\u7523\u30b5\u30a4\u30c8\u306b\u3082\u5bfe\u5fdc\u3059\u308b\u6c4e\u7528\u30af\u30ed\u30fc\u30e9\u30fc\u3092\u958b\u767a\u3057\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u306e\u30b3\u30b9\u30c8\u306e\u5927\u5e45\u306a\u524a\u6e1b\u306b\u6210\u529f\u3002\n\u82f1\u8a9e\u8b1b\u5e2b\u6642\u4ee3\u306b\u57f9\u3063\u305f\u30b9\u30ad\u30eb\u3092\u6d3b\u304b\u3057\u6a5f\u68b0\u5b66\u7fd2\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u793e\u5185\u80b2\u6210\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u958b\u59cb\u3059\u308b\u306a\u3069\u3001\n\u5e38\u306b\u65b0\u3057\u3044\u3053\u3068\u306b\u6311\u6226\u3057\u3066\u3044\u308b\u3002",
            "title": "Home"
        },
        {
            "location": "/#machine-learning-engineer-training-programmltp",
            "text": "MLTP\u306f\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u4e00\u304b\u3089\u66f8\u304f\u3053\u3068\u306b\u3088\u3063\u3066\u6a5f\u68b0\u5b66\u7fd2\u3092\u52c9\u5f37\u3059\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u3059\u3002\n\u5143\u3005\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u306e\u30a8\u30f3\u30b8\u30cb\u30a2\u5411\u3051\u306e\u793e\u5185\u6559\u80b2\u30d7\u30ed\u30b0\u30e9\u30e0\u3068\u3057\u3066\u59cb\u307e\u308a\u307e\u3057\u305f\u3002\n\u3057\u304b\u3057\u3001\u3088\u308a\u591a\u304f\u306e\u65b9\u306e\u5f79\u306b\u7acb\u3061\u305f\u3044\u3068\u3044\u3046\u601d\u3044\u304b\u3089\u3001\u5916\u90e8\u306b\u516c\u958b\u3059\u308b\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002",
            "title": "Machine Learning engineer Training Program(MLTP)"
        },
        {
            "location": "/#_1",
            "text": "",
            "title": "\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u5185\u5bb9"
        },
        {
            "location": "/#traditional-machine-learning",
            "text": "python\u3068numpy\u3092\u4f7f\u3063\u3066mini scikit-learn library\u3092\u4f5c\u308a\u307e\u3059\u3002\u8272\u3005\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u52c9\u5f37\u3057\u3066\u304f\u4e2d\u3067\u540c\u6642\u306b\u6a5f\u68b0\u5b66\u7fd2\u306e\u57fa\u672c\u7684\u306a\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u8eab\u306b\u4ed8\u3051\u307e\u3059\u3002  Unit1  Introduction  k-Nearest Neighbors  Unit2  Supervised Learning  Unit3  Naive Bayes  Unit4  K-Means Clustering  Unit5  Linear Regression  Unit6  Logistic Regression",
            "title": "Traditional Machine Learning"
        },
        {
            "location": "/#deep-learningwip-20175",
            "text": "PyTorch\u3092\u4f7f\u3063\u3066Deep Learning\u3092\u52c9\u5f37\u3057\u3066\u3044\u304d\u307e\u3059\u3002  Unit7 \nLogistic Regression2  Unit8 \nNeural Network  Unit9 \nRecurrent Neural Network\uff08\u81ea\u7136\u8a00\u8a9e\u51e6\u7406\uff09  Unit10 \nConvolutional Neural Network\uff08\u753b\u50cf\u8a8d\u8b58\uff09",
            "title": "Deep Learning(WIP, \u5b8c\u6210\u4e88\u5b9a\uff1a2017\u5e745\u6708)"
        },
        {
            "location": "/#_2",
            "text": "\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u3000\u30c7\u30fc\u30bf\u30b5\u30a4\u30a8\u30f3\u30c6\u30a3\u30b9\u30c8  \u9ad8\u6a4b\u5efa\u4e09   kenzo@itandi.co.jp  1990\u5e74\u751f\u307e\u308c\u3002\u30a2\u30e1\u30ea\u30ab\u306eUniversity of Northern Iowa \u2013 Computer Science major\u5352\u696d\u3002\n\u5728\u5b66\u4e2d\u306b\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\u306b\u76ee\u899a\u3081\u3001Web\u958b\u767a\u3068\u6a5f\u68b0\u5b66\u7fd2\u3092\u72ec\u5b66\u3067\u7fd2\u5f97\u3002\n\u5352\u696d\u5f8c\u306b\u82f1\u8a9e\u8b1b\u5e2b\u3092\u7d4c\u30662016\u5e745\u6708\u306b\u30a4\u30bf\u30f3\u30b8\u682a\u5f0f\u4f1a\u793e\u306b\u5165\u793e\u3002\n\u540c\u793e\u3067\u9867\u5ba2\u5206\u6790\u3001\u30c1\u30e3\u30c3\u30c8\u306e\u81ea\u52d5\u8fd4\u4fe1\u3001\u753b\u50cf\u8a8d\u8b58\u306a\u3069\u6a5f\u68b0\u5b66\u7fd2\u3092\u4f7f\u3063\u305f\u696d\u52d9\u5168\u822c\u306b\u643a\u308f\u308b\u3002\n\u307e\u305f\u3001\u3069\u3093\u306a\u4e0d\u52d5\u7523\u30b5\u30a4\u30c8\u306b\u3082\u5bfe\u5fdc\u3059\u308b\u6c4e\u7528\u30af\u30ed\u30fc\u30e9\u30fc\u3092\u958b\u767a\u3057\u30af\u30ed\u30fc\u30ea\u30f3\u30b0\u306e\u30b3\u30b9\u30c8\u306e\u5927\u5e45\u306a\u524a\u6e1b\u306b\u6210\u529f\u3002\n\u82f1\u8a9e\u8b1b\u5e2b\u6642\u4ee3\u306b\u57f9\u3063\u305f\u30b9\u30ad\u30eb\u3092\u6d3b\u304b\u3057\u6a5f\u68b0\u5b66\u7fd2\u30a8\u30f3\u30b8\u30cb\u30a2\u306e\u793e\u5185\u80b2\u6210\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u958b\u59cb\u3059\u308b\u306a\u3069\u3001\n\u5e38\u306b\u65b0\u3057\u3044\u3053\u3068\u306b\u6311\u6226\u3057\u3066\u3044\u308b\u3002",
            "title": "\u8b1b\u5e2b\u7d39\u4ecb"
        },
        {
            "location": "/section1/unit1/introduction/",
            "text": "Machine Learning\u306f\u5927\u304d\u304f\uff13\u7a2e\u985e\u306b\u5206\u304b\u308c\u307e\u3059\u3002\n\n\nSupervised Learning\n\n\nSupervised Learning\u306fInput\u304b\u3089Output\u3092\u4e88\u6e2c\u3059\u308b\u3082\u306e\u3067\u3059\u3002\u73fe\u5728\u30d3\u30b8\u30cd\u30b9\u3067\u4f7f\u308f\u308c\u3066\u3044\u308bML\u306e95%\u4ee5\u4e0a\u306fSupervised Learning\u3067\u3059\u3002\n\n\n\n\n\n\n\n\nTask\n\n\nInput\n\n\nOutput\n\n\n\n\n\n\n\n\n\n\nMachine Translation\n\n\nEnglish\n\n\nJapanese\n\n\n\n\n\n\nSpeech Recognition\n\n\nAudio\n\n\nText\n\n\n\n\n\n\nImage Recognition\n\n\nImage\n\n\nCategory\n\n\n\n\n\n\nQuestion Answering\n\n\nQuestion\n\n\nAnswer\n\n\n\n\n\n\nStock Market Prediction\n\n\nPast\n\n\nFuture\n\n\n\n\n\n\nRecommender System\n\n\nPast Behavior\n\n\nPreference\n\n\n\n\n\n\n\n\nRecommender System\u306f\u7279\u6b8a\u3067Unsupervised Learning\u306e\u5074\u9762\u3082\u3042\u308a\u307e\u3059\u3002\n\n\nSupervised Learning\u306b\u5fc5\u8981\u306a\u3082\u306e\u306f\u3001Input\u3068Output\u306e\u30da\u30a2\u3067\u3059\u3002\u4f8b\u3048\u3070Image Recognition\u306a\u3089\u3001\u753b\u50cf\u3068\u305d\u308c\u304c\u4f55\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5c5e\u3057\u3066\u3044\u308b\u304b\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306eInput\u3068Output\u306e\u30da\u30a2\u3092Training Data(\u6559\u5e2b\u7528\u30c7\u30fc\u30bf)\u3068\u547c\u3073\u307e\u3059\u3002\n\n\nInput\u3068Output\u306b\u306f\u8272\u3093\u306a\u30bf\u30a4\u30d7\u304c\u3042\u308a\u307e\u3059\u3002\u305d\u306e\u30bf\u30a4\u30d7\u306b\u3088\u3063\u3066\u3069\u306eML\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u304b\u3042\u308b\u7a0b\u5ea6\u7d5e\u3089\u308c\u307e\u3059\u3002\n\n\nUnsupervised Learning\n\n\nSupervised Learning\u306f\u7279\u5b9a\u306eOutput\u3092\u4e88\u6e2c\u3059\u308b\u3068\u3044\u3046\u30cf\u30c3\u30ad\u30ea\u3057\u305f\u30b4\u30fc\u30eb\u304c\u3042\u308b\u306e\u306b\u5bfe\u3057\u3001Unsupervised Learning\u306fDiscovery\u3084Preprocessing\u306e\u5074\u9762\u304c\u5f37\u3044\u3067\u3059\u3002\n\n\nClustering\n\u306f\u30c7\u30fc\u30bf\u3092\u30b0\u30eb\u30fc\u30d7\u306b\u5206\u3051\u307e\u3059\u3002Customer Segmentation\u306a\u3069\u304c\u4e3b\u306a\u4f8b\u3067\u3059\u3002\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u3092\u77e5\u308a\u305f\u3044\u6642\u306b\u4f7f\u3063\u305f\u308a\u3057\u307e\u3059\u3002\n\n\nDimensionality Reduction\n\u306f\u305d\u306e\u540d\u306e\u901a\u308aDimension\u3092\u6e1b\u3089\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u8a00\u3046Dimension\u306fFeature(\u7279\u5fb4)\u3092\u6307\u3057\u307e\u3059\u3002Dimensionality Reduction\u306b\u306f\nFeature Selection\n\u3068\nFeature Extraction\n\u306e\u5f79\u5272\u304c\u3042\u308a\u307e\u3059\u3002\n\n\nFeature Selection\n\u306f\u3069\u306e\u7279\u5fb4\u304c\u6700\u3082\u91cd\u8981\u304c\u3092\u767a\u898b\u3059\u308b\u3082\u306e\u3067\u3059\u3002\nFeature Extraction\n\u306f\u3001\u591a\u304f\u306e\u7279\u5fb4\u3092\u5c11\u6570\u306e\u7279\u5fb4\u306b\u5909\u63db\u3057\u307e\u3059\u3002\u5f8c\u3005\u52c9\u5f37\u3059\u308bK-Nearest Neighbor\u306fHigh Dimensional Data\u306b\u5411\u304b\u306a\u3044\u306e\u3067\u3001\u524d\u51e6\u7406\u3068\u3057\u3066Feature Extraction\u3092\u4f7f\u3063\u305f\u308a\u3057\u307e\u3059\u3002\n\n\nGenerative Models\n\u306fTraining Data\u304b\u3089\u30d1\u30bf\u30fc\u30f3\u3092\u898b\u3064\u3051\u51fa\u3057\u3001\u4f3c\u305f\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3092\u4f5c\u308a\u51fa\u3059\u3082\u306e\u306e\u3053\u3068\u3092\u8a00\u3044\u307e\u3059\u3002\nAuto Encoder\n\u3084\nDeep Generative Models\n\u304c\u305d\u308c\u306b\u5f53\u305f\u308a\u307e\u3059\u3002Deep Learning\u306e\u6700\u5148\u7aef\u306fGenerative Models\u306b\u3042\u308b\u3068\u8a00\u3063\u3066\u3082\u904e\u8a00\u3067\u306f\u306a\u304f\u3001\u8fd1\u5e74\u3053\u306e\u30a8\u30ea\u30a2\u3067\u306e\u30ea\u30b5\u30fc\u30c1\u304c\u6025\u6fc0\u306b\u9032\u3093\u3067\u3044\u307e\u3059\u3002\u8272\u3093\u306a\u30d3\u30b8\u30cd\u30b9\u30c1\u30e3\u30f3\u30b9\u304c\u3042\u308b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u73fe\u6642\u70b9\u3067\u306f\u30a2\u30ab\u30c7\u30df\u30c3\u30af\u306e\u5834\u3067\u6b62\u307e\u3063\u3066\u3044\u307e\u3059\u3002\n\n\nReinforcement Learning\n\n\nDeepmind\u306eAtari Game\u3084Alpha Go\u306e\u304a\u304b\u3052\u3067Reinforcement Learning\u306f\u8aac\u660e\u4e0d\u8981\u306a\u307b\u3069\u6709\u540d\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002Reinforcement Learning\u306fSupervised Learning\u3068\u540c\u3058\u3088\u3046\u306b\u30b4\u30fc\u30eb\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u304c\u3001Supervised Learning\u304cInput\u306b\u5bfe\u3057Output(\u7b54\u3048)\u3092\u4f7f\u3046\u306e\u306b\u5bfe\u3057\u3001Reinforcement Learning\u306fAction\u306b\u5bfe\u3057Reward(\u5831\u916c)\u3068State\u3092\u5f97\u307e\u3059\u3002\n\n\nReinforcement Learning\u3068Supervised Learning\u306e\u4e00\u756a\u306e\u9055\u3044\u306f\u3001Reinforcement Learning\u306f\u3042\u3089\u304b\u3058\u3081\u30c7\u30fc\u30bf\u3092\u6e9c\u3081\u3066\u304a\u304f\u3053\u3068\u304c\u51fa\u6765\u307e\u305b\u3093\u3002\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u306e\u4e2d\u3067\u30c7\u30fc\u30bf\u304c\u751f\u307f\u51fa\u3055\u308c\u307e\u3059\u3002\u3088\u3063\u3066Reinforcement Learning\u306f\u4e3b\u306b\u30b2\u30fc\u30e0\u306b\u4f7f\u308f\u308c\u307e\u3059\u3002\u4f55\u6545\u306a\u3089Virtual Environment\u3067\u306a\u3044\u3068\u5b66\u7fd2\u30b9\u30d4\u30fc\u30c9\u304c\u9045\u3059\u304e\u308b\u304b\u3089\u3067\u3059\u3002\u3088\u3063\u3066\u307e\u3060\u307e\u3060\u30d3\u30b8\u30cd\u30b9\u30b7\u30fc\u30f3\u306b\u306f\u6d78\u900f\u3057\u3066\u3044\u307e\u305b\u3093\u3002\n\n\nOpen AI\u304cVirtual Environment\u3092\u8ab0\u3067\u3082\u7c21\u5358\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u3057\u3066\u304f\u308c\u305f\u304a\u304b\u3052\u3067\u3001Reinforcement Learning\u306f\uff11\u5e74\u524d\u3068\u6bd4\u3079\u3066\u9065\u304b\u306b\u52c9\u5f37\u3057\u6613\u304f\u306a\u308a\u307e\u3057\u305f\u3002\nhttps://openai.com/blog/universe/\nhttps://gym.openai.com/\n\n\nThe Scope of This Program\n\n\n\u3053\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u306fSupervised Learning\u3092\u4e2d\u5fc3\u306b\u52c9\u5f37\u3057\u3066\u3044\u304d\u307e\u3059\u3002Unsupervised Learning\u306b\u3082\u5c11\u3057\u89e6\u308c\u308b\u4e88\u5b9a\u3067\u3059\u3002",
            "title": "Introduction"
        },
        {
            "location": "/section1/unit1/introduction/#supervised-learning",
            "text": "Supervised Learning\u306fInput\u304b\u3089Output\u3092\u4e88\u6e2c\u3059\u308b\u3082\u306e\u3067\u3059\u3002\u73fe\u5728\u30d3\u30b8\u30cd\u30b9\u3067\u4f7f\u308f\u308c\u3066\u3044\u308bML\u306e95%\u4ee5\u4e0a\u306fSupervised Learning\u3067\u3059\u3002     Task  Input  Output      Machine Translation  English  Japanese    Speech Recognition  Audio  Text    Image Recognition  Image  Category    Question Answering  Question  Answer    Stock Market Prediction  Past  Future    Recommender System  Past Behavior  Preference     Recommender System\u306f\u7279\u6b8a\u3067Unsupervised Learning\u306e\u5074\u9762\u3082\u3042\u308a\u307e\u3059\u3002  Supervised Learning\u306b\u5fc5\u8981\u306a\u3082\u306e\u306f\u3001Input\u3068Output\u306e\u30da\u30a2\u3067\u3059\u3002\u4f8b\u3048\u3070Image Recognition\u306a\u3089\u3001\u753b\u50cf\u3068\u305d\u308c\u304c\u4f55\u306e\u30ab\u30c6\u30b4\u30ea\u306b\u5c5e\u3057\u3066\u3044\u308b\u304b\u304c\u5fc5\u8981\u3067\u3059\u3002\u3053\u306eInput\u3068Output\u306e\u30da\u30a2\u3092Training Data(\u6559\u5e2b\u7528\u30c7\u30fc\u30bf)\u3068\u547c\u3073\u307e\u3059\u3002  Input\u3068Output\u306b\u306f\u8272\u3093\u306a\u30bf\u30a4\u30d7\u304c\u3042\u308a\u307e\u3059\u3002\u305d\u306e\u30bf\u30a4\u30d7\u306b\u3088\u3063\u3066\u3069\u306eML\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u304b\u3042\u308b\u7a0b\u5ea6\u7d5e\u3089\u308c\u307e\u3059\u3002",
            "title": "Supervised Learning"
        },
        {
            "location": "/section1/unit1/introduction/#unsupervised-learning",
            "text": "Supervised Learning\u306f\u7279\u5b9a\u306eOutput\u3092\u4e88\u6e2c\u3059\u308b\u3068\u3044\u3046\u30cf\u30c3\u30ad\u30ea\u3057\u305f\u30b4\u30fc\u30eb\u304c\u3042\u308b\u306e\u306b\u5bfe\u3057\u3001Unsupervised Learning\u306fDiscovery\u3084Preprocessing\u306e\u5074\u9762\u304c\u5f37\u3044\u3067\u3059\u3002  Clustering \u306f\u30c7\u30fc\u30bf\u3092\u30b0\u30eb\u30fc\u30d7\u306b\u5206\u3051\u307e\u3059\u3002Customer Segmentation\u306a\u3069\u304c\u4e3b\u306a\u4f8b\u3067\u3059\u3002\u30c7\u30fc\u30bf\u306e\u7279\u5fb4\u3092\u77e5\u308a\u305f\u3044\u6642\u306b\u4f7f\u3063\u305f\u308a\u3057\u307e\u3059\u3002  Dimensionality Reduction \u306f\u305d\u306e\u540d\u306e\u901a\u308aDimension\u3092\u6e1b\u3089\u3057\u307e\u3059\u3002\u3053\u3053\u3067\u8a00\u3046Dimension\u306fFeature(\u7279\u5fb4)\u3092\u6307\u3057\u307e\u3059\u3002Dimensionality Reduction\u306b\u306f Feature Selection \u3068 Feature Extraction \u306e\u5f79\u5272\u304c\u3042\u308a\u307e\u3059\u3002  Feature Selection \u306f\u3069\u306e\u7279\u5fb4\u304c\u6700\u3082\u91cd\u8981\u304c\u3092\u767a\u898b\u3059\u308b\u3082\u306e\u3067\u3059\u3002 Feature Extraction \u306f\u3001\u591a\u304f\u306e\u7279\u5fb4\u3092\u5c11\u6570\u306e\u7279\u5fb4\u306b\u5909\u63db\u3057\u307e\u3059\u3002\u5f8c\u3005\u52c9\u5f37\u3059\u308bK-Nearest Neighbor\u306fHigh Dimensional Data\u306b\u5411\u304b\u306a\u3044\u306e\u3067\u3001\u524d\u51e6\u7406\u3068\u3057\u3066Feature Extraction\u3092\u4f7f\u3063\u305f\u308a\u3057\u307e\u3059\u3002  Generative Models \u306fTraining Data\u304b\u3089\u30d1\u30bf\u30fc\u30f3\u3092\u898b\u3064\u3051\u51fa\u3057\u3001\u4f3c\u305f\u3088\u3046\u306a\u30c7\u30fc\u30bf\u3092\u4f5c\u308a\u51fa\u3059\u3082\u306e\u306e\u3053\u3068\u3092\u8a00\u3044\u307e\u3059\u3002 Auto Encoder \u3084 Deep Generative Models \u304c\u305d\u308c\u306b\u5f53\u305f\u308a\u307e\u3059\u3002Deep Learning\u306e\u6700\u5148\u7aef\u306fGenerative Models\u306b\u3042\u308b\u3068\u8a00\u3063\u3066\u3082\u904e\u8a00\u3067\u306f\u306a\u304f\u3001\u8fd1\u5e74\u3053\u306e\u30a8\u30ea\u30a2\u3067\u306e\u30ea\u30b5\u30fc\u30c1\u304c\u6025\u6fc0\u306b\u9032\u3093\u3067\u3044\u307e\u3059\u3002\u8272\u3093\u306a\u30d3\u30b8\u30cd\u30b9\u30c1\u30e3\u30f3\u30b9\u304c\u3042\u308b\u3068\u601d\u3044\u307e\u3059\u304c\u3001\u73fe\u6642\u70b9\u3067\u306f\u30a2\u30ab\u30c7\u30df\u30c3\u30af\u306e\u5834\u3067\u6b62\u307e\u3063\u3066\u3044\u307e\u3059\u3002",
            "title": "Unsupervised Learning"
        },
        {
            "location": "/section1/unit1/introduction/#reinforcement-learning",
            "text": "Deepmind\u306eAtari Game\u3084Alpha Go\u306e\u304a\u304b\u3052\u3067Reinforcement Learning\u306f\u8aac\u660e\u4e0d\u8981\u306a\u307b\u3069\u6709\u540d\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002Reinforcement Learning\u306fSupervised Learning\u3068\u540c\u3058\u3088\u3046\u306b\u30b4\u30fc\u30eb\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u304c\u3001Supervised Learning\u304cInput\u306b\u5bfe\u3057Output(\u7b54\u3048)\u3092\u4f7f\u3046\u306e\u306b\u5bfe\u3057\u3001Reinforcement Learning\u306fAction\u306b\u5bfe\u3057Reward(\u5831\u916c)\u3068State\u3092\u5f97\u307e\u3059\u3002  Reinforcement Learning\u3068Supervised Learning\u306e\u4e00\u756a\u306e\u9055\u3044\u306f\u3001Reinforcement Learning\u306f\u3042\u3089\u304b\u3058\u3081\u30c7\u30fc\u30bf\u3092\u6e9c\u3081\u3066\u304a\u304f\u3053\u3068\u304c\u51fa\u6765\u307e\u305b\u3093\u3002\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u306e\u4e2d\u3067\u30c7\u30fc\u30bf\u304c\u751f\u307f\u51fa\u3055\u308c\u307e\u3059\u3002\u3088\u3063\u3066Reinforcement Learning\u306f\u4e3b\u306b\u30b2\u30fc\u30e0\u306b\u4f7f\u308f\u308c\u307e\u3059\u3002\u4f55\u6545\u306a\u3089Virtual Environment\u3067\u306a\u3044\u3068\u5b66\u7fd2\u30b9\u30d4\u30fc\u30c9\u304c\u9045\u3059\u304e\u308b\u304b\u3089\u3067\u3059\u3002\u3088\u3063\u3066\u307e\u3060\u307e\u3060\u30d3\u30b8\u30cd\u30b9\u30b7\u30fc\u30f3\u306b\u306f\u6d78\u900f\u3057\u3066\u3044\u307e\u305b\u3093\u3002  Open AI\u304cVirtual Environment\u3092\u8ab0\u3067\u3082\u7c21\u5358\u306b\u4f7f\u3048\u308b\u3088\u3046\u306b\u3057\u3066\u304f\u308c\u305f\u304a\u304b\u3052\u3067\u3001Reinforcement Learning\u306f\uff11\u5e74\u524d\u3068\u6bd4\u3079\u3066\u9065\u304b\u306b\u52c9\u5f37\u3057\u6613\u304f\u306a\u308a\u307e\u3057\u305f\u3002\nhttps://openai.com/blog/universe/\nhttps://gym.openai.com/",
            "title": "Reinforcement Learning"
        },
        {
            "location": "/section1/unit1/introduction/#the-scope-of-this-program",
            "text": "\u3053\u306e\u30d7\u30ed\u30b0\u30e9\u30e0\u3067\u306fSupervised Learning\u3092\u4e2d\u5fc3\u306b\u52c9\u5f37\u3057\u3066\u3044\u304d\u307e\u3059\u3002Unsupervised Learning\u306b\u3082\u5c11\u3057\u89e6\u308c\u308b\u4e88\u5b9a\u3067\u3059\u3002",
            "title": "The Scope of This Program"
        },
        {
            "location": "/section1/unit1/k-nn/",
            "text": "k-Nearest Neighbors(k-NN)\u306f\u4e00\u756a\u7c21\u5358\u306b\u7406\u89e3\u51fa\u6765\u308bSupervised Learning\u306e\u30e2\u30c7\u30eb\u3067\u3059\u3002\n\n\nk-NN\u306e\u8aac\u660e\n\n\n\u4ee5\u4e0b\u306e\u56f3\u306f\u3001\u4f4f\u6240\u3068\u305d\u306e\u4eba\u304c\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u306e\u95a2\u4fc2\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u306f\u4e00\u4eba\u66ae\u3089\u3057\u4ee5\u5916\u3068\u8003\u3048\u3066\u4e0b\u3055\u3044\u3002\u4f4f\u6240\u306f\u7def\u5ea6\u3068\u7d4c\u5ea6\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\u6771\u4eac\u306e\u7def\u5ea6\u3068\u7d4c\u5ea6\u306f\u3053\u306e\u30c7\u30fc\u30bf\u3068\u5168\u7136\u9055\u3044\u307e\u3059\u304c\u3001\u3053\u306e\u30b0\u30e9\u30d5\u304c\u6771\u4eac\u3060\u3068\u4eee\u5b9a\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n\u5357\u897f\u306b\u306f\u4e00\u4eba\u66ae\u3089\u3057\u304c\u591a\u304f\u3001\u5317\u6771\u306b\u306f\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\u3002\n\n\n\u3067\u306f\u3053\u306e\u30c7\u30fc\u30bf\u3092\u5143\u306b\u3001\u7def\u5ea6\u3068\u7d4c\u5ea6\u304b\u3089\u305d\u306e\u4eba\u304c\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u4e88\u6e2c\u3057\u305f\u3044\u3068\u3057\u307e\u3057\u3087\u3046\u3002k-NN\u304c\u3069\u3046\u3084\u3063\u3066\u4e88\u6e2c\u3059\u308b\u304b\u3068\u3044\u3046\u3068\u3001\u305d\u306e\u5024\u306e\u96a3\u4eba(Neighbor)\u3092\u898b\u3066\u4e88\u6e2c\u3057\u307e\u3059\u3002\u30a8\u30ea\u30a2\u306b\u3088\u3063\u3066\u4e00\u4eba\u66ae\u3089\u3057\u304c\u591a\u304f\u4f4f\u3093\u3067\u3044\u305f\u308a\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\u591a\u304b\u3063\u305f\u308a\u3059\u308b\u306e\u3067\u3001\u96a3\u4eba\u3092\u898b\u3066\u4e88\u6e2c\u3059\u308b\u306e\u306f\u60aa\u304f\u306a\u3044\u65b9\u6cd5\u3067\u3059\u3002\n\n\n\u3061\u306a\u307f\u306bk-NN\u306b\u306f\u5834\u6240\u306e\u30c7\u30fc\u30bf\u3060\u3051\u3067\u306a\u304f\u3069\u3093\u306a\u30c7\u30fc\u30bf\u3067\u3082\u4f7f\u3048\u307e\u3059\u3002\u5b9f\u969b\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u4e88\u6e2c\u3059\u308b\u306b\u306f\u9593\u53d6\u308a\u3084\u8cc3\u6599\u306e\u65b9\u304c\u5f79\u306b\u7acb\u3061\u307e\u3059\u3088\u306d\u3002\u305f\u3060k-NN\u306e\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306b\u4f4f\u6240\u304c\u4e00\u756a\u5206\u304b\u308a\u6613\u3044\u305f\u3081\u4eca\u56de\u306f\u4f4f\u6240\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\n\n\n\u66f4\u306b\u3001\u3053\u308c\u306fk-NN\u306b\u9650\u3063\u305f\u3053\u3068\u3067\u306f\u306a\u3044\u306e\u3067\u3059\u304c\u3001Feature\u304c\uff12\u3064\u3067\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u308f\u3051\u3067\u3082\u3042\u308a\u307e\u305b\u3093\u3002\uff11\u3064\u3067\u3082\u826f\u3044\u3057\uff11\uff10\uff10\u500b\u3067\u3082\u826f\u3044\u3067\u3059\u3002\n\n\nk-NN\u306f\u96a3\u4eba\u3092\u4f55\u4eba\u53c2\u8003\u306b\u3059\u308b\u304b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002k-NN\u306ek\u304c\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u3053\u3068\u3067\u3059\u3002\u306a\u306e\u3067k=1\u3067\u3042\u308c\u3070\u6700\u3082\u8fd1\u3044\u4eba\u3092\u53c2\u8003\u306b\u3001k=3\u3067\u3042\u308c\u3070\u6700\u3082\u8fd1\u3044\uff13\u4eba\u3092\u898b\u3066\u591a\u3044\u65b9\u3092\u63a1\u7528\u3057\u307e\u3059\u3002\n\n\nk-NN\u3092\u624b\u3067\u8a08\u7b97\u3057\u3066\u307f\u3088\u3046\n\n\n\u4e0a\u8a18\u306e\u4f8b\u3092\u4f7f\u3063\u3066k-NN\u3092\u624b\u3067\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u304c\u51fa\u6765\u308c\u3070\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u306e\u306f\u7c21\u5358\u3067\u3059\u3002\u4eca\u307e\u3067\u300c\u96a3\u4eba\u300d\u3084\u300c\u8fd1\u3044\u300d\u3068\u3044\u3046\u5358\u8a9e\u3092\u30ab\u30b8\u30e5\u30a2\u30eb\u306b\u4f7f\u3063\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u8fd1\u4f3c\u5024\u306f\nManhattan Distance\n\u304b\nEuclidean Distance\n\u3092\u4f7f\u3044\u307e\u3059\u3002Manhattan Distance\u306f\u305d\u308c\u305e\u308c\u306e\u8ef8\uff08\u3053\u306e\u5834\u5408x\u3068y\uff09\u306e\u5dee\u7570\u306e\u7d76\u5bfe\u5024\u3092\u8db3\u3057\u305f\u3082\u306e\u3067\u3001Euclidean Distance\u306f\uff12\u70b9\u3092\u76f4\u7dda\u3067\u7d50\u3093\u3060\u6642\u306e\u8ddd\u96e2\u3067\u3059\u3002Manhattan Distance\u306e\u65b9\u304c\u8a08\u7b97\u304c\u697d\u306a\u306e\u3067\u307e\u305a\u3053\u308c\u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n d(p, q) = \\displaystyle\\sum_{i=1}^{n} |p_i - q_i| \n\n\n\n\n\u3067\u306f\u4e2d\u5fc3\u306b\u4e00\u756a\u8fd1\u3044\u8d64\u306e\u70b9(-1, -1)\u3068\u53f3\u306eTest sample(1, 0)\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n |-1 - 1| + |-1 - 0| = 2 + 1 = 3 \n\n\n\n\n\u3053\u306e\u3088\u3046\u306b\u305d\u308c\u305e\u308c\u306eTest sample\u6bce\u306b\u5168Training sample\u3068\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u305d\u306e\u5f8c\u305d\u308c\u3092\u8ddd\u96e2\u304c\u8fd1\u3044\u9806\u306b\u4e26\u3079\u3001k\u306e\u5206\u3060\u3051\u53d6\u308a\u3001\u305d\u306e\u4e2d\u3067\u591a\u3044\u30af\u30e9\u30b9\u3092\u63a1\u7528\u3057\u307e\u3059\u3002\n\n\nTest sample(1, 0)\u306e\u30b1\u30fc\u30b9\u3067\u8a00\u3046\u3068\u3001k=3\u306e\u5834\u5408(1, 1), (2, 2), (-1, -1)\u304c\u6700\u3082\u8fd1\u3044\uff13\u3064\u3067\u3059\u3002\u305d\u306e\u4e2d\u3067\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\uff12\u3064\u306a\u306e\u3067\u3001\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u3068\u4e88\u6e2c\u3057\u307e\u3059\u3002\u30bf\u30a4\u3092\u907f\u3051\u308b\u70bak\u306b\u306f\u5947\u6570\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\nExercises\n\n\n\u30b3\u30fc\u30c9\u306f\u3053\u3053\u306b\u3042\u308a\u307e\u3059\u3002\n\nhttps://github.com/itandi/mltp\n\n\nScikit-learn Style\n\n\nExercise\u3067\u306fk-NN\u3092numpy\u3067\u66f8\u3044\u3066\u3082\u3089\u3044\u307e\u3059\u304c\u3001API\u306f\nscikit-learn\n\u3068\u540c\u3058\u306b\u3057\u3066\u3044\u307e\u3059\u3002scikit-learn\u306f\u3069\u306e\u30e2\u30c7\u30eb\u3067\u3082API\u304c\u540c\u3058\u306a\u306e\u3067\u975e\u5e38\u306b\u4f7f\u3044\u3084\u3059\u3044\u3067\u3059\u3002\u4ee5\u4e0b\u306e\u7c21\u5358\u306a\u4f8b\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\n## Input\u306f2d array(N, number of features)\nx_train = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n## Target\u306f1d array(N, )\ny_train = np.array([1,1,1,0,0,0])\n\n## \u30e2\u30c7\u30eb\u306einitialization.\nneighbor = KNeighborsClassifier()\n## fit\u3067\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nneighbor.fit(x_train, y_train)\n\n## predict\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u308b\u306e\u30672d array\u3092\u6e21\u3059\nx_test = np.array([[1, 0], [-2, -2]])\nprint(neighbor.predict(x_test))\n\n\n\n\nscikit-learn\u3067\u306fML\u306e\u30e2\u30c7\u30eb\u3092\nEstimator\n\u3068\u547c\u3093\u3067\u3044\u3066\u3001Estimator\u306f\u30af\u30e9\u30b9\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u307e\u305aEstimator\u3092initialize\u3057\u3001\nfit\n\u3067\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u3057\u307e\u3059\u3002\u4e88\u6e2c\u3057\u305f\u3044\u6642\u306f\npredict\n\u3092\u547c\u3073\u307e\u3059\u3002\n\n\nThe Starter Code\n\n\n\u4ee5\u4e0b\u304cStarter code\u3067\u3059\u3002k-NN\u306f\u4ed6\u306e\u30e2\u30c7\u30eb\u3068\u9055\u3044\nfit\n\u3067\u306f\u4f55\u3082\u305b\u305a\u5358\u306b\nx\n\u3068\ny\n\u3092\u4fdd\u5b58\u3059\u308b\u3060\u3051\u3067\u3059\u3002\n_predict_one\n\u30671 sample\u6bce\u306b\u51e6\u7406\u3092\u3057\u307e\u3059\u3002\u4eca\u306f\u6bce\u56de1\u3092return\u3057\u3066\u3044\u307e\u3059\u3002\n\n\nimport numpy as np\n\nclass MyKNeighborsClassifier(object):\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n\n    def fit(self, x, y):\n        self.x = x\n        self.y = y\n        return self\n\n    def _predict_one(self, test):\n        return 1\n\n    def predict(self, x):\n        return [self._predict_one(i) for i in x]\n\nx = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\ny = np.array([1,1,1,0,0,0])\nneighbor = MyKNeighborsClassifier()\nneighbor.fit(x, y)\nprint(neighbor.predict(np.array([[1, 0], [-2, -2]])))\n\n\n\n\nExercise\u306e\u7b54\u3048\u306f\u6b21\u306eExercise\u306b\u66f8\u3044\u3066\u3042\u308a\u307e\u3059\u3002\n\n\nExercise 1\n\n\n\u6700\u521d\u306b\u8ddd\u96e2\u3092\u6e2c\u308b\u30e1\u30bd\u30c3\u30c9\n_distance\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002Manhattan Distance\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\nExercise 2\n\n\ndistance\u3092\u8a08\u7b97\u3057\u305f\u3089\u5c0f\u3055\u3044\u9806\u306b\u30bd\u30fc\u30c8\u3057\u3001\nself.n_neighbors\n\u306e\u6570\u3060\u3051\u53d6\u308a\u307e\u3059\u3002\n\u305d\u306e\u5f8c\n_compute_weights\n\u3067weight\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002weight\u306f\u4e0a\u3067\u306f\u8aac\u660e\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u304c\u3001\u5404\u30c7\u30fc\u30bf\u306e\u91cd\u8981\u5ea6\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3059\u3002\u307e\u305a\u306f\nuniform weights\n\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u4e0a\u3067\u3084\u3063\u305f\u306e\u3068\u540c\u3058\u65b9\u6cd5\u3067\u3001\u5168\u30c7\u30fc\u30bf\u540c\u3058\u6bd4\u91cd\u3092\u6301\u3064\u3068\u3044\u3046\u610f\u5473\u3067\u3059\u3002\u3064\u307e\u308adistance\u306b\u95a2\u308f\u3089\u305a1\u3092return\u3059\u308c\u3070\u5168\u30c7\u30fc\u30bf\u540c\u3058\u6bd4\u91cd\u306b\u306a\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070 \ntop_k_distances\n\u304c\n[1, 2, 3, -4]\n\u3060\u3063\u305f\u3089\n[1,1,1,1]\n\u3092return\u3057\u307e\u3059\u3002\n\n\ndef _predict_one(self, test):\n    distances = np.array([self._distance(x, test) for x in self.x])\n    top_k = np.argsort(distances)[:self.n_neighbors]\n    top_k_ys = self.y[top_k]\n    top_k_distances = distances[top_k]\n    top_k_weights = self._compute_weights(top_k_distances)\n\n\n\n\nExercise 3\n\n\n\u3053\u306eExercise\u3067\u57fa\u672c\u7684\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3082\u3046\u5b8c\u6210\u3057\u307e\u3059\uff01\u5148\u307b\u3069\u8a08\u7b97\u3057\u305f\ntop_k_weights\n\u3092\u5143\u306b\u3001weight\u304c\u4e00\u756a\u5927\u304d\u3044\u30af\u30e9\u30b9\u3092return\u3057\u307e\u3057\u3087\u3046\u3002\n\n\nExercise 4\n\n\n\u4eca\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3060\u3068\u5358\u7d14\u306b\u30c8\u30c3\u30d7K\u306e\u5927\u591a\u6570\u3092\u53d6\u308a\u307e\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u5834\u5408\u306f\u3069\u3046\u3067\u3057\u3087\u3046\uff1f\n\n\nX = np.array([[1, 1], [4, 4], [5, 5]])\ny = np.array([1,0,0])\nneighbor = MyKNeighborsClassifier(n_neighbors=3).fit(X, y)\nprint(neighbor._predict_one(np.array([0, 0])))\n\n\n\n\n\n\n\u4e00\u756a\u8fd1\u3044\u306e\u306f\u8d64\u3067\u3059\u304c\u3001\u9752\u304c\uff12\u3064\u3042\u308b\u305f\u3081\u305d\u3063\u3061\u3092\u63a1\u7528\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\u6570\u3060\u3051\u3067\u306a\u304f\u8ddd\u96e2\u3082\u8003\u616e\u306b\u5165\u308c\u3089\u308c\u305f\u3089\u826f\u3044\u3067\u3059\u3088\u306d\u3002\n\n\n\u305d\u306e\u70ba\u306b\u306f\u8ddd\u96e2\u306einverse(1/d)\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\n__init__\n\u306b\nweights\n\u304c\u8ffd\u52a0\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\ndef __init__(self, n_neighbors=5, weights='uniform'):\n    self.n_neighbors = n_neighbors\n    self.weights = weights\n\n\n\n\n_compute_weights\n\u3092\u5b8c\u6210\u3055\u305b\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 5\n\n\n\u6b21\u306bEuclidean Distance\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n\n\n\n\n d(p, q) = \\sqrt{\\displaystyle\\sum_{i=1}^{n} (p_i - q_i)^2} \n\n\n\n\n__init__\n\u306b\u306f\np\n\u304c\u8ffd\u52a0\u3055\u308c\u3066\u3044\u307e\u3059\u3002scikit-learn\u3068\u540c\u3058\u304f\u30c7\u30d5\u30a9\u30eb\u30c8\u306fEuclidean Distance\u3067\u3059\u3002\n\n\ndef __init__(self, n_neighbors=5, weights='uniform', p=2):\n    self.n_neighbors = n_neighbors\n    self.weights = weights\n    self.p = p\n\n\n\n\n_distance\n\u3092\u5b8c\u6210\u3055\u305b\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 6\n\n\n\u6700\u5f8c\u306b\nscore\n\u30e1\u30bd\u30c3\u30c9\u3092\u66f8\u304d\u307e\u3059\u3002\nscore\n \u306fk-NN\u306b\u95a2\u308f\u3089\u305a\u3069\u306eEstimator\u306b\u3082\u3042\u308a\u3001classifier\u306e\u5834\u5408\u306fmean accuracy\uff08\u7cbe\u5ea6\uff09\u3092return\u3057\u307e\u3059\u3002\n\n\nIris Flower Dataset\n\n\nscikit-learn\u306b\u306f\u5e7e\u3064\u304b\u306e\u6709\u540d\u306aData set\u304c\u5165\u3063\u3066\u3044\u307e\u3059\u3002\nIris flower data set\n\u306f\uff13\u3064\u306e\u82b1\u306e\u7a2e\u985e\u3092\uff14\u3064\u306e\u7279\u5fb4\u304b\u3089\u6210\u308a\u7acb\u3063\u3066\u3044\u307e\u3059\u3002\nmodel_selection\n\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5165\u3063\u3066\u308b\ntrain_test_split\n\u3067training data\u3068test data\u30926:4\u306b\u5206\u3051\u307e\u3059\u3002\n\n\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom s8_final import MyKNeighborsClassifier\n\niris = datasets.load_iris()\n\nx_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.4)\nneighbor = MyKNeighborsClassifier(n_neighbors=5, weights='uniform', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train))\nprint(neighbor.score(x_test, y_test))\n\n\n\n\nIris flower\u306f\u304b\u306a\u308a\u30af\u30ea\u30fc\u30f3\u306a\u30c7\u30fc\u30bf\u306a\u306e\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3082\u9ad8\u3044\u7cbe\u5ea6\u304c\u7c21\u5358\u306b\u51fa\u307e\u3059\u3002\nn_neighbors\n,\nweights\n,\np\n\u3092\u3044\u3058\u3063\u3066\u5909\u5316\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002",
            "title": "k-Nearest Neighbors"
        },
        {
            "location": "/section1/unit1/k-nn/#k-nn",
            "text": "\u4ee5\u4e0b\u306e\u56f3\u306f\u3001\u4f4f\u6240\u3068\u305d\u306e\u4eba\u304c\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u306e\u95a2\u4fc2\u3092\u8868\u3057\u3066\u3044\u307e\u3059\u3002\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u306f\u4e00\u4eba\u66ae\u3089\u3057\u4ee5\u5916\u3068\u8003\u3048\u3066\u4e0b\u3055\u3044\u3002\u4f4f\u6240\u306f\u7def\u5ea6\u3068\u7d4c\u5ea6\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002\u6771\u4eac\u306e\u7def\u5ea6\u3068\u7d4c\u5ea6\u306f\u3053\u306e\u30c7\u30fc\u30bf\u3068\u5168\u7136\u9055\u3044\u307e\u3059\u304c\u3001\u3053\u306e\u30b0\u30e9\u30d5\u304c\u6771\u4eac\u3060\u3068\u4eee\u5b9a\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002   \u5357\u897f\u306b\u306f\u4e00\u4eba\u66ae\u3089\u3057\u304c\u591a\u304f\u3001\u5317\u6771\u306b\u306f\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\u591a\u3044\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\u3002  \u3067\u306f\u3053\u306e\u30c7\u30fc\u30bf\u3092\u5143\u306b\u3001\u7def\u5ea6\u3068\u7d4c\u5ea6\u304b\u3089\u305d\u306e\u4eba\u304c\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u4e88\u6e2c\u3057\u305f\u3044\u3068\u3057\u307e\u3057\u3087\u3046\u3002k-NN\u304c\u3069\u3046\u3084\u3063\u3066\u4e88\u6e2c\u3059\u308b\u304b\u3068\u3044\u3046\u3068\u3001\u305d\u306e\u5024\u306e\u96a3\u4eba(Neighbor)\u3092\u898b\u3066\u4e88\u6e2c\u3057\u307e\u3059\u3002\u30a8\u30ea\u30a2\u306b\u3088\u3063\u3066\u4e00\u4eba\u66ae\u3089\u3057\u304c\u591a\u304f\u4f4f\u3093\u3067\u3044\u305f\u308a\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\u591a\u304b\u3063\u305f\u308a\u3059\u308b\u306e\u3067\u3001\u96a3\u4eba\u3092\u898b\u3066\u4e88\u6e2c\u3059\u308b\u306e\u306f\u60aa\u304f\u306a\u3044\u65b9\u6cd5\u3067\u3059\u3002  \u3061\u306a\u307f\u306bk-NN\u306b\u306f\u5834\u6240\u306e\u30c7\u30fc\u30bf\u3060\u3051\u3067\u306a\u304f\u3069\u3093\u306a\u30c7\u30fc\u30bf\u3067\u3082\u4f7f\u3048\u307e\u3059\u3002\u5b9f\u969b\u4e00\u4eba\u66ae\u3089\u3057\u304b\u3069\u3046\u304b\u4e88\u6e2c\u3059\u308b\u306b\u306f\u9593\u53d6\u308a\u3084\u8cc3\u6599\u306e\u65b9\u304c\u5f79\u306b\u7acb\u3061\u307e\u3059\u3088\u306d\u3002\u305f\u3060k-NN\u306e\u30b3\u30f3\u30bb\u30d7\u30c8\u3092\u7406\u89e3\u3059\u308b\u305f\u3081\u306b\u4f4f\u6240\u304c\u4e00\u756a\u5206\u304b\u308a\u6613\u3044\u305f\u3081\u4eca\u56de\u306f\u4f4f\u6240\u3092\u4f7f\u3063\u3066\u3044\u307e\u3059\u3002  \u66f4\u306b\u3001\u3053\u308c\u306fk-NN\u306b\u9650\u3063\u305f\u3053\u3068\u3067\u306f\u306a\u3044\u306e\u3067\u3059\u304c\u3001Feature\u304c\uff12\u3064\u3067\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u308f\u3051\u3067\u3082\u3042\u308a\u307e\u305b\u3093\u3002\uff11\u3064\u3067\u3082\u826f\u3044\u3057\uff11\uff10\uff10\u500b\u3067\u3082\u826f\u3044\u3067\u3059\u3002  k-NN\u306f\u96a3\u4eba\u3092\u4f55\u4eba\u53c2\u8003\u306b\u3059\u308b\u304b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002k-NN\u306ek\u304c\u305d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u3053\u3068\u3067\u3059\u3002\u306a\u306e\u3067k=1\u3067\u3042\u308c\u3070\u6700\u3082\u8fd1\u3044\u4eba\u3092\u53c2\u8003\u306b\u3001k=3\u3067\u3042\u308c\u3070\u6700\u3082\u8fd1\u3044\uff13\u4eba\u3092\u898b\u3066\u591a\u3044\u65b9\u3092\u63a1\u7528\u3057\u307e\u3059\u3002",
            "title": "k-NN\u306e\u8aac\u660e"
        },
        {
            "location": "/section1/unit1/k-nn/#k-nn_1",
            "text": "\u4e0a\u8a18\u306e\u4f8b\u3092\u4f7f\u3063\u3066k-NN\u3092\u624b\u3067\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u304c\u51fa\u6765\u308c\u3070\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u306e\u306f\u7c21\u5358\u3067\u3059\u3002\u4eca\u307e\u3067\u300c\u96a3\u4eba\u300d\u3084\u300c\u8fd1\u3044\u300d\u3068\u3044\u3046\u5358\u8a9e\u3092\u30ab\u30b8\u30e5\u30a2\u30eb\u306b\u4f7f\u3063\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u8fd1\u4f3c\u5024\u306f Manhattan Distance \u304b Euclidean Distance \u3092\u4f7f\u3044\u307e\u3059\u3002Manhattan Distance\u306f\u305d\u308c\u305e\u308c\u306e\u8ef8\uff08\u3053\u306e\u5834\u5408x\u3068y\uff09\u306e\u5dee\u7570\u306e\u7d76\u5bfe\u5024\u3092\u8db3\u3057\u305f\u3082\u306e\u3067\u3001Euclidean Distance\u306f\uff12\u70b9\u3092\u76f4\u7dda\u3067\u7d50\u3093\u3060\u6642\u306e\u8ddd\u96e2\u3067\u3059\u3002Manhattan Distance\u306e\u65b9\u304c\u8a08\u7b97\u304c\u697d\u306a\u306e\u3067\u307e\u305a\u3053\u308c\u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002    d(p, q) = \\displaystyle\\sum_{i=1}^{n} |p_i - q_i|    \u3067\u306f\u4e2d\u5fc3\u306b\u4e00\u756a\u8fd1\u3044\u8d64\u306e\u70b9(-1, -1)\u3068\u53f3\u306eTest sample(1, 0)\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002    |-1 - 1| + |-1 - 0| = 2 + 1 = 3    \u3053\u306e\u3088\u3046\u306b\u305d\u308c\u305e\u308c\u306eTest sample\u6bce\u306b\u5168Training sample\u3068\u306e\u8ddd\u96e2\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u305d\u306e\u5f8c\u305d\u308c\u3092\u8ddd\u96e2\u304c\u8fd1\u3044\u9806\u306b\u4e26\u3079\u3001k\u306e\u5206\u3060\u3051\u53d6\u308a\u3001\u305d\u306e\u4e2d\u3067\u591a\u3044\u30af\u30e9\u30b9\u3092\u63a1\u7528\u3057\u307e\u3059\u3002  Test sample(1, 0)\u306e\u30b1\u30fc\u30b9\u3067\u8a00\u3046\u3068\u3001k=3\u306e\u5834\u5408(1, 1), (2, 2), (-1, -1)\u304c\u6700\u3082\u8fd1\u3044\uff13\u3064\u3067\u3059\u3002\u305d\u306e\u4e2d\u3067\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u304c\uff12\u3064\u306a\u306e\u3067\u3001\u30eb\u30fc\u30e0\u30b7\u30a7\u30a2\u3068\u4e88\u6e2c\u3057\u307e\u3059\u3002\u30bf\u30a4\u3092\u907f\u3051\u308b\u70bak\u306b\u306f\u5947\u6570\u3092\u4f7f\u3044\u307e\u3059\u3002",
            "title": "k-NN\u3092\u624b\u3067\u8a08\u7b97\u3057\u3066\u307f\u3088\u3046"
        },
        {
            "location": "/section1/unit1/k-nn/#exercises",
            "text": "\u30b3\u30fc\u30c9\u306f\u3053\u3053\u306b\u3042\u308a\u307e\u3059\u3002 https://github.com/itandi/mltp",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit1/k-nn/#scikit-learn-style",
            "text": "Exercise\u3067\u306fk-NN\u3092numpy\u3067\u66f8\u3044\u3066\u3082\u3089\u3044\u307e\u3059\u304c\u3001API\u306f scikit-learn \u3068\u540c\u3058\u306b\u3057\u3066\u3044\u307e\u3059\u3002scikit-learn\u306f\u3069\u306e\u30e2\u30c7\u30eb\u3067\u3082API\u304c\u540c\u3058\u306a\u306e\u3067\u975e\u5e38\u306b\u4f7f\u3044\u3084\u3059\u3044\u3067\u3059\u3002\u4ee5\u4e0b\u306e\u7c21\u5358\u306a\u4f8b\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002  import numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\n\n## Input\u306f2d array(N, number of features)\nx_train = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n## Target\u306f1d array(N, )\ny_train = np.array([1,1,1,0,0,0])\n\n## \u30e2\u30c7\u30eb\u306einitialization.\nneighbor = KNeighborsClassifier()\n## fit\u3067\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\nneighbor.fit(x_train, y_train)\n\n## predict\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u3092\u53d6\u308b\u306e\u30672d array\u3092\u6e21\u3059\nx_test = np.array([[1, 0], [-2, -2]])\nprint(neighbor.predict(x_test))  scikit-learn\u3067\u306fML\u306e\u30e2\u30c7\u30eb\u3092 Estimator \u3068\u547c\u3093\u3067\u3044\u3066\u3001Estimator\u306f\u30af\u30e9\u30b9\u306b\u306a\u3063\u3066\u3044\u307e\u3059\u3002\u307e\u305aEstimator\u3092initialize\u3057\u3001 fit \u3067\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u3057\u307e\u3059\u3002\u4e88\u6e2c\u3057\u305f\u3044\u6642\u306f predict \u3092\u547c\u3073\u307e\u3059\u3002",
            "title": "Scikit-learn Style"
        },
        {
            "location": "/section1/unit1/k-nn/#the-starter-code",
            "text": "\u4ee5\u4e0b\u304cStarter code\u3067\u3059\u3002k-NN\u306f\u4ed6\u306e\u30e2\u30c7\u30eb\u3068\u9055\u3044 fit \u3067\u306f\u4f55\u3082\u305b\u305a\u5358\u306b x \u3068 y \u3092\u4fdd\u5b58\u3059\u308b\u3060\u3051\u3067\u3059\u3002 _predict_one \u30671 sample\u6bce\u306b\u51e6\u7406\u3092\u3057\u307e\u3059\u3002\u4eca\u306f\u6bce\u56de1\u3092return\u3057\u3066\u3044\u307e\u3059\u3002  import numpy as np\n\nclass MyKNeighborsClassifier(object):\n    def __init__(self, n_neighbors=5):\n        self.n_neighbors = n_neighbors\n\n    def fit(self, x, y):\n        self.x = x\n        self.y = y\n        return self\n\n    def _predict_one(self, test):\n        return 1\n\n    def predict(self, x):\n        return [self._predict_one(i) for i in x]\n\nx = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\ny = np.array([1,1,1,0,0,0])\nneighbor = MyKNeighborsClassifier()\nneighbor.fit(x, y)\nprint(neighbor.predict(np.array([[1, 0], [-2, -2]])))  Exercise\u306e\u7b54\u3048\u306f\u6b21\u306eExercise\u306b\u66f8\u3044\u3066\u3042\u308a\u307e\u3059\u3002",
            "title": "The Starter Code"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-1",
            "text": "\u6700\u521d\u306b\u8ddd\u96e2\u3092\u6e2c\u308b\u30e1\u30bd\u30c3\u30c9 _distance \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002Manhattan Distance\u3092\u4f7f\u3044\u307e\u3059\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-2",
            "text": "distance\u3092\u8a08\u7b97\u3057\u305f\u3089\u5c0f\u3055\u3044\u9806\u306b\u30bd\u30fc\u30c8\u3057\u3001 self.n_neighbors \u306e\u6570\u3060\u3051\u53d6\u308a\u307e\u3059\u3002\n\u305d\u306e\u5f8c _compute_weights \u3067weight\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002weight\u306f\u4e0a\u3067\u306f\u8aac\u660e\u3057\u307e\u305b\u3093\u3067\u3057\u305f\u304c\u3001\u5404\u30c7\u30fc\u30bf\u306e\u91cd\u8981\u5ea6\u306e\u3088\u3046\u306a\u3082\u306e\u3067\u3059\u3002\u307e\u305a\u306f uniform weights \u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u308c\u306f\u4e0a\u3067\u3084\u3063\u305f\u306e\u3068\u540c\u3058\u65b9\u6cd5\u3067\u3001\u5168\u30c7\u30fc\u30bf\u540c\u3058\u6bd4\u91cd\u3092\u6301\u3064\u3068\u3044\u3046\u610f\u5473\u3067\u3059\u3002\u3064\u307e\u308adistance\u306b\u95a2\u308f\u3089\u305a1\u3092return\u3059\u308c\u3070\u5168\u30c7\u30fc\u30bf\u540c\u3058\u6bd4\u91cd\u306b\u306a\u308a\u307e\u3059\u3002\u4f8b\u3048\u3070  top_k_distances \u304c [1, 2, 3, -4] \u3060\u3063\u305f\u3089 [1,1,1,1] \u3092return\u3057\u307e\u3059\u3002  def _predict_one(self, test):\n    distances = np.array([self._distance(x, test) for x in self.x])\n    top_k = np.argsort(distances)[:self.n_neighbors]\n    top_k_ys = self.y[top_k]\n    top_k_distances = distances[top_k]\n    top_k_weights = self._compute_weights(top_k_distances)",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-3",
            "text": "\u3053\u306eExercise\u3067\u57fa\u672c\u7684\u306a\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3082\u3046\u5b8c\u6210\u3057\u307e\u3059\uff01\u5148\u307b\u3069\u8a08\u7b97\u3057\u305f top_k_weights \u3092\u5143\u306b\u3001weight\u304c\u4e00\u756a\u5927\u304d\u3044\u30af\u30e9\u30b9\u3092return\u3057\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 3"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-4",
            "text": "\u4eca\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3060\u3068\u5358\u7d14\u306b\u30c8\u30c3\u30d7K\u306e\u5927\u591a\u6570\u3092\u53d6\u308a\u307e\u3059\u304c\u3001\u4ee5\u4e0b\u306e\u5834\u5408\u306f\u3069\u3046\u3067\u3057\u3087\u3046\uff1f  X = np.array([[1, 1], [4, 4], [5, 5]])\ny = np.array([1,0,0])\nneighbor = MyKNeighborsClassifier(n_neighbors=3).fit(X, y)\nprint(neighbor._predict_one(np.array([0, 0])))   \u4e00\u756a\u8fd1\u3044\u306e\u306f\u8d64\u3067\u3059\u304c\u3001\u9752\u304c\uff12\u3064\u3042\u308b\u305f\u3081\u305d\u3063\u3061\u3092\u63a1\u7528\u3057\u3066\u3057\u307e\u3044\u307e\u3059\u3002\u6570\u3060\u3051\u3067\u306a\u304f\u8ddd\u96e2\u3082\u8003\u616e\u306b\u5165\u308c\u3089\u308c\u305f\u3089\u826f\u3044\u3067\u3059\u3088\u306d\u3002  \u305d\u306e\u70ba\u306b\u306f\u8ddd\u96e2\u306einverse(1/d)\u3092\u4f7f\u3044\u307e\u3059\u3002  __init__ \u306b weights \u304c\u8ffd\u52a0\u3055\u308c\u3066\u3044\u307e\u3059\u3002  def __init__(self, n_neighbors=5, weights='uniform'):\n    self.n_neighbors = n_neighbors\n    self.weights = weights  _compute_weights \u3092\u5b8c\u6210\u3055\u305b\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 4"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-5",
            "text": "\u6b21\u306bEuclidean Distance\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002    d(p, q) = \\sqrt{\\displaystyle\\sum_{i=1}^{n} (p_i - q_i)^2}    __init__ \u306b\u306f p \u304c\u8ffd\u52a0\u3055\u308c\u3066\u3044\u307e\u3059\u3002scikit-learn\u3068\u540c\u3058\u304f\u30c7\u30d5\u30a9\u30eb\u30c8\u306fEuclidean Distance\u3067\u3059\u3002  def __init__(self, n_neighbors=5, weights='uniform', p=2):\n    self.n_neighbors = n_neighbors\n    self.weights = weights\n    self.p = p  _distance \u3092\u5b8c\u6210\u3055\u305b\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 5"
        },
        {
            "location": "/section1/unit1/k-nn/#exercise-6",
            "text": "\u6700\u5f8c\u306b score \u30e1\u30bd\u30c3\u30c9\u3092\u66f8\u304d\u307e\u3059\u3002 score  \u306fk-NN\u306b\u95a2\u308f\u3089\u305a\u3069\u306eEstimator\u306b\u3082\u3042\u308a\u3001classifier\u306e\u5834\u5408\u306fmean accuracy\uff08\u7cbe\u5ea6\uff09\u3092return\u3057\u307e\u3059\u3002",
            "title": "Exercise 6"
        },
        {
            "location": "/section1/unit1/k-nn/#iris-flower-dataset",
            "text": "scikit-learn\u306b\u306f\u5e7e\u3064\u304b\u306e\u6709\u540d\u306aData set\u304c\u5165\u3063\u3066\u3044\u307e\u3059\u3002 Iris flower data set \u306f\uff13\u3064\u306e\u82b1\u306e\u7a2e\u985e\u3092\uff14\u3064\u306e\u7279\u5fb4\u304b\u3089\u6210\u308a\u7acb\u3063\u3066\u3044\u307e\u3059\u3002 model_selection \u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5165\u3063\u3066\u308b train_test_split \u3067training data\u3068test data\u30926:4\u306b\u5206\u3051\u307e\u3059\u3002  from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom s8_final import MyKNeighborsClassifier\n\niris = datasets.load_iris()\n\nx_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.4)\nneighbor = MyKNeighborsClassifier(n_neighbors=5, weights='uniform', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train))\nprint(neighbor.score(x_test, y_test))  Iris flower\u306f\u304b\u306a\u308a\u30af\u30ea\u30fc\u30f3\u306a\u30c7\u30fc\u30bf\u306a\u306e\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u3082\u9ad8\u3044\u7cbe\u5ea6\u304c\u7c21\u5358\u306b\u51fa\u307e\u3059\u3002 n_neighbors , weights , p \u3092\u3044\u3058\u3063\u3066\u5909\u5316\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002",
            "title": "Iris Flower Dataset"
        },
        {
            "location": "/section1/unit2/supervised_learning/",
            "text": "\u524d\u56dek-Nearest Neighbors\u3092\u52c9\u5f37\u3057\u3066Supervised Learning\u3068\u306f\u4f55\u304b\u3092\u7406\u89e3\u3057\u307e\u3057\u305f\u3002\n\u3057\u304b\u3057\u30c7\u30fc\u30bf\u306b\u306f\u8272\u3093\u306a\u7a2e\u985e\u304c\u3042\u308a\u3001\u3069\u3093\u306a\u30c7\u30fc\u30bf\u3067\u3082\u305d\u306e\u307e\u307eClassifier\u306b\u7a81\u3063\u8fbc\u3081\u3070\u52dd\u624b\u306b\u4e88\u6e2c\u3057\u3066\u304f\u308c\u308b\u308f\u3051\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n\n\n\u4eca\u56de\u306fIris Flower Data set\u3088\u308a\u3082\u5c11\u3057\u3060\u3051\u8907\u96d1\u306a\u30c7\u30fc\u30bf\u3092\u4f7f\u3044\u3001Supervised Learning\u306e\u57fa\u790e\u3092\u52c9\u5f37\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n\n\u4eca\u56de\u4f7f\u3046\u306e\u306fHuman Resource\u306e\u30c7\u30fc\u30bf\u3067\u3059\u3002\u5f93\u696d\u54e1\u306e\u60c5\u5831\u304b\u3089\u305d\u306e\u4eba\u304c\u9000\u8077\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u4e88\u6e2c\u3059\u308b\u3068\u3044\u3046\u3082\u306e\u3067\u3059\u3002\n\nhttps://www.kaggle.com/ludobenistant/hr-analytics\n\n\n\u30da\u30fc\u30b8\u306e\u4e0b\u306ePreview\u306e\"Show Column Description\"\u3068\u3044\u3046\u3068\u3053\u308d\u306b\u5404\u7279\u5fb4\u306e\u7c21\u5358\u306a\u8aac\u660e\u3068\u30c7\u30fc\u30bf\u30bf\u30a4\u30d7\u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\n\n\n\u30ab\u30c6\u30b4\u30ea\u30fc\u3092\u6570\u5b57\u306b\u76f4\u3059\n\n\nsales(\u6240\u5c5e\u90e8\u7f72)\u3068salary\u306e\u30c7\u30fc\u30bf\u306fstring\u3067\u3001\u3053\u306e\u5834\u5408\u3069\u3061\u3089\u3082\u30ab\u30c6\u30b4\u30ea\u30fc\u3067\u3059\u3002string\u3092\u305d\u306e\u307e\u307ek-NN\u306b\u7a81\u3063\u8fbc\u3080\u308f\u3051\u306b\u306f\u3044\u304b\u306a\u3044\u306e\u3067\u3001\u6570\u5b57\u306b\u76f4\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\n\n\u4ee5\u4e0b\u306esalary\u306e\u3088\u3046\u306bpandas\u3068python dictionary\u3092\u4f7f\u3063\u3066\u6570\u5b57\u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3057\u3001\nscikit learn\u306e label encoder\n\u306elabel encoder\u3092\u4f7f\u3063\u3066\u81ea\u52d5\u7684\u306b\u6570\u5b57\u306b\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002\n\n\n#s1_categorical.py\nimport numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nle = LabelEncoder()\n\ndf = pd.read_csv(\"HR_comma_sep.csv\")\n\nsalary_mapping = {'high': 3, 'medium': 2, 'low': 1}\ndf[\"salary\"] = df[\"salary\"].map(salary_mapping)\n\ndf.sales = le.fit_transform(df.sales)\nprint(df.head())\n\ny = df.left.values\ncol = list(df.columns)\ncol.remove(\"left\")\nx = df[col].values\n\n\n\n\nFeature Scaling\n\n\n\u30c7\u30fc\u30bf\u306b\u3088\u3063\u3066\u30ec\u30f3\u30b8\u304c\u9055\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070satisfaction_level\u3084last_evaluation\u306e\u30ec\u30f3\u30b8\u306f0~1\u3067\u3059\u3002average_monthly_hours\u306f\u4ed6\u306e\u7279\u5fb4\u306b\u6bd4\u3079\u3066\u30ec\u30f3\u30b8\u304c\u5927\u304d\u3044\u306e\u304c\u5206\u304b\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u3053\u306e\u307e\u307ek-NN\u306b\u5165\u308c\u308b\u3068\u3001average_monthly_hours\u306e\u9055\u3044\u304c\u4ed6\u306e\u7279\u5fb4\u306e\u9055\u3044\u306b\u6bd4\u3079\u3066\u5927\u304d\u3044\u305f\u3081\u3001\u4ed6\u306e\u7279\u5fb4\u304c\u307b\u3068\u3093\u3069\u8003\u616e\u3055\u308c\u306a\u304f\u306a\u308a\u307e\u3059\u3002\n\n\n\u3069\u306e\u7279\u5fb4\u3082\u5747\u7b49\u306b\u8003\u616e\u3059\u308b\u306b\u306f\u3001\u5404\u7279\u5fb4\u3092\u540c\u3058\u5927\u304d\u3055\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u305d\u306e\u51e6\u7406\u306e\u3053\u3068\u3092\nFeature Scaling\n\u3068\u547c\u3073\u307e\u3059\u3002\n\nhttps://en.wikipedia.org/wiki/Feature_scaling\n\n\n\u305d\u306e\u4e2d\u3067\u3082\u3001\u5e73\u5747(mean)\u30920\u306b\u3057\u6a19\u6e96\u504f\u5dee(standard deviation)\u30921\u306b\u306a\u308b\u3088\u3046\u306b\u7279\u5fb4\u3092\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u308b\u30e1\u30bd\u30c3\u30c9\u3092\nStandardization\n\u3068\u547c\u3073\u307e\u3059\u3002\u516c\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n\n\n\n\n x' = \\frac{x - \\bar{x}}{\\sigma} \n\n\n\n\nx = [1, 5, 0] \u3060\u3068\u3057\u3066x'\u3092\u6c42\u3081\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n \\bar{x} = \\frac{1 + 5 + 0}{3} = 2 \n\n\n\n\n\n\n x - \\bar{x} = [1-2, 5-2, 0-2] = [-1, 3, -2] \n\n\n\n\n\n\n \\sigma = \\sqrt{ \\frac{1^2 + 3^2 + (-2)^2}{3}} = \\sqrt{\\frac{14}{3}} = 2.160 \n\n\n\n\n\n\n x' = \\frac{[-1,3,-2]}{2.160} = [-0.463,  1.389, -0.926] \n\n\n\n\nFeature Scaling\u306f\u307b\u307c\u5168\u3066\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u969b\u306b\u5fc5\u8981\u3067\u3059\u3002Feature Scaling\u304c\u5fc5\u8981\u306a\u3044\u6709\u540d\u306a\u30e2\u30c7\u30eb\u306bDecision Tree\u304c\u3042\u308a\u307e\u3059\u3002\n\n\nExercise 1\n\n\n\u307e\u305a\u306f\u4e00\u3064\u306e\u7279\u5fb4\u3060\u3051\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u308b\u95a2\u6570\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\n\n\nExercise 2\n\n\nscikit-learn\u306escale\n\u306fX\u3092\u30a4\u30f3\u30d7\u30c3\u30c8\u3068\u3057\u3066\u53d6\u308b\u306e\u3067\u3001\u5404\u7279\u5fb4\u3092\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u307e\u3059\u3002\n\n\nExercise 3\n\n\n\u5b9f\u969b\u306fTraining data\u3092Test data\u306b\u5225\u3005\u306bscale\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001Training data\u306emean\u3068standard deviation\u3092\u4f7f\u3063\u3066\u4e21\u65b9\u3068\u3082\u30b9\u30b1\u30fc\u30eb\u3057\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u306b\u306f\nStandardScaler\n\u3068\u3044\u3046\u30af\u30e9\u30b9\u3092\u4f7f\u3044\u307e\u3059\u3002\u4ee5\u4e0b\u304c\u5178\u578b\u7684\u306a\u4f7f\u7528\u4f8b\u3067\u3059\u3002\n\n\nscaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\n\n\n\n\nfit\u306e\u90e8\u5206\u306f\u65e2\u306b\u5b8c\u6210\u3057\u3066\u3044\u308b\u306e\u3067\u3001transform\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002\n\n\nOverfitting\n\n\nSupervised Learning\u306e\u76ee\u7684\u306f\u5c06\u6765\u306e\u30c7\u30fc\u30bf\u3001\u3064\u307e\u308aTest data\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3068\u3044\u3046\u3053\u3068\u306ftraining accuracy(training data\u3067\u306e\u7cbe\u5ea6)\u304c\u5e7e\u3089\u9ad8\u304f\u3067\u3082\u610f\u5473\u304c\u3042\u308a\u307e\u305b\u3093\u3002training accuracy\u3092\u9ad8\u3081\u308b\u3053\u3068\u3092\u9811\u5f35\u308a\u904e\u304e\u3066test accuracy\u304c\u4f4e\u304f\u306a\u3063\u3066\u3057\u307e\u3046\u3053\u3068\u3092\nOverfitting\n\u3068\u547c\u3073\u307e\u3059\u3002\n\n\nk-NN\u306e\u5834\u5408\u3001k=1\u3060\u3068training accuracy\u306f\u5fc5\u305a1.0\u306b\u306a\u308a\u307e\u3059\u3002\u4f55\u6545\u306a\u3089\u3001\u305d\u306e\u30c7\u30fc\u30bf\u81ea\u8eab\u304c\u96a3\u4eba\u306b\u306a\u308b\u304b\u3089\u3067\u3059\u3002\u3057\u304b\u3057\u3053\u308c\u3067\u306fgeneralize\u3057\u3066\u3044\u307e\u305b\u3093\u3002\nk=3\u306e\u65b9\u304ctest accuracy\u304c\u9ad8\u3044\u3067\u3059\u3002\n\n\n# s6_overfitting.py\n\n...\n\n\n## Overfitting\nneighbor = KNeighborsClassifier(n_neighbors=1, weights='uniform', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train)) # 1.0\nprint(neighbor.score(x_test, y_test)) # 0.9526\n\n## Test accuracy\u306f\u3053\u3063\u3061\u306e\u65b9\u304c\u9ad8\u3044\nneighbor = KNeighborsClassifier(n_neighbors=3, weights='distance', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train)) # 1.0\nprint(neighbor.score(x_test, y_test)) # 0.9550\n\n\n\n\n\n\u4eca\u56de\u306e\u30c7\u30fc\u30bf\u306f\u64ec\u4f3c\u7684\u306b\u4f5c\u3089\u308c\u305f\u3082\u306e\u3067\u3042\u308a\u30ce\u30a4\u30ba\u304c\u5c11\u306a\u3044\u306e\u3067\u3001\u5168\u4f53\u7684\u306b\u7cbe\u5ea6\u304c\u9ad8\u304f\u3066\u3042\u307e\u308a\u9762\u767d\u304f\u306a\u3044\u3067\u3059\u304c\u3001\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u3060\u3068overfitting\u306e\u554f\u984c\u304c\u9855\u8457\u306b\u8868\u308c\u307e\u3059\u3002training accuracy\u3068test accuracy\u306e\u5dee\u304c10%\u4ee5\u4e0a\u958b\u3044\u3066\u3044\u305f\u3089\u78ba\u5b9f\u306boverfitting\u306a\u306e\u3067\u3001training accuracy\u3068test accuracy\u306e\u5dee\u3092\u7e2e\u3081\u308b\u3088\u3046\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u3057\u307e\u3057\u3087\u3046\u3002\n\n\n\u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066overfitting\u306e\u5bfe\u51e6\u6cd5\u304c\u9055\u3044\u307e\u3059\u3002k-NN\u306e\u5834\u5408\u306f\u3001k\u304c\u5c11\u306a\u3044\u7a0boverfit\u3057\u307e\u3059\u3002\u307e\u305fweights\u3092distance\u306b\u3059\u308b\u3068\u9060\u304f\u306e\u30c7\u30fc\u30bf\u306e\u5b58\u5728\u304c\u5f31\u304f\u306a\u308b\u306e\u3067overfit\u3057\u304c\u3061\u3067\u3059\u3002\n\n\n\u30e2\u30c7\u30eb\u306b\u95a2\u4fc2\u306a\u304foverfit\u3092\u9632\u3050\u4e00\u756a\u7c21\u5358\u306a\u65b9\u6cd5\u304c\u30c7\u30fc\u30bf\u3092\u5897\u3084\u3059\u3053\u3068\u3067\u3059\u3002\u5c11\u306a\u3044\u30c7\u30fc\u30bf\u306bNeural Network\u306e\u3088\u3046\u306a\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u306e\u9ad8\u3044\u30e2\u30c7\u30eb\u3001\u3064\u307e\u308atraining accuracy\u306e\u9ad8\u3044\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u3068\u3001\u3069\u3093\u306a\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u3044\u3058\u3063\u3066\u3082overfit\u3057\u307e\u3059\u3002\n\u3088\u3063\u3066\u3069\u3046\u3084\u3063\u3066\u5b89\u304f\u5927\u91cf\u306e\u6559\u5e2b\u7528\u30c7\u30fc\u30bf\u3092\u96c6\u3081\u308b\u304b\u3068\u3044\u3046\u306e\u306f\u975e\u5e38\u306b\u91cd\u8981\u306a\u554f\u984c\u3067\u3059\u3002",
            "title": "Supervised Learning"
        },
        {
            "location": "/section1/unit2/supervised_learning/#_1",
            "text": "sales(\u6240\u5c5e\u90e8\u7f72)\u3068salary\u306e\u30c7\u30fc\u30bf\u306fstring\u3067\u3001\u3053\u306e\u5834\u5408\u3069\u3061\u3089\u3082\u30ab\u30c6\u30b4\u30ea\u30fc\u3067\u3059\u3002string\u3092\u305d\u306e\u307e\u307ek-NN\u306b\u7a81\u3063\u8fbc\u3080\u308f\u3051\u306b\u306f\u3044\u304b\u306a\u3044\u306e\u3067\u3001\u6570\u5b57\u306b\u76f4\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002  \u4ee5\u4e0b\u306esalary\u306e\u3088\u3046\u306bpandas\u3068python dictionary\u3092\u4f7f\u3063\u3066\u6570\u5b57\u306b\u5909\u63db\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3057\u3001 scikit learn\u306e label encoder \u306elabel encoder\u3092\u4f7f\u3063\u3066\u81ea\u52d5\u7684\u306b\u6570\u5b57\u306b\u3059\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002  #s1_categorical.py\nimport numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\nle = LabelEncoder()\n\ndf = pd.read_csv(\"HR_comma_sep.csv\")\n\nsalary_mapping = {'high': 3, 'medium': 2, 'low': 1}\ndf[\"salary\"] = df[\"salary\"].map(salary_mapping)\n\ndf.sales = le.fit_transform(df.sales)\nprint(df.head())\n\ny = df.left.values\ncol = list(df.columns)\ncol.remove(\"left\")\nx = df[col].values",
            "title": "\u30ab\u30c6\u30b4\u30ea\u30fc\u3092\u6570\u5b57\u306b\u76f4\u3059"
        },
        {
            "location": "/section1/unit2/supervised_learning/#feature-scaling",
            "text": "\u30c7\u30fc\u30bf\u306b\u3088\u3063\u3066\u30ec\u30f3\u30b8\u304c\u9055\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070satisfaction_level\u3084last_evaluation\u306e\u30ec\u30f3\u30b8\u306f0~1\u3067\u3059\u3002average_monthly_hours\u306f\u4ed6\u306e\u7279\u5fb4\u306b\u6bd4\u3079\u3066\u30ec\u30f3\u30b8\u304c\u5927\u304d\u3044\u306e\u304c\u5206\u304b\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u3053\u306e\u307e\u307ek-NN\u306b\u5165\u308c\u308b\u3068\u3001average_monthly_hours\u306e\u9055\u3044\u304c\u4ed6\u306e\u7279\u5fb4\u306e\u9055\u3044\u306b\u6bd4\u3079\u3066\u5927\u304d\u3044\u305f\u3081\u3001\u4ed6\u306e\u7279\u5fb4\u304c\u307b\u3068\u3093\u3069\u8003\u616e\u3055\u308c\u306a\u304f\u306a\u308a\u307e\u3059\u3002  \u3069\u306e\u7279\u5fb4\u3082\u5747\u7b49\u306b\u8003\u616e\u3059\u308b\u306b\u306f\u3001\u5404\u7279\u5fb4\u3092\u540c\u3058\u5927\u304d\u3055\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\u305d\u306e\u51e6\u7406\u306e\u3053\u3068\u3092 Feature Scaling \u3068\u547c\u3073\u307e\u3059\u3002 https://en.wikipedia.org/wiki/Feature_scaling  \u305d\u306e\u4e2d\u3067\u3082\u3001\u5e73\u5747(mean)\u30920\u306b\u3057\u6a19\u6e96\u504f\u5dee(standard deviation)\u30921\u306b\u306a\u308b\u3088\u3046\u306b\u7279\u5fb4\u3092\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u308b\u30e1\u30bd\u30c3\u30c9\u3092 Standardization \u3068\u547c\u3073\u307e\u3059\u3002\u516c\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002    x' = \\frac{x - \\bar{x}}{\\sigma}    x = [1, 5, 0] \u3060\u3068\u3057\u3066x'\u3092\u6c42\u3081\u3066\u307f\u307e\u3057\u3087\u3046\u3002    \\bar{x} = \\frac{1 + 5 + 0}{3} = 2      x - \\bar{x} = [1-2, 5-2, 0-2] = [-1, 3, -2]      \\sigma = \\sqrt{ \\frac{1^2 + 3^2 + (-2)^2}{3}} = \\sqrt{\\frac{14}{3}} = 2.160      x' = \\frac{[-1,3,-2]}{2.160} = [-0.463,  1.389, -0.926]    Feature Scaling\u306f\u307b\u307c\u5168\u3066\u306e\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u969b\u306b\u5fc5\u8981\u3067\u3059\u3002Feature Scaling\u304c\u5fc5\u8981\u306a\u3044\u6709\u540d\u306a\u30e2\u30c7\u30eb\u306bDecision Tree\u304c\u3042\u308a\u307e\u3059\u3002",
            "title": "Feature Scaling"
        },
        {
            "location": "/section1/unit2/supervised_learning/#exercise-1",
            "text": "\u307e\u305a\u306f\u4e00\u3064\u306e\u7279\u5fb4\u3060\u3051\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u308b\u95a2\u6570\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit2/supervised_learning/#exercise-2",
            "text": "scikit-learn\u306escale \u306fX\u3092\u30a4\u30f3\u30d7\u30c3\u30c8\u3068\u3057\u3066\u53d6\u308b\u306e\u3067\u3001\u5404\u7279\u5fb4\u3092\u30b9\u30b1\u30fc\u30eb\u3055\u305b\u307e\u3059\u3002",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit2/supervised_learning/#exercise-3",
            "text": "\u5b9f\u969b\u306fTraining data\u3092Test data\u306b\u5225\u3005\u306bscale\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001Training data\u306emean\u3068standard deviation\u3092\u4f7f\u3063\u3066\u4e21\u65b9\u3068\u3082\u30b9\u30b1\u30fc\u30eb\u3057\u307e\u3059\u3002\n\u305d\u306e\u305f\u3081\u306b\u306f StandardScaler \u3068\u3044\u3046\u30af\u30e9\u30b9\u3092\u4f7f\u3044\u307e\u3059\u3002\u4ee5\u4e0b\u304c\u5178\u578b\u7684\u306a\u4f7f\u7528\u4f8b\u3067\u3059\u3002  scaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)  fit\u306e\u90e8\u5206\u306f\u65e2\u306b\u5b8c\u6210\u3057\u3066\u3044\u308b\u306e\u3067\u3001transform\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 3"
        },
        {
            "location": "/section1/unit2/supervised_learning/#overfitting",
            "text": "Supervised Learning\u306e\u76ee\u7684\u306f\u5c06\u6765\u306e\u30c7\u30fc\u30bf\u3001\u3064\u307e\u308aTest data\u3092\u4e88\u6e2c\u3059\u308b\u3053\u3068\u3067\u3059\u3002\u3068\u3044\u3046\u3053\u3068\u306ftraining accuracy(training data\u3067\u306e\u7cbe\u5ea6)\u304c\u5e7e\u3089\u9ad8\u304f\u3067\u3082\u610f\u5473\u304c\u3042\u308a\u307e\u305b\u3093\u3002training accuracy\u3092\u9ad8\u3081\u308b\u3053\u3068\u3092\u9811\u5f35\u308a\u904e\u304e\u3066test accuracy\u304c\u4f4e\u304f\u306a\u3063\u3066\u3057\u307e\u3046\u3053\u3068\u3092 Overfitting \u3068\u547c\u3073\u307e\u3059\u3002  k-NN\u306e\u5834\u5408\u3001k=1\u3060\u3068training accuracy\u306f\u5fc5\u305a1.0\u306b\u306a\u308a\u307e\u3059\u3002\u4f55\u6545\u306a\u3089\u3001\u305d\u306e\u30c7\u30fc\u30bf\u81ea\u8eab\u304c\u96a3\u4eba\u306b\u306a\u308b\u304b\u3089\u3067\u3059\u3002\u3057\u304b\u3057\u3053\u308c\u3067\u306fgeneralize\u3057\u3066\u3044\u307e\u305b\u3093\u3002\nk=3\u306e\u65b9\u304ctest accuracy\u304c\u9ad8\u3044\u3067\u3059\u3002  # s6_overfitting.py\n\n...\n\n\n## Overfitting\nneighbor = KNeighborsClassifier(n_neighbors=1, weights='uniform', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train)) # 1.0\nprint(neighbor.score(x_test, y_test)) # 0.9526\n\n## Test accuracy\u306f\u3053\u3063\u3061\u306e\u65b9\u304c\u9ad8\u3044\nneighbor = KNeighborsClassifier(n_neighbors=3, weights='distance', p=2)\nneighbor.fit(x_train, y_train)\nprint(neighbor.score(x_train, y_train)) # 1.0\nprint(neighbor.score(x_test, y_test)) # 0.9550  \u4eca\u56de\u306e\u30c7\u30fc\u30bf\u306f\u64ec\u4f3c\u7684\u306b\u4f5c\u3089\u308c\u305f\u3082\u306e\u3067\u3042\u308a\u30ce\u30a4\u30ba\u304c\u5c11\u306a\u3044\u306e\u3067\u3001\u5168\u4f53\u7684\u306b\u7cbe\u5ea6\u304c\u9ad8\u304f\u3066\u3042\u307e\u308a\u9762\u767d\u304f\u306a\u3044\u3067\u3059\u304c\u3001\u5b9f\u969b\u306e\u30c7\u30fc\u30bf\u3060\u3068overfitting\u306e\u554f\u984c\u304c\u9855\u8457\u306b\u8868\u308c\u307e\u3059\u3002training accuracy\u3068test accuracy\u306e\u5dee\u304c10%\u4ee5\u4e0a\u958b\u3044\u3066\u3044\u305f\u3089\u78ba\u5b9f\u306boverfitting\u306a\u306e\u3067\u3001training accuracy\u3068test accuracy\u306e\u5dee\u3092\u7e2e\u3081\u308b\u3088\u3046\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8abf\u6574\u3057\u307e\u3057\u3087\u3046\u3002  \u30e2\u30c7\u30eb\u306b\u3088\u3063\u3066overfitting\u306e\u5bfe\u51e6\u6cd5\u304c\u9055\u3044\u307e\u3059\u3002k-NN\u306e\u5834\u5408\u306f\u3001k\u304c\u5c11\u306a\u3044\u7a0boverfit\u3057\u307e\u3059\u3002\u307e\u305fweights\u3092distance\u306b\u3059\u308b\u3068\u9060\u304f\u306e\u30c7\u30fc\u30bf\u306e\u5b58\u5728\u304c\u5f31\u304f\u306a\u308b\u306e\u3067overfit\u3057\u304c\u3061\u3067\u3059\u3002  \u30e2\u30c7\u30eb\u306b\u95a2\u4fc2\u306a\u304foverfit\u3092\u9632\u3050\u4e00\u756a\u7c21\u5358\u306a\u65b9\u6cd5\u304c\u30c7\u30fc\u30bf\u3092\u5897\u3084\u3059\u3053\u3068\u3067\u3059\u3002\u5c11\u306a\u3044\u30c7\u30fc\u30bf\u306bNeural Network\u306e\u3088\u3046\u306a\u30ad\u30e3\u30d1\u30b7\u30c6\u30a3\u306e\u9ad8\u3044\u30e2\u30c7\u30eb\u3001\u3064\u307e\u308atraining accuracy\u306e\u9ad8\u3044\u30e2\u30c7\u30eb\u3092\u4f7f\u3046\u3068\u3001\u3069\u3093\u306a\u306b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u3044\u3058\u3063\u3066\u3082overfit\u3057\u307e\u3059\u3002\n\u3088\u3063\u3066\u3069\u3046\u3084\u3063\u3066\u5b89\u304f\u5927\u91cf\u306e\u6559\u5e2b\u7528\u30c7\u30fc\u30bf\u3092\u96c6\u3081\u308b\u304b\u3068\u3044\u3046\u306e\u306f\u975e\u5e38\u306b\u91cd\u8981\u306a\u554f\u984c\u3067\u3059\u3002",
            "title": "Overfitting"
        },
        {
            "location": "/section1/unit3/naive_bayes/",
            "text": "Naive Bayes\u306fk-NN\u3068\u540c\u69d8\u30b7\u30f3\u30d7\u30eb\u306a\u30e2\u30c7\u30eb\u3067\u3059\u3002\u3088\u304ftext classification\u306b\u4f7f\u308f\u308c\u307e\u3059\u3002\n\n\nscikit-learn\u306b\u306f\n\uff13\u7a2e\u985e\u306eNaive Bayes\n\u304c\u3042\u308a\u307e\u3059\u3002\u4eca\u56de\u306fMultinomial\u3068Bernoulli\u3092\u4f5c\u308a\u307e\u3059\u3002\n\n\nMultinomial Naive Bayes\n\n\n\u307e\u305a\u306fMultinomial Naive Bayes\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002\nAn Introduction to Information Retrieval\u306eChapter13\n\u306e\u4f8b\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\nPDF\u306f\u3053\u3061\u3089\u304b\u3089\u53d6\u5f97\u51fa\u6765\u307e\u3059\u3002\n\nhttps://nlp.stanford.edu/IR-book/\n\n\nTable 13.1 \u306b\u30c7\u30fc\u30bf\u304c\u8f09\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u7a2e\u985e\u3092\u5206\u985e\u3059\u308btext classification\u306e\u30c7\u30fc\u30bf\u3067\u3059\u3002training set\u306f\uff14\u3064\u3042\u308a\u3001\u305d\u308c\u305e\u308c\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5358\u8a9e\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070document 1\u306b\u306f\"Chinese\",\"Beijing\",\"Chinese\"\u3068\u3044\u3046\u5358\u8a9e\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\n\n\n\n\n\u5f53\u7136\u5b9f\u969b\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u3084\u6620\u753b\u306e\u30ec\u30d3\u30e5\u30fc\u3092\u5206\u985e\u3059\u308b\u3068\u306a\u308b\u3068\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308b\u5358\u8a9e\u6570\u306f\u3082\u3063\u3068\u591a\u3044\u3067\u3059\u304c\u3001\u624b\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u8a08\u7b97\u3059\u308b\u70ba\u306b\u5c0f\u3055\u3044\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002\n\n\n\u4e00\u756a\u53f3\u306e\u30ab\u30e9\u30e0\u306f\u30af\u30e9\u30b9\u3067\u3059\u3002\u4eca\u56de\u306f\u30af\u30e9\u30b9\u306f\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u4e2d\u56fd\u306b\u95a2\u3059\u308b\u3082\u306e\u304b\u3069\u3046\u304b\u306a\u306e\u3067yes\u3068no\u306e\uff12\u7a2e\u985e\u3060\u3051\u3067\u3059\u3002\n\n\n\u3053\u306e\uff14\u3064\u306etraining data\u3092\u5143\u306b\u3001document 5\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\n\n\u4e88\u6e2c\u3059\u308b\u306b\u306f\np(c)\n\u3068\np(t|c)\n\u306e\uff12\u30d1\u30fc\u30c4\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n\np(c)\n\n\n\u307e\u305a\u306fp(c)\u3092\u6c42\u3081\u307e\u3059\u3002p(c)\u306f\u5358\u7d14\u306btraining set\u3067\u306e\u30af\u30e9\u30b9c\u306e\u5272\u5408\u3067\u3059\u3002\n\u6559\u79d1\u66f8\u3067\u306f\n\n\n\n\n p(c) = p(c = yes) \n\n\n\n\n\n\n p(\\bar{c}) = p(c = no) \n\n\n\n\n\u3068\u3057\u3066\u3044\u307e\u3059\u3002training set \u306f\u5168\u90e8\u3067\uff14\u3064\u3042\u308a\uff13\u3064\u304cyes\u306a\u306e\u3067\n\n\n\n\n p(c) = 3/4 \n\n\n\n\n\n\n p(\\bar{c}) = 1/4 \n\n\n\n\n\u3068\u306a\u308a\u307e\u3059\u3002\n\n\np(t|c)\n\n\n\u6b21\u306b\np(t|c)\n\u3092\u6c42\u3081\u307e\u3059\u3002t\u306f\nterm\n\u306e\u7565\u3067\u5358\u8a9e\u306e\u7a2e\u985e\u306e\u3053\u3068\u3092\u6307\u3057\u307e\u3059\u3002\u305d\u308c\u306b\u5bfe\u3057\nword\n\u306f\u4e00\u3064\u4e00\u3064\u306e\u5358\u8a9e\u306e\u3053\u3068\u3092\u6307\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070document 1\u3067\u306fterm\u306f\"Chinese\"\u3068\"Beijing\"\u306e\uff12\u3064\u3067\u3059\u304c\u3001word\u306f\uff13\u3064\u3067\u3059\u3002\n\n\np(t|c)\n\u306f\"\u305d\u306e\u30af\u30e9\u30b9\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308bt\u306e\u7dcf\u6570\"\u00f7\"\u305d\u306e\u30af\u30e9\u30b9\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308b\u7dcf\u5358\u8a9e\u6570\"\u3067\u3059\u3002\n\n\np(Chinese|c)\n\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\nChinese\u306fdocument 1,2,3\u5408\u308f\u305b\u30665\u3064\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002document 1,2,3\u306e\u7dcf\u5358\u8a9e\u6570\u306f8\u306a\u306e\u3067\n\n\n\n\n \\hat{p}(Chinese|c) = 5 / 8 \n\n\n\n\n\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\u6700\u5f8c\u306b\u3053\u308c\u3089\u3092\u639b\u3051\u5408\u308f\u305b\u308b\u306e\u3067\u3059\u304c\u3001\u4e00\u3064\u554f\u984c\u304c\u3042\u308a\u307e\u3059\u3002training data\u306b\u4e00\u3064\u3082\u5165\u3063\u3066\u3044\u306a\u3044\u5358\u8a9e\u3060\u3068\np(t|c) = 0 / 8 = 0\n\u306b\u306a\u3063\u3066\u3057\u307e\u3044\u5168\u4f53\u304c0\u306b\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u9632\u3050\u305f\u3081\u306b\nsmoothing\n\u3068\u3046\u30c6\u30af\u30cb\u30c3\u30af\u3092\u4f7f\u3044\u307e\u3059\u3002smoothing\u306b\u306f\u5e7e\u3064\u304b\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u5168term\u306b1\u3092\u8db3\u3059\nadd-one smoothing\n\u304c\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a\u65b9\u6cd5\u3067\u3059\u3002\n\n\n\u3088\u3063\u3066\np(Chinese|c)\n\u306e\u5834\u5408\u3001\u5168\u4f53\u30676 terms(Chinese, Beijing, Shanghai, Macao, Tokyo, Japan)\u3042\u308b\u306e\u3067\u5206\u6bcd\u306b\uff16\u3092\u8db3\u3057\u3001\u5206\u5b50\u306b\uff11\u3092\u8db3\u3057\u307e\u3059\u3002\n\n\n\n\n \\hat{p}(Chinese|c) = (5 + 1)  / (8 + 6) = 6 / 14 = 3/7 \n\n\n\n\n\u672c\u5f53\u306ftraining set\u306b\u51fa\u3066\u304f\u308b\u5168term\u306e\np(t|c)\n\u3092\nfit\n\u6642\u306b\u8a08\u7b97\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u4eca\u56de\u306ftest set\u304c\uff11\u3064\u3060\u3051\u306a\u306e\u3067\u305d\u308c\u306b\u542b\u307e\u308c\u3066\u308bterm\u306e\u5206\u3060\u3051\u8a08\u7b97\u3057\u307e\u3059\u3002\n\n\n\n\n\u81ea\u5206\u3067\u78ba\u304b\u3081\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002\n\n\n\u5f8c\u306fp258\u306e\u4ee5\u4e0b\u306e\u6570\u5f0f\u306b\u5f93\u3063\u3066\u3053\u308c\u3089\u3092\u304b\u3051\u3042\u308f\u305b\u307e\u3059\u3002\n\n\n\n\n\"Chinese\"\u306fdocument 5\u306b\uff13\u3064\u542b\u307e\u308c\u3066\u308b\u306e\u3067\uff13\u4e57\u3057\u307e\u3059\u3002\u5148\u982d\u306bp(c)\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067\u6ce8\u610f\u3057\u307e\u3057\u3087\u3046\u3002\n\n\n\n\np(c|d5)\n\u306e\u65b9\u304c\u9ad8\u3044\u306e\u3067\u3001document 5\u306fyes\u3001\u3064\u307e\u308a\u4e2d\u56fd\u306b\u95a2\u3059\u308b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3068\u4e88\u6e2c\u3057\u307e\u3059\u3002\n\n\n\u4e0a\u306e\u7d50\u679c\u3092\u898b\u3066\u5206\u304b\u308b\u901a\u308a\u3001\np(c|d)\n\u306f\u3082\u306e\u51c4\u304f\u5c0f\u3055\u3044\u6570\u5024\u306b\u306a\u308a\u304c\u3061\u3067\u3059\u3002\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u5927\u304d\u3044\u3068\u66f4\u306b\u3053\u308c\u304c\u5c0f\u3055\u304f\u306a\u308a\u3001floating point underflow\u304c\u8d77\u3053\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u9632\u3050\u70ba\u306b\u3001\u5b9f\u969b\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u6642\u306flog\u3092\u4f7f\u3044\u307e\u3059\u3002\uff08P258\u53c2\u7167\uff09\n\n\nExercises\n\n\nk-NN\u3068\u540c\u3058\u304f\u3001\nscikit-learn\u306eMultinomialNB\n\u3068\u540c\u3058API\u306b\u3057\u307e\u3059\u3002\n\n\nimport numpy as np\n\nnp.set_printoptions(precision=6)\n\nclass MyMultinomialNB(object):\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        N = X.shape[0]\n        # group by class\n        separated = [X[np.where(y == i)[0]] for i in np.unique(y)]\n        return separated\n\nX = np.array([\n    [2,1,0,0,0,0],\n    [2,0,1,0,0,0],\n    [1,0,0,1,0,0],\n    [1,0,0,0,1,1]\n])\ny = np.array([0,0,0,1])\nnb = MyMultinomialNB().fit(X, y)\nprint(nb)\n\n\n\n\nX\u306f\u4f8b\u306etraining set\u3092\u6570\u5024\u306b\u76f4\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u5168\u90e8\u30676 term(Chinese, Beijing, Shanghai, Macao, Tokyo, Japan)\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067dimension\u304c\uff16\u3042\u308a\u307e\u3059\u3002\n\n\ny\u306f0\u304c\"yes\"\u30011\u3092\"no\"\u3068\u3057\u3066\u3044\u307e\u3059\u3002\n\n\n__init__\n\u306ealpha\u306fsmoothing\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u3059\u3002\u5f8c\u3067\u4f7f\u3046\u306e\u3067\u4eca\u306f\u7121\u8996\u3057\u3066\u5927\u4e08\u592b\u3067\u3059\u3002\n\n\nfit\n\u3067\u306f\u307e\u305a\u30af\u30e9\u30b9\u6bce\u306b\u30c7\u30fc\u30bf\u3092\u5206\u3051\u307e\u3059\u3002\nfit\n\u306f\u6700\u7d42\u7684\u306b\u306f\nself\n\u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u4eca\u306f\u4e00\u65e6\u7121\u8996\u3057\u3066\nseparated\n\u3092\u30ea\u30bf\u30fc\u30f3\u3057\u3066\u3044\u307e\u3059\u3002\n\n\n# output\n[array([[2, 1, 0, 0, 0, 0],\n       [2, 0, 1, 0, 0, 0],\n       [1, 0, 0, 1, 0, 0]]), array([[1, 0, 0, 0, 1, 1]])]\n\n\n\n\nExercise 1\n\n\np(c)\n\u3092\u8a08\u7b97\u3057\u3066\nself.class_log_prior_\n\u306b\u30a2\u30b5\u30a4\u30f3\u3057\u3066\u4e0b\u3055\u3044\u3002\u305d\u306e\u969blog\u306b\u3059\u308b\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002\u666e\u901a\u306b\u8a08\u7b97\u3057\u305f\u5f8c\u305d\u308c\u305e\u308c\u306b\nnp.log\n\u3092\u4f7f\u3046\u3060\u3051\u3067\u3059\u3002\n\n\nExercise 2\n\n\n\u6b21\u306b\u5404\u30af\u30e9\u30b9\u6bce\u306b\u305d\u308c\u305e\u308c\u306eterm\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u307e\u3059\u3002\nself.alpha\n\u3092smoothing\u3068\u3057\u3066\u8db3\u3059\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002\n\n\nExercise 3\n\n\n\u6700\u5f8c\u306b\np(t|c)\n\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\u3053\u308c\u3082log\u306b\u3059\u308b\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002\n\u3053\u308c\u3067\nfit\n\u306f\u5b8c\u6210\u3067\u3059\u3002\n\n\nExercise 4\n\n\n\u6b21\u306b\npredict_log_proba\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u3053\u308c\u306f\np(c|d)\n\u306e\u3053\u3068\u3067\u3059\u3002\n\nself.feature_log_prob_\n\u3068\nself.class_log_prior_\n\u3092\u3053\u3053\u3067\u4f7f\u3044\u307e\u3059\u3002\nlog probability\u3092\u4f7f\u3063\u3066\u308b\u306e\u3067\u639b\u3051\u305a\u306b\u8db3\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 5\n\n\n\u5148\u7a0b\u306e\npredict_log_proba\n\u3092\u4f7f\u3063\u3066\u4e00\u756a\u9ad8\u3044\u3082\u306e\u3092\u30ea\u30bf\u30fc\u30f3\u3057\u307e\u3059\u3002index\u304c\u30af\u30e9\u30b9\u306b\u306a\u3063\u3066\u308b\u306e\u3067index\u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308c\u3070OK\u3067\u3059\u3002\n\n\nBernoulli Naive Bayes\n\n\nBernoulli Naive Bayes\u306fMultinomial Naive Bayes\u3068\u9055\u3044\u5404term\u304c\u542b\u307e\u308c\u3066\u308b\u304b\u3060\u3051\u3092\u8003\u616e\u3057\u3001\u4f55\u56de\u542b\u307e\u308c\u3066\u308b\u304b\u306f\u7121\u8996\u3057\u307e\u3059\u3002\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3053\u3061\u3089\u306e\u65b9\u304c\u7cbe\u5ea6\u304c\u9ad8\u3044\u3067\u3059\u3002\n\n\nMultinomial NB\u3067\u306ftest data\u306b\u542b\u307e\u308c\u308bterm\u306e\np(t|c)\n\u3060\u3051\u4f7f\u3044\u307e\u3059\u304c\u3001Bernoulli NB\u306e\u5834\u5408\u306ftest data\u306b\u542b\u307e\u308c\u306a\u3044term\u3092\n1 - p(t|c)\n\u3068\u3057\u3066\u4f7f\u3044\u307e\u3059\u3002\n\n\n\n\n\n\nExercises\n\n\nExercise 6\n\n\ncount\n\u307e\u3067\u306fMultinomial Naive Bayes\u3068\u540c\u3058\u3067\u3059\u3002\ndenominator\n\u306f\nself.feature_prob\n\u306e\u5206\u6bcd\u306b\u3042\u305f\u308b\u90e8\u5206\u306a\u306e\u3067\u3053\u308c\u3092\u4f7f\u3063\u3066\nself.feature_prob\n\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002\u3053\u306e\u6bb5\u968e\u3067\u306flog\u306b\u3057\u307e\u305b\u3093\u3002\n\n\nclass MyBernoulliNB(object):\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        N = X.shape[0]\n        # group by class\n        separated = [X[np.where(y == i)[0]] for i in np.unique(y)]\n        # class prior\n        self.class_log_prior_ = [np.log(len(i) / N) for i in separated]\n        # count of each word\n        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n\n        # number of documents in each class\n        smoothing = 2 * self.alpha\n        denominator = np.array([len(i) + smoothing for i in separated])\n        # probability of each term\n        self.feature_prob_ = # Your code here\n                return self\n\n\n\n\nExercise 7\n\n\npredict_log_proba\n\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\nself.feature_prob_\n\u306f\u3053\u3053\u3067log\u306b\u3057\u307e\u3057\u3087\u3046\u3002\n\n\nbinarize\n\n\n\u3053\u308c\u307e\u3067\u306f\u30e2\u30c7\u30eb\u306e\u5916\u3067\u624b\u52d5\u3067\u30c7\u30fc\u30bf\u3092\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u30e2\u30c7\u30eb\u5185\u3067\u81ea\u52d5\u7684\u306b\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u3066\u304f\u308c\u305f\u65b9\u304c\u4fbf\u5229\u3067\u3059\u3088\u306d\u3002\n\nscikit-learn\u306eBernoulliNB\n\u3067\u306f\u305d\u306e\u6a5f\u80fd\u304c\u4ed8\u3044\u3066\u3044\u307e\u3059\u3002\nbinarize\n\u3068\u3044\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30b9\u30ec\u30c3\u30b7\u30e7\u30eb\u30c9\u3092\u8a2d\u5b9a\u3057\u3001\u81ea\u52d5\u7684\u306b\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u307e\u3059\u3002\n\n\n# s10_binarize.py\n\ndef __init__(self, alpha=1.0, binarize=0.0):\n    self.alpha = alpha\n    self.binarize = binarize\n\ndef fit(self, X, y):\n    X = self._binarize_X(X)\n    ...\n\ndef predict_log_proba(self, X):\n    X = self._binarize_X(X)\n    ...\n\ndef _binarize_X(self, X):\n    return np.where(X > self.binarize, 1, 0) if self.binarize != None else X\n\nnb = MyBernoulliNB(alpha=1, binarize=0.0).fit(X, y)\nprint(nb.predict(X_test))",
            "title": "Naive Bayes"
        },
        {
            "location": "/section1/unit3/naive_bayes/#multinomial-naive-bayes",
            "text": "\u307e\u305a\u306fMultinomial Naive Bayes\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002 An Introduction to Information Retrieval\u306eChapter13 \u306e\u4f8b\u3092\u4f7f\u3044\u307e\u3059\u3002  PDF\u306f\u3053\u3061\u3089\u304b\u3089\u53d6\u5f97\u51fa\u6765\u307e\u3059\u3002 https://nlp.stanford.edu/IR-book/  Table 13.1 \u306b\u30c7\u30fc\u30bf\u304c\u8f09\u3063\u3066\u3044\u307e\u3059\u3002\u3053\u308c\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306e\u7a2e\u985e\u3092\u5206\u985e\u3059\u308btext classification\u306e\u30c7\u30fc\u30bf\u3067\u3059\u3002training set\u306f\uff14\u3064\u3042\u308a\u3001\u305d\u308c\u305e\u308c\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5358\u8a9e\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070document 1\u306b\u306f\"Chinese\",\"Beijing\",\"Chinese\"\u3068\u3044\u3046\u5358\u8a9e\u304c\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002   \u5f53\u7136\u5b9f\u969b\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u3084\u6620\u753b\u306e\u30ec\u30d3\u30e5\u30fc\u3092\u5206\u985e\u3059\u308b\u3068\u306a\u308b\u3068\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308b\u5358\u8a9e\u6570\u306f\u3082\u3063\u3068\u591a\u3044\u3067\u3059\u304c\u3001\u624b\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u8a08\u7b97\u3059\u308b\u70ba\u306b\u5c0f\u3055\u3044\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u3044\u307e\u3059\u3002  \u4e00\u756a\u53f3\u306e\u30ab\u30e9\u30e0\u306f\u30af\u30e9\u30b9\u3067\u3059\u3002\u4eca\u56de\u306f\u30af\u30e9\u30b9\u306f\u3053\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u4e2d\u56fd\u306b\u95a2\u3059\u308b\u3082\u306e\u304b\u3069\u3046\u304b\u306a\u306e\u3067yes\u3068no\u306e\uff12\u7a2e\u985e\u3060\u3051\u3067\u3059\u3002  \u3053\u306e\uff14\u3064\u306etraining data\u3092\u5143\u306b\u3001document 5\u3092\u4e88\u6e2c\u3057\u307e\u3059\u3002  \u4e88\u6e2c\u3059\u308b\u306b\u306f p(c) \u3068 p(t|c) \u306e\uff12\u30d1\u30fc\u30c4\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002",
            "title": "Multinomial Naive Bayes"
        },
        {
            "location": "/section1/unit3/naive_bayes/#pc",
            "text": "\u307e\u305a\u306fp(c)\u3092\u6c42\u3081\u307e\u3059\u3002p(c)\u306f\u5358\u7d14\u306btraining set\u3067\u306e\u30af\u30e9\u30b9c\u306e\u5272\u5408\u3067\u3059\u3002\n\u6559\u79d1\u66f8\u3067\u306f    p(c) = p(c = yes)      p(\\bar{c}) = p(c = no)    \u3068\u3057\u3066\u3044\u307e\u3059\u3002training set \u306f\u5168\u90e8\u3067\uff14\u3064\u3042\u308a\uff13\u3064\u304cyes\u306a\u306e\u3067    p(c) = 3/4      p(\\bar{c}) = 1/4    \u3068\u306a\u308a\u307e\u3059\u3002",
            "title": "p(c)"
        },
        {
            "location": "/section1/unit3/naive_bayes/#ptc",
            "text": "\u6b21\u306b p(t|c) \u3092\u6c42\u3081\u307e\u3059\u3002t\u306f term \u306e\u7565\u3067\u5358\u8a9e\u306e\u7a2e\u985e\u306e\u3053\u3068\u3092\u6307\u3057\u307e\u3059\u3002\u305d\u308c\u306b\u5bfe\u3057 word \u306f\u4e00\u3064\u4e00\u3064\u306e\u5358\u8a9e\u306e\u3053\u3068\u3092\u6307\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070document 1\u3067\u306fterm\u306f\"Chinese\"\u3068\"Beijing\"\u306e\uff12\u3064\u3067\u3059\u304c\u3001word\u306f\uff13\u3064\u3067\u3059\u3002  p(t|c) \u306f\"\u305d\u306e\u30af\u30e9\u30b9\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308bt\u306e\u7dcf\u6570\"\u00f7\"\u305d\u306e\u30af\u30e9\u30b9\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u542b\u307e\u308c\u308b\u7dcf\u5358\u8a9e\u6570\"\u3067\u3059\u3002  p(Chinese|c) \u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\nChinese\u306fdocument 1,2,3\u5408\u308f\u305b\u30665\u3064\u542b\u307e\u308c\u3066\u3044\u307e\u3059\u3002document 1,2,3\u306e\u7dcf\u5358\u8a9e\u6570\u306f8\u306a\u306e\u3067    \\hat{p}(Chinese|c) = 5 / 8    \u3068\u306a\u308a\u307e\u3059\u3002  \u6700\u5f8c\u306b\u3053\u308c\u3089\u3092\u639b\u3051\u5408\u308f\u305b\u308b\u306e\u3067\u3059\u304c\u3001\u4e00\u3064\u554f\u984c\u304c\u3042\u308a\u307e\u3059\u3002training data\u306b\u4e00\u3064\u3082\u5165\u3063\u3066\u3044\u306a\u3044\u5358\u8a9e\u3060\u3068 p(t|c) = 0 / 8 = 0 \u306b\u306a\u3063\u3066\u3057\u307e\u3044\u5168\u4f53\u304c0\u306b\u306a\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u9632\u3050\u305f\u3081\u306b smoothing \u3068\u3046\u30c6\u30af\u30cb\u30c3\u30af\u3092\u4f7f\u3044\u307e\u3059\u3002smoothing\u306b\u306f\u5e7e\u3064\u304b\u7a2e\u985e\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u5168term\u306b1\u3092\u8db3\u3059 add-one smoothing \u304c\u6700\u3082\u30b7\u30f3\u30d7\u30eb\u306a\u65b9\u6cd5\u3067\u3059\u3002  \u3088\u3063\u3066 p(Chinese|c) \u306e\u5834\u5408\u3001\u5168\u4f53\u30676 terms(Chinese, Beijing, Shanghai, Macao, Tokyo, Japan)\u3042\u308b\u306e\u3067\u5206\u6bcd\u306b\uff16\u3092\u8db3\u3057\u3001\u5206\u5b50\u306b\uff11\u3092\u8db3\u3057\u307e\u3059\u3002    \\hat{p}(Chinese|c) = (5 + 1)  / (8 + 6) = 6 / 14 = 3/7    \u672c\u5f53\u306ftraining set\u306b\u51fa\u3066\u304f\u308b\u5168term\u306e p(t|c) \u3092 fit \u6642\u306b\u8a08\u7b97\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u4eca\u56de\u306ftest set\u304c\uff11\u3064\u3060\u3051\u306a\u306e\u3067\u305d\u308c\u306b\u542b\u307e\u308c\u3066\u308bterm\u306e\u5206\u3060\u3051\u8a08\u7b97\u3057\u307e\u3059\u3002   \u81ea\u5206\u3067\u78ba\u304b\u3081\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002  \u5f8c\u306fp258\u306e\u4ee5\u4e0b\u306e\u6570\u5f0f\u306b\u5f93\u3063\u3066\u3053\u308c\u3089\u3092\u304b\u3051\u3042\u308f\u305b\u307e\u3059\u3002   \"Chinese\"\u306fdocument 5\u306b\uff13\u3064\u542b\u307e\u308c\u3066\u308b\u306e\u3067\uff13\u4e57\u3057\u307e\u3059\u3002\u5148\u982d\u306bp(c)\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067\u6ce8\u610f\u3057\u307e\u3057\u3087\u3046\u3002   p(c|d5) \u306e\u65b9\u304c\u9ad8\u3044\u306e\u3067\u3001document 5\u306fyes\u3001\u3064\u307e\u308a\u4e2d\u56fd\u306b\u95a2\u3059\u308b\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3068\u4e88\u6e2c\u3057\u307e\u3059\u3002  \u4e0a\u306e\u7d50\u679c\u3092\u898b\u3066\u5206\u304b\u308b\u901a\u308a\u3001 p(c|d) \u306f\u3082\u306e\u51c4\u304f\u5c0f\u3055\u3044\u6570\u5024\u306b\u306a\u308a\u304c\u3061\u3067\u3059\u3002\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304c\u5927\u304d\u3044\u3068\u66f4\u306b\u3053\u308c\u304c\u5c0f\u3055\u304f\u306a\u308a\u3001floating point underflow\u304c\u8d77\u3053\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u9632\u3050\u70ba\u306b\u3001\u5b9f\u969b\u30b3\u30fc\u30c9\u3092\u66f8\u304f\u6642\u306flog\u3092\u4f7f\u3044\u307e\u3059\u3002\uff08P258\u53c2\u7167\uff09",
            "title": "p(t|c)"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercises",
            "text": "k-NN\u3068\u540c\u3058\u304f\u3001 scikit-learn\u306eMultinomialNB \u3068\u540c\u3058API\u306b\u3057\u307e\u3059\u3002  import numpy as np\n\nnp.set_printoptions(precision=6)\n\nclass MyMultinomialNB(object):\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        N = X.shape[0]\n        # group by class\n        separated = [X[np.where(y == i)[0]] for i in np.unique(y)]\n        return separated\n\nX = np.array([\n    [2,1,0,0,0,0],\n    [2,0,1,0,0,0],\n    [1,0,0,1,0,0],\n    [1,0,0,0,1,1]\n])\ny = np.array([0,0,0,1])\nnb = MyMultinomialNB().fit(X, y)\nprint(nb)  X\u306f\u4f8b\u306etraining set\u3092\u6570\u5024\u306b\u76f4\u3057\u305f\u3082\u306e\u3067\u3059\u3002\u5168\u90e8\u30676 term(Chinese, Beijing, Shanghai, Macao, Tokyo, Japan)\u542b\u307e\u308c\u3066\u3044\u308b\u306e\u3067dimension\u304c\uff16\u3042\u308a\u307e\u3059\u3002  y\u306f0\u304c\"yes\"\u30011\u3092\"no\"\u3068\u3057\u3066\u3044\u307e\u3059\u3002  __init__ \u306ealpha\u306fsmoothing\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u3059\u3002\u5f8c\u3067\u4f7f\u3046\u306e\u3067\u4eca\u306f\u7121\u8996\u3057\u3066\u5927\u4e08\u592b\u3067\u3059\u3002  fit \u3067\u306f\u307e\u305a\u30af\u30e9\u30b9\u6bce\u306b\u30c7\u30fc\u30bf\u3092\u5206\u3051\u307e\u3059\u3002 fit \u306f\u6700\u7d42\u7684\u306b\u306f self \u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308b\u306e\u3067\u3059\u304c\u3001\u4eca\u306f\u4e00\u65e6\u7121\u8996\u3057\u3066 separated \u3092\u30ea\u30bf\u30fc\u30f3\u3057\u3066\u3044\u307e\u3059\u3002  # output\n[array([[2, 1, 0, 0, 0, 0],\n       [2, 0, 1, 0, 0, 0],\n       [1, 0, 0, 1, 0, 0]]), array([[1, 0, 0, 0, 1, 1]])]",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-1",
            "text": "p(c) \u3092\u8a08\u7b97\u3057\u3066 self.class_log_prior_ \u306b\u30a2\u30b5\u30a4\u30f3\u3057\u3066\u4e0b\u3055\u3044\u3002\u305d\u306e\u969blog\u306b\u3059\u308b\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002\u666e\u901a\u306b\u8a08\u7b97\u3057\u305f\u5f8c\u305d\u308c\u305e\u308c\u306b np.log \u3092\u4f7f\u3046\u3060\u3051\u3067\u3059\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-2",
            "text": "\u6b21\u306b\u5404\u30af\u30e9\u30b9\u6bce\u306b\u305d\u308c\u305e\u308c\u306eterm\u3092\u30ab\u30a6\u30f3\u30c8\u3057\u307e\u3059\u3002 self.alpha \u3092smoothing\u3068\u3057\u3066\u8db3\u3059\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-3",
            "text": "\u6700\u5f8c\u306b p(t|c) \u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\u3053\u308c\u3082log\u306b\u3059\u308b\u306e\u3092\u5fd8\u308c\u306a\u3044\u3067\u4e0b\u3055\u3044\u3002\n\u3053\u308c\u3067 fit \u306f\u5b8c\u6210\u3067\u3059\u3002",
            "title": "Exercise 3"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-4",
            "text": "\u6b21\u306b predict_log_proba \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u3053\u308c\u306f p(c|d) \u306e\u3053\u3068\u3067\u3059\u3002 self.feature_log_prob_ \u3068 self.class_log_prior_ \u3092\u3053\u3053\u3067\u4f7f\u3044\u307e\u3059\u3002\nlog probability\u3092\u4f7f\u3063\u3066\u308b\u306e\u3067\u639b\u3051\u305a\u306b\u8db3\u3057\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 4"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-5",
            "text": "\u5148\u7a0b\u306e predict_log_proba \u3092\u4f7f\u3063\u3066\u4e00\u756a\u9ad8\u3044\u3082\u306e\u3092\u30ea\u30bf\u30fc\u30f3\u3057\u307e\u3059\u3002index\u304c\u30af\u30e9\u30b9\u306b\u306a\u3063\u3066\u308b\u306e\u3067index\u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308c\u3070OK\u3067\u3059\u3002",
            "title": "Exercise 5"
        },
        {
            "location": "/section1/unit3/naive_bayes/#bernoulli-naive-bayes",
            "text": "Bernoulli Naive Bayes\u306fMultinomial Naive Bayes\u3068\u9055\u3044\u5404term\u304c\u542b\u307e\u308c\u3066\u308b\u304b\u3060\u3051\u3092\u8003\u616e\u3057\u3001\u4f55\u56de\u542b\u307e\u308c\u3066\u308b\u304b\u306f\u7121\u8996\u3057\u307e\u3059\u3002\u5834\u5408\u306b\u3088\u3063\u3066\u306f\u3053\u3061\u3089\u306e\u65b9\u304c\u7cbe\u5ea6\u304c\u9ad8\u3044\u3067\u3059\u3002  Multinomial NB\u3067\u306ftest data\u306b\u542b\u307e\u308c\u308bterm\u306e p(t|c) \u3060\u3051\u4f7f\u3044\u307e\u3059\u304c\u3001Bernoulli NB\u306e\u5834\u5408\u306ftest data\u306b\u542b\u307e\u308c\u306a\u3044term\u3092 1 - p(t|c) \u3068\u3057\u3066\u4f7f\u3044\u307e\u3059\u3002",
            "title": "Bernoulli Naive Bayes"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercises_1",
            "text": "",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-6",
            "text": "count \u307e\u3067\u306fMultinomial Naive Bayes\u3068\u540c\u3058\u3067\u3059\u3002 denominator \u306f self.feature_prob \u306e\u5206\u6bcd\u306b\u3042\u305f\u308b\u90e8\u5206\u306a\u306e\u3067\u3053\u308c\u3092\u4f7f\u3063\u3066 self.feature_prob \u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002\u3053\u306e\u6bb5\u968e\u3067\u306flog\u306b\u3057\u307e\u305b\u3093\u3002  class MyBernoulliNB(object):\n    def __init__(self, alpha=1.0):\n        self.alpha = alpha\n\n    def fit(self, X, y):\n        N = X.shape[0]\n        # group by class\n        separated = [X[np.where(y == i)[0]] for i in np.unique(y)]\n        # class prior\n        self.class_log_prior_ = [np.log(len(i) / N) for i in separated]\n        # count of each word\n        count = np.array([np.array(i).sum(axis=0) for i in separated]) + self.alpha\n\n        # number of documents in each class\n        smoothing = 2 * self.alpha\n        denominator = np.array([len(i) + smoothing for i in separated])\n        # probability of each term\n        self.feature_prob_ = # Your code here\n                return self",
            "title": "Exercise 6"
        },
        {
            "location": "/section1/unit3/naive_bayes/#exercise-7",
            "text": "predict_log_proba \u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002 self.feature_prob_ \u306f\u3053\u3053\u3067log\u306b\u3057\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 7"
        },
        {
            "location": "/section1/unit3/naive_bayes/#binarize",
            "text": "\u3053\u308c\u307e\u3067\u306f\u30e2\u30c7\u30eb\u306e\u5916\u3067\u624b\u52d5\u3067\u30c7\u30fc\u30bf\u3092\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u3066\u3044\u307e\u3057\u305f\u304c\u3001\u30e2\u30c7\u30eb\u5185\u3067\u81ea\u52d5\u7684\u306b\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u3066\u304f\u308c\u305f\u65b9\u304c\u4fbf\u5229\u3067\u3059\u3088\u306d\u3002 scikit-learn\u306eBernoulliNB \u3067\u306f\u305d\u306e\u6a5f\u80fd\u304c\u4ed8\u3044\u3066\u3044\u307e\u3059\u3002 binarize \u3068\u3044\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u3067\u30b9\u30ec\u30c3\u30b7\u30e7\u30eb\u30c9\u3092\u8a2d\u5b9a\u3057\u3001\u81ea\u52d5\u7684\u306b\u30d0\u30a4\u30ca\u30ea\u30fc\u306b\u3057\u307e\u3059\u3002  # s10_binarize.py\n\ndef __init__(self, alpha=1.0, binarize=0.0):\n    self.alpha = alpha\n    self.binarize = binarize\n\ndef fit(self, X, y):\n    X = self._binarize_X(X)\n    ...\n\ndef predict_log_proba(self, X):\n    X = self._binarize_X(X)\n    ...\n\ndef _binarize_X(self, X):\n    return np.where(X > self.binarize, 1, 0) if self.binarize != None else X\n\nnb = MyBernoulliNB(alpha=1, binarize=0.0).fit(X, y)\nprint(nb.predict(X_test))",
            "title": "binarize"
        },
        {
            "location": "/section1/unit4/k-means/",
            "text": "\u4eca\u56de\u306fK-Means\u3068\u3044\u3046\u4e00\u756a\u30b7\u30f3\u30d7\u30eb\u3067\u6709\u540d\u306a\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u306e\u30e2\u30c7\u30eb\u3092\u52c9\u5f37\u3057\u307e\u3059\u3002\n\n\n\u4ee5\u4e0b\u306e\u30c7\u30fc\u30bf\u3092\uff12\u3064\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5206\u3051\u305f\u3044\u3068\u3057\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n\u307e\u305a\ncluster center\n(\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u4e2d\u5fc3\u5024)\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u6c7a\u3081\u307e\u3059\u3002\u4e00\u756a\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001X\u306e\u4e2d\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3076\u65b9\u6cd5\u3067\u3059\u3002\u3053\u306e\u5834\u5408\n(1,1)\n\u3068\n(1,2)\n\u3092\u9078\u3073\u307e\u3057\u305f\u3002X\u3068\u88ab\u3089\u306a\u3044\u3088\u3046\u306b\u5c11\u3057\u305a\u3089\u3057\u3066\u307e\u3059\u304c\u672c\u5f53\u306f\u540c\u3058\u5024\u3067\u3059\u3002\n\n\n\u6b21\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u30c7\u30fc\u30bf\u3067\u3069\u3063\u3061\u306ecluster center\u306b\u8fd1\u3044\u304b\u3092Euclidean Distance\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3057\u307e\u3059\u3002\u3053\u306e\u5834\u5408\n(1,1)\n\u4ee5\u5916\u306e\uff14\u3064\u306e\u30c7\u30fc\u30bf\u306f\u5168\u3066\n(1,2)\n\u306e\u65b9\u306b\u8fd1\u3044\u3067\u3059\u3002\n\n\n\n\n\u6b21\u306bcluster center\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3057\u307e\u3059\u3002\u65b9\u6cd5\u306f\u7c21\u5358\u3067\u3001\u305d\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5c5e\u3057\u3066\u308b\u30c7\u30fc\u30bf\u306e\u5e73\u5747\u5024\u3092\u53d6\u308a\u307e\u3059\u3002\n(1,1)\n\u306b\u95a2\u3057\u3066\u306f\u5c5e\u3057\u3066\u308b\u30c7\u30fc\u30bf\u304c\n(1,1)\n\u3057\u304b\u306a\u3044\u306e\u3067\u305d\u306e\u307e\u307e\u3067\u3059\u3002\n\n\n(1,2)\n\u306f\u5c5e\u3057\u3066\u308b\u30c7\u30fc\u30bf\u304c\uff14\u3064\u3042\u308a\u307e\u3059\u3002x\u8ef8\u3068y\u8ef8\u3067\u305d\u308c\u305e\u308c\u5e73\u5747\u3092\u53d6\u308b\u306e\u3067x\u8ef8\u306f\n\n\n\n\n \\frac{1+2+4+5}{4} = \\frac{12}{4} = 3 \n\n\n\n\ny\u8ef8\u306f\n\n\n\n\n \\frac{2+2+5+4}{4} = \\frac{13}{4} = 3.25 \n\n\n\n\n\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\u5f8c\u306f\u540c\u3058\u30b9\u30c6\u30c3\u30d7\u3092\u7e70\u308a\u8fd4\u3059\u3060\u3051\u3067\u3059\u3002cluster center\u304c\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3055\u308c\u305f\u306e\u3067\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u3082\u305d\u308c\u306b\u5fdc\u3058\u3066\u5909\u5316\u3057\u305f\u306e\u304c\u5206\u304b\u308a\u307e\u3059\u3002\n\n\n\n\n\u3053\u308c\u3092\u7e70\u308a\u8fd4\u3057\u3066\u3044\u304f\u3046\u3061\u306bcluster center\u306f\u3053\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\n\n\nExercises\n\n\n\u4eca\u56de\u3082\nscikit-learn\u306eK-Means\n\u3068\u540c\u3058API\u306b\u3057\u307e\u3059\u3002\n\n\nimport numpy as np\n\nclass MyKMeans(object):\n    def __init__(self, n_clusters=8, max_iter=300, random_state=None):\n        self.n_clusters = n_clusters\n        self.max_iter = max_iter\n        self.random_state = random_state\n        if self.random_state:\n            np.random.seed(self.random_state)\n\n\n\n\nExercise 1\n\n\n\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u521d\u671f\u5024\u3092n_clusters\u306e\u5206\u3060\u3051\u4f5c\u308a\u307e\u3059\u3002X\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3073\nself.cluster_centers_\n\u306b\u5165\u308c\u307e\u3057\u3087\u3046\u3002\n\n\nExercise 2\n\n\n\u6b21\u306bEuclidean Distance\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002k-NN\u306e\u6642\u306b\u66f8\u3044\u305f\u306e\u3067\u8a08\u7b97\u306e\u65b9\u6cd5\u306f\u5206\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u4eca\u56de\u306f\u30a4\u30f3\u30d7\u30c3\u30c8\u304c2d array(centers)\u30681d array(x)\u306a\u306e\u3067\u3001x\u3068\u305d\u308c\u305e\u308c\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u4e2d\u592e\u5024\u3068\u306eEuclidean Distance\u3092\u8a08\u7b97\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n\nnumpy\u306ebroadcasting\u3092\u4f7f\u3048\u3070\u30eb\u30fc\u30d7\u306a\u3057\u3067\u3044\u3051\u307e\u3059\u3002\n\n\nExercise 3\n\n\n\u6b21\u306b\u4e00\u756a\u8fd1\u3044\u30af\u30e9\u30b9\u30bf\u30fc\u306eindex\u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308b\u30e1\u30bd\u30c3\u30c9\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\n_distance\n\u3092\u4f7f\u3063\u3066\u4e0b\u3055\u3044\n\n\nExercise 4\n\n\n\u3084\u3063\u3068\u30e1\u30a4\u30f3\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u66f8\u3051\u307e\u3059\u3002\n_nearest\n\u3092\u4f7f\u3063\u3066x\u304c\u3069\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5c5e\u3059\u308b\u304b\u3092\u8a08\u7b97\u3057\nself.labels_\n\u306b\u5165\u308c\u3066\u3044\u307e\u3059\u3002\n\u3053\u308c\u3092\u4f7f\u3063\u3066X\u3092\u30af\u30e9\u30b9\u30bf\u30fc\u6bce\u306b\u5206\u3051\u307e\u3057\u3087\u3046\u3002\n\n\ndef fit(self, X):\n    initial = np.random.permutation(X.shape[0])[:self.n_clusters]\n    self.cluster_centers_ = X[initial]\n\n    for _ in range(self.max_iter):\n        self.labels_ = np.array([self._nearest(self.cluster_centers_, x) for x in X])\n        X_by_cluster = # your code here\n        return X_by_cluster\n\n\n\n\nExercise 5\n\n\nself.cluster_centers_\n\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3055\u305b\u307e\u3057\u3087\u3046\u3002\nX_by_cluster\n\u306e\u5e73\u5747\u5024\u3092\u53d6\u308a\u307e\u3059\u3002\n\n\nExercise 6\n\n\n\u5b66\u7fd2\u306b\u306f\u4e0d\u8981\u306a\u306e\u3067\u3059\u304c\u3001\u3069\u308c\u3060\u3051\u4e0a\u624b\u304f\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3055\u308c\u3066\u308b\u304b\u3092\u898b\u308b\u305f\u3081\u306b\ninertia\n\u3068\u3044\u3046\u6307\u6a19\u3092\u4f7f\u3044\u307e\u3059\u3002\ninertia\u306f\u305d\u308c\u305e\u308c\u306ecluster center\u3068\u305d\u308c\u306b\u5c5e\u3057\u3066\u308b\u30c7\u30fc\u30bf\u306e\nSquare Distance\n\u306e\u5408\u8a08\u3067\u3059\u3002Square Distance\u306fEuclidean Distance\u306e\u30eb\u30fc\u30c8\u3092\u53d6\u3089\u306a\u3044\u7248\u3067\u3059\u3002\n\n\n\u4f8b\u3048\u3070cluster center(1,2)\u3068x(3,4)\u306eSquare Distance\u306f\n\n\n\n\n (1-3)^2 + (2-4)^2 = 4 + 4 = 8 \n\n\n\n\n\u3067\u3059\u3002\n\n\nEarly Stopping\n\n\n\u5b9f\u969b\u306f\u4f55\u56de\u76ee\u3067cluster center\u304c\u52d5\u304b\u306a\u304f\u306a\u308b\u304b\u5206\u304b\u3089\u306a\u3044\u306e\u3067\u3001max_iter\u3092\u9069\u5f53\u306b\u9078\u3093\u3067\u3084\u308a\u307e\u3059\u3002\n\u30c7\u30fc\u30bf\u304c\u5c11\u306a\u3044\u5834\u5408\u306f\u3053\u308c\u3067\u3082\u826f\u3044\u3093\u3067\u3059\u304c\u3001\u30c7\u30fc\u30bf\u304c\u591a\u3044\u5834\u5408\u306f\u7121\u99c4\u306a\u5b66\u7fd2\u6642\u9593\u3092\u524a\u6e1b\u3057\u305f\u3044\u3067\u3059\u3002\u305d\u306e\u70ba\u306b\u306f\nself.inertia_\n\u304c\u307b\u3068\u3093\u3069\u5909\u5316\u3057\u306a\u304f\u306a\u3063\u305f\u3089\u30b9\u30c8\u30c3\u30d7\u3059\u308b\u3068\u3044\u3046\u65b9\u6cd5\u304c\u3042\u308a\u307e\u3059\u3002\nscikit-learn\u3067\u306f\ntolerance\n(tol)\u3068\u3044\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3042\u308a\u3001\u3069\u308c\u304f\u3089\u3044\u5909\u5316\u3057\u306a\u304f\u306a\u3063\u305f\u3089\u6b62\u3081\u308b\u304b\u3068\u3044\u3046\u306e\u3092\u3053\u3053\u3067\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u3067\u304c\u51fa\u6765\u307e\u3059\u3002\n\n\n\u3082\u3057\u4f59\u88d5\u304c\u3042\u308c\u3070\u66f8\u3044\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002\n\n\n\u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\n\n\n\u4f55\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5206\u3051\u305f\u3044\u3068\u3044\u3046\u306e\u304c\u6c7a\u307e\u3063\u3066\u308b\u5834\u5408\u306f\u554f\u984c\u306a\u3044\u306e\u3067\u3059\u304c\u3001\u591a\u304f\u306e\u5834\u5408\u306f\u5e7e\u3064\u306b\u5206\u3051\u305f\u3089\u3044\u3044\u304b\u5206\u304b\u3089\u306a\u3044\u3068\u3044\u3046\u306e\u304c\u666e\u901a\u3067\u3059\u3002\n\n\n\u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u898b\u3064\u3051\u308b\u4e00\u756a\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u5225\u306binertia\u3092\u898b\u3066inertia\u306e\u6e1b\u5c11\u304c\u8457\u3057\u3044\u3068\u3053\u308d\u3092\u9078\u3073\u307e\u3059\u3002\n\n\n\u4ee5\u4e0b\u306e\u4f8b\u3060\u3068\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u304c\uff13\u306e\u5834\u5408\uff12\u306e\u6642\u3088\u308a\u3082inertia\u304c\u5927\u5e45\u306b\u6e1b\u5c11\u3057\u3066\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u305d\u308c\u4ee5\u4e0a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u5897\u3084\u3057\u3066\u3082\u305d\u3053\u307e\u3067inertia\u304c\u6e1b\u5c11\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u306f\uff13\u3068\u8a00\u3048\u307e\u3059\u3002\n\n\n\n\n\u3082\u3063\u3068\u8907\u96d1\u306a\u30c6\u30af\u30cb\u30c3\u30af\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u3053\u308c\u3060\u3051\u77e5\u3063\u3066\u3044\u308c\u3070\u5341\u5206\u3067\u3057\u3087\u3046\u3002",
            "title": "K-Means Clustering"
        },
        {
            "location": "/section1/unit4/k-means/#exercises",
            "text": "\u4eca\u56de\u3082 scikit-learn\u306eK-Means \u3068\u540c\u3058API\u306b\u3057\u307e\u3059\u3002  import numpy as np\n\nclass MyKMeans(object):\n    def __init__(self, n_clusters=8, max_iter=300, random_state=None):\n        self.n_clusters = n_clusters\n        self.max_iter = max_iter\n        self.random_state = random_state\n        if self.random_state:\n            np.random.seed(self.random_state)",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-1",
            "text": "\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u521d\u671f\u5024\u3092n_clusters\u306e\u5206\u3060\u3051\u4f5c\u308a\u307e\u3059\u3002X\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3073 self.cluster_centers_ \u306b\u5165\u308c\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-2",
            "text": "\u6b21\u306bEuclidean Distance\u3092\u8a08\u7b97\u3057\u307e\u3059\u3002k-NN\u306e\u6642\u306b\u66f8\u3044\u305f\u306e\u3067\u8a08\u7b97\u306e\u65b9\u6cd5\u306f\u5206\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u4eca\u56de\u306f\u30a4\u30f3\u30d7\u30c3\u30c8\u304c2d array(centers)\u30681d array(x)\u306a\u306e\u3067\u3001x\u3068\u305d\u308c\u305e\u308c\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306e\u4e2d\u592e\u5024\u3068\u306eEuclidean Distance\u3092\u8a08\u7b97\u3057\u3066\u4e0b\u3055\u3044\u3002  numpy\u306ebroadcasting\u3092\u4f7f\u3048\u3070\u30eb\u30fc\u30d7\u306a\u3057\u3067\u3044\u3051\u307e\u3059\u3002",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-3",
            "text": "\u6b21\u306b\u4e00\u756a\u8fd1\u3044\u30af\u30e9\u30b9\u30bf\u30fc\u306eindex\u3092\u30ea\u30bf\u30fc\u30f3\u3059\u308b\u30e1\u30bd\u30c3\u30c9\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002 _distance \u3092\u4f7f\u3063\u3066\u4e0b\u3055\u3044",
            "title": "Exercise 3"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-4",
            "text": "\u3084\u3063\u3068\u30e1\u30a4\u30f3\u306e\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u304c\u66f8\u3051\u307e\u3059\u3002 _nearest \u3092\u4f7f\u3063\u3066x\u304c\u3069\u306e\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5c5e\u3059\u308b\u304b\u3092\u8a08\u7b97\u3057 self.labels_ \u306b\u5165\u308c\u3066\u3044\u307e\u3059\u3002\n\u3053\u308c\u3092\u4f7f\u3063\u3066X\u3092\u30af\u30e9\u30b9\u30bf\u30fc\u6bce\u306b\u5206\u3051\u307e\u3057\u3087\u3046\u3002  def fit(self, X):\n    initial = np.random.permutation(X.shape[0])[:self.n_clusters]\n    self.cluster_centers_ = X[initial]\n\n    for _ in range(self.max_iter):\n        self.labels_ = np.array([self._nearest(self.cluster_centers_, x) for x in X])\n        X_by_cluster = # your code here\n        return X_by_cluster",
            "title": "Exercise 4"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-5",
            "text": "self.cluster_centers_ \u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3055\u305b\u307e\u3057\u3087\u3046\u3002 X_by_cluster \u306e\u5e73\u5747\u5024\u3092\u53d6\u308a\u307e\u3059\u3002",
            "title": "Exercise 5"
        },
        {
            "location": "/section1/unit4/k-means/#exercise-6",
            "text": "\u5b66\u7fd2\u306b\u306f\u4e0d\u8981\u306a\u306e\u3067\u3059\u304c\u3001\u3069\u308c\u3060\u3051\u4e0a\u624b\u304f\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u3055\u308c\u3066\u308b\u304b\u3092\u898b\u308b\u305f\u3081\u306b inertia \u3068\u3044\u3046\u6307\u6a19\u3092\u4f7f\u3044\u307e\u3059\u3002\ninertia\u306f\u305d\u308c\u305e\u308c\u306ecluster center\u3068\u305d\u308c\u306b\u5c5e\u3057\u3066\u308b\u30c7\u30fc\u30bf\u306e Square Distance \u306e\u5408\u8a08\u3067\u3059\u3002Square Distance\u306fEuclidean Distance\u306e\u30eb\u30fc\u30c8\u3092\u53d6\u3089\u306a\u3044\u7248\u3067\u3059\u3002  \u4f8b\u3048\u3070cluster center(1,2)\u3068x(3,4)\u306eSquare Distance\u306f    (1-3)^2 + (2-4)^2 = 4 + 4 = 8    \u3067\u3059\u3002",
            "title": "Exercise 6"
        },
        {
            "location": "/section1/unit4/k-means/#early-stopping",
            "text": "\u5b9f\u969b\u306f\u4f55\u56de\u76ee\u3067cluster center\u304c\u52d5\u304b\u306a\u304f\u306a\u308b\u304b\u5206\u304b\u3089\u306a\u3044\u306e\u3067\u3001max_iter\u3092\u9069\u5f53\u306b\u9078\u3093\u3067\u3084\u308a\u307e\u3059\u3002\n\u30c7\u30fc\u30bf\u304c\u5c11\u306a\u3044\u5834\u5408\u306f\u3053\u308c\u3067\u3082\u826f\u3044\u3093\u3067\u3059\u304c\u3001\u30c7\u30fc\u30bf\u304c\u591a\u3044\u5834\u5408\u306f\u7121\u99c4\u306a\u5b66\u7fd2\u6642\u9593\u3092\u524a\u6e1b\u3057\u305f\u3044\u3067\u3059\u3002\u305d\u306e\u70ba\u306b\u306f self.inertia_ \u304c\u307b\u3068\u3093\u3069\u5909\u5316\u3057\u306a\u304f\u306a\u3063\u305f\u3089\u30b9\u30c8\u30c3\u30d7\u3059\u308b\u3068\u3044\u3046\u65b9\u6cd5\u304c\u3042\u308a\u307e\u3059\u3002\nscikit-learn\u3067\u306f tolerance (tol)\u3068\u3044\u3046\u30d1\u30e9\u30e1\u30fc\u30bf\u304c\u3042\u308a\u3001\u3069\u308c\u304f\u3089\u3044\u5909\u5316\u3057\u306a\u304f\u306a\u3063\u305f\u3089\u6b62\u3081\u308b\u304b\u3068\u3044\u3046\u306e\u3092\u3053\u3053\u3067\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u3067\u304c\u51fa\u6765\u307e\u3059\u3002  \u3082\u3057\u4f59\u88d5\u304c\u3042\u308c\u3070\u66f8\u3044\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Early Stopping"
        },
        {
            "location": "/section1/unit4/k-means/#_1",
            "text": "\u4f55\u30af\u30e9\u30b9\u30bf\u30fc\u306b\u5206\u3051\u305f\u3044\u3068\u3044\u3046\u306e\u304c\u6c7a\u307e\u3063\u3066\u308b\u5834\u5408\u306f\u554f\u984c\u306a\u3044\u306e\u3067\u3059\u304c\u3001\u591a\u304f\u306e\u5834\u5408\u306f\u5e7e\u3064\u306b\u5206\u3051\u305f\u3089\u3044\u3044\u304b\u5206\u304b\u3089\u306a\u3044\u3068\u3044\u3046\u306e\u304c\u666e\u901a\u3067\u3059\u3002  \u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u898b\u3064\u3051\u308b\u4e00\u756a\u7c21\u5358\u306a\u65b9\u6cd5\u306f\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u5225\u306binertia\u3092\u898b\u3066inertia\u306e\u6e1b\u5c11\u304c\u8457\u3057\u3044\u3068\u3053\u308d\u3092\u9078\u3073\u307e\u3059\u3002  \u4ee5\u4e0b\u306e\u4f8b\u3060\u3068\u3001\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u304c\uff13\u306e\u5834\u5408\uff12\u306e\u6642\u3088\u308a\u3082inertia\u304c\u5927\u5e45\u306b\u6e1b\u5c11\u3057\u3066\u3044\u307e\u3059\u3002\u3057\u304b\u3057\u305d\u308c\u4ee5\u4e0a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u3092\u5897\u3084\u3057\u3066\u3082\u305d\u3053\u307e\u3067inertia\u304c\u6e1b\u5c11\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570\u306f\uff13\u3068\u8a00\u3048\u307e\u3059\u3002   \u3082\u3063\u3068\u8907\u96d1\u306a\u30c6\u30af\u30cb\u30c3\u30af\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u3053\u308c\u3060\u3051\u77e5\u3063\u3066\u3044\u308c\u3070\u5341\u5206\u3067\u3057\u3087\u3046\u3002",
            "title": "\u6700\u9069\u306a\u30af\u30e9\u30b9\u30bf\u30fc\u6570"
        },
        {
            "location": "/section1/unit5/linear_regression/",
            "text": "Linear Regression\u306fSupervised Learning\u3067\u3059\u304c\u3001k-NN\u3084Naive Bayes\u304c\u30af\u30e9\u30b9\u3092\u4e88\u6e2c\u3059\u308bClassification\u306a\u306e\u306b\u5bfe\u3057\u3001Linear Regression\u306f\u6570\u5024\u3092\u4e88\u6e2c\u3059\u308bRegression\u306b\u306a\u308a\u307e\u3059\u3002\u4e0d\u52d5\u7523\u306e\u4fa1\u683c\u4e88\u6e2c\u3084\u682a\u5f0f\u5e02\u5834\u306e\u4e88\u6e2c\u304cRegression\u306b\u5f53\u305f\u308a\u307e\u3059\u3002\n\n\nLinear Regression\u3067\u306fOptimization(\u6700\u9069\u5316)\u3092\u4f7f\u3046\u306e\u3067\u3001\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306e\u7a2e\u985e\u3068\u3057\u3066\u306fLogistic Regression\u3084Neural Network\u3068\u540c\u3058\u3067\u3059\u3002Deep Learning\u3092\u5b66\u3076\u4e0a\u3067\u306e\u571f\u53f0\u3068\u306a\u308b\u7406\u8ad6\u304c\u8a70\u307e\u3063\u3066\u3044\u307e\u3059\u3002\n\n\nOptimization\u306b\u306f\u5fae\u5206\u7a4d\u5206\u3092\u4f7f\u3046\u306e\u3067\u4eca\u307e\u3067\u3088\u308a\u6025\u6fc0\u306b\u96e3\u3057\u304f\u306a\u308a\u307e\u3059\u3002\n\n\nLinear Regression\u306e\u8aac\u660e\n\n\nAndrew Ng\u306eLecture notes1\n\u304c\u975e\u5e38\u306b\u5206\u304b\u308a\u6613\u3044\u306e\u3067\u3001\u305d\u308c\u3092\u5143\u306b\u8aac\u660e\u3057\u307e\u3059\u3002\n\n\nLinear Regression\u306f\u7dda\u5f62\u95a2\u6570\u3092\u4f7f\u3063\u3066\u30a4\u30f3\u30d7\u30c3\u30c8(x)\u304b\u3089\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8(y)\u3092\u6982\u7b97\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070\u4e0d\u52d5\u7523\u306e\u4fa1\u683c\u4e88\u6e2c\u3067\u3042\u308c\u3070\u30a4\u30f3\u30d7\u30c3\u30c8\u304c\u5c02\u6709\u9762\u7a4d\u3084\u9593\u53d6\u308a\u3001\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u304c\u4fa1\u683c\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\u4ee5\u4e0b\u306e\u7c21\u5358\u306a\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u8aac\u660e\u3057\u3066\u3044\u304d\u307e\u3059\u3002x\u306e\u7279\u5fb4\u306f\u5e7e\u3064\u3042\u3063\u3066\u3082\u826f\u3044\u306e\u3067\u3059\u304c\u3001\u30b0\u30e9\u30d5\u3067\u8aac\u660e\u3059\u308b\u305f\u3081\u3053\u306e\u30c7\u30fc\u30bf\u306ex\u306e\u7279\u5fb4\u306f\u4e00\u3064\u3060\u3051\u3067\u3059\u3002\n\n\n\n\n\n\n\n\nx\n\n\ny\n\n\n\n\n\n\n\n\n\n\n0\n\n\n-1\n\n\n\n\n\n\n1\n\n\n1\n\n\n\n\n\n\n2\n\n\n3\n\n\n\n\n\n\n3\n\n\n5\n\n\n\n\n\n\n\n\n\n\ny\u3092\u6982\u7b97\u3059\u308b\u7dda\u5f62\u95a2\u6570\u3092\u6c42\u3081\u308d\u3068\u4eba\u9593\u304c\u8a00\u308f\u308c\u305f\u3089\u76f4\u611f\u7684\u306b\u5206\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\n\n\n\u3053\u306e\u3088\u3046\u306b\u30b0\u30e9\u30d5\u306b\u3059\u308b\u3068\u5168\u3066\u306e\u30c7\u30fc\u30bf\u304c\u76f4\u7dda\u72b6\u306b\u4e26\u3093\u3067\u3044\u307e\u3059\u3002\u666e\u901a\u306e\u30c7\u30fc\u30bf\u3053\u3093\u306a\u306b\u30af\u30ea\u30fc\u30f3\u3067\u306f\u306a\u3044\u3067\u3059\u304c\u3001\u8aac\u660e\u3057\u6613\u3044\u306e\u3067\u7c21\u5358\u306a\u30c7\u30fc\u30bf\u3092\u9078\u3073\u307e\u3057\u305f\u3002\n\n\n\u8a08\u7b97\u3059\u308b\u3068\u5206\u304b\u308b\u901a\u308a\u3001\u3053\u306e\u7dda\u5f62\u95a2\u6570\u306f\n\n\n\n\n y = 2x - 1 \n\n\n\n\n\u3067\u3059\u3002\n\n\n\u3053\u308c\u3092\u6570\u5f0f\u306b\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\ny\n\u3068\nh(x)\n\u306f\u540c\u3058\u610f\u5473\u3067\u3059\u3002\nn\n\u306f\u7279\u5fb4\u306e\u6570\u3067\u3059\u3002\n\n\n\n\n h(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_nx_n \n\n\n\n\n\u4eca\u56de\u306e\u4f8b\u3067\u306fx\u306e\u7279\u5fb4\u304c\u4e00\u3064\u3057\u304b\u306a\u3044\u306e\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002\n\n\n\n\n h(x) = \\theta_0 + \\theta_1x_1 \n\n\n\n\n\n\n\\theta_0 = -1\n, \n\\theta_1 = 2\n\u3067\u3059\u3002\n\n\n\u3053\u306e\u6570\u5f0f\u306fdot product\u3067\u8868\u305b\u308b\u306e\u3067\u3059\u304c\u3001\u305d\u306e\u70ba\u306b\u306f\n\\theta\n\u3068\nx\n\u3092\u540c\u3058\u9577\u3055\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\n\\theta_0\n\u306f\u30a4\u30f3\u30bf\u30fc\u30bb\u30d7\u30c8\u306a\u306e\u3067\u3001\nx_0 = 1\n\u306b\u3057\u307e\u3059\u3002\n\n\n\n\n\n\\begin{align}\nh(x) & = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_nx_n \\\\\n          &=  \\displaystyle\\sum_{i=0}^{n} \\theta_ix_i  \\\\\n           &= \\theta^Tx\n\\end{align}\n\n\n\n\n\n\n\nx_1 = 3\n\u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n\n\\begin{align}\nh(x) &=  \\theta^Tx \\\\\n&= \n\\begin{bmatrix}\n-1 & 2\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n1 \\\\ 3\n\\end{bmatrix} \\\\\n&= -1 \\cdot 1 + 2 \\cdot 3 \\\\\n&= 5\n\\end{align}\n\n\n\n\n\nx\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3067\u3059\u304c\u3001\u5168\u30b5\u30f3\u30d7\u30eb(X)\u3092\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u305f\u65b9\u304c\u697d\u306a\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u6570\u5f0f\u3092\u4f7f\u3044\u307e\u3059\u3002m\u3092\u30b5\u30f3\u30d7\u30eb\u6570\u3068\u3059\u308b\u3068X\u304c\nm \\times n\n, \n\\theta\n\u304c\nn \\times 1\n\u306a\u306e\u3067\nh(X)\n\u304c\nm \\times 1\n\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\n\n h(X) = X\\theta \n\n\n\n\n\u4f8b\u306e\u30c7\u30fc\u30bf\u3092\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n \n\\begin{align} h(X) &= X\\theta \\\\ \n&= \\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n1 & 2 \\\\\n1 & 3 \\\\\n\\end{bmatrix} \n\\cdot \n\\begin{bmatrix}-1 \\\\ 2\n\\end{bmatrix} \\\\ \n&= \n\\begin{bmatrix}\n-1 \\\\ 1 \\\\ 3 \\\\ 5\n\\end{bmatrix}\n\\end{align}\n\n\n\n\n\n\u4e0a\u8a18\u306f\u6700\u9069\u306a\n\\theta\n\u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3057\u305f\u3082\u306e\u3067\u3059\u304c\u3001\u76ee\u7684\u306f\u3053\u306e\n\\theta\n\u3092\u898b\u3064\u3051\u308b\u3053\u3068\u3067\u3059\u3002\u305d\u306e\u70ba\u306b\u306f\u307e\u305a\n\\theta\n\u3092\u9069\u5f53\u306b\u9078\u3073\u3001\nh(x)\n\u304c\ny\n\u3068\u3069\u308c\u3060\u3051\u9055\u3046\u304b\u306b\u5fdc\u3058\u3066\n\\theta\n\u3092\u4fee\u6b63\u3057\u3066\u3044\u304d\u307e\u3059\u3002\n\n\nAndrew Ng\u306eLecture notes1\u306e4\u30da\u30fc\u30b8\n\u306b\u6700\u9069\u5316\u306e\u8aac\u660e\u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\u5fae\u5206\u7a4d\u5206\u304c\u95a2\u308f\u308b\u90e8\u5206\u306a\u306e\u3067\u3053\u3053\u3067\u306e\u8aac\u660e\u306f\u5272\u611b\u3057\u307e\u3059\u3002\n\\theta\n\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3059\u308b\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n\n\n\n\n \\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X \n\n\n\n\n\n\n\\alpha\n\u306f\nlearning rate\n\u3068\u547c\u3070\u308c\u308b\u3082\u306e\u3067\u3001\u3069\u308c\u3060\u3051\u65e9\u304f\u6700\u9069\u5316\u3059\u308b\u304b\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u3053\u308c\u304c\u5c0f\u3055\u3059\u304e\u308b\u3068\u5b66\u7fd2\u304c\u9045\u304f\u3001\u5927\u304d\u3059\u304e\u308b\u3068converge(\u53ce\u675f)\u3057\u306a\u304f\u306a\u308a\u307e\u3059\u3002\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\u5b9f\u969b\u306b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u884c\u3059\u308b\u3068\u7406\u89e3\u51fa\u6765\u308b\u3068\u601d\u3044\u307e\u3059\u3002\n\n\nm\u3067\u5272\u308b\u7406\u7531\u306f\u3001\u30b5\u30f3\u30d7\u30eb\u6570\u306b\u3088\u308b\u30a8\u30e9\u30fc\u5024\u306e\u9055\u3044\u3092\u7121\u304f\u3059\u305f\u3081\u3067\u3059\u3002m\u304c\u306a\u3044\u3068\u30b5\u30f3\u30d7\u30eb\u6570\u306b\u5fdc\u3058\u3066\n\\alpha\n\u3092\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u5927\u5909\u3067\u3059\u3002\n\n\nExercises\n\n\n\u3067\u306f\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002\n\neta\n\u306flearning rate\u306e\u3053\u3068\u3067\u3059\u3002\nfit\n\u3067\u306f\u307e\u305a\nx_0\n\u3092\u8db3\u3057\u307e\u3059\u3002\n\n\nclass MyLinearRegression(object):\n    def __init__(self, eta=0.1, n_iter=50):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        return X\n\nX = np.array([[0], [1], [2], [3]])\ny = np.array([-1, 1, 3, 5])\nregr = MyLinearRegression()\nprint(regr.fit(X, y))\n\n\n\n\n[[1 0]\n [1 1]\n [1 2]\n [1 3]]\n\n\n\n\nExercise 1\n\n\n\n\nh(X) = X\\theta\n\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\n\n\nExercise 2\n\n\n\n\n\\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X\n\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\nm\n\u3068\nself.eta\n\u3092\u4f7f\u3063\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 3\n\n\npredict\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002Exercise1\u3068\u307b\u3068\u3093\u3069\u540c\u3058\u3067\u3059\u3002\n\n\nExercise 4\n\n\nLinear Regression\u306f\u5b8c\u6210\u3057\u305f\u3093\u3067\u3059\u304c\u3001\u4e00\u3064\u554f\u984c\u304c\u3042\u308a\u307e\u3059\u3002\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u591a\u3044\u3068\u8a08\u7b97\u3059\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u5b66\u7fd2\u304c\u9045\u3044\u3067\u3059\u3002\nStochastic Gradient Descent\n(SGD)\u306f\u3053\u308c\u3092\u89e3\u6c7a\u3059\u308b\u70ba\u306b\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u8a08\u7b97\u3057\u305d\u306e\u90fd\u5ea6weight\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3057\u307e\u3059\u3002SGD\u306e\u6b20\u70b9\u306f\u30a8\u30e9\u30fc\u306e\u6700\u5c0f\u5024\u306bconverge\u306b\u3057\u306a\u3044\u3053\u3068\u3067\u3059\u304c\u3001\u5b9f\u969b\u306f\u305d\u3053\u307e\u3067\u5927\u304d\u306a\u554f\u984c\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002\n\n\nweight\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u306a\u306e\u3067m\u306f\u3082\u3046\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002\n\n\nDiabetes Dataset\n\n\nDiabetes Dataset\n\u3092\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u3002\u7279\u5fb4\u304c\uff11\uff10\u500b\u3042\u308a\u307e\u3059\u304c\u3001\u8996\u899a\u5316\u3057\u305f\u3044\u306e\u3067\uff11\u3064\u3060\u3051\u4f7f\u3046\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\u662f\u975e\u8272\u3093\u306a\u7279\u5fb4\u3067\u8a66\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Linear Regression"
        },
        {
            "location": "/section1/unit5/linear_regression/#linear-regression",
            "text": "Andrew Ng\u306eLecture notes1 \u304c\u975e\u5e38\u306b\u5206\u304b\u308a\u6613\u3044\u306e\u3067\u3001\u305d\u308c\u3092\u5143\u306b\u8aac\u660e\u3057\u307e\u3059\u3002  Linear Regression\u306f\u7dda\u5f62\u95a2\u6570\u3092\u4f7f\u3063\u3066\u30a4\u30f3\u30d7\u30c3\u30c8(x)\u304b\u3089\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8(y)\u3092\u6982\u7b97\u3057\u307e\u3059\u3002\u4f8b\u3048\u3070\u4e0d\u52d5\u7523\u306e\u4fa1\u683c\u4e88\u6e2c\u3067\u3042\u308c\u3070\u30a4\u30f3\u30d7\u30c3\u30c8\u304c\u5c02\u6709\u9762\u7a4d\u3084\u9593\u53d6\u308a\u3001\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u304c\u4fa1\u683c\u3068\u306a\u308a\u307e\u3059\u3002  \u4ee5\u4e0b\u306e\u7c21\u5358\u306a\u30c7\u30fc\u30bf\u3092\u4f7f\u3063\u3066\u8aac\u660e\u3057\u3066\u3044\u304d\u307e\u3059\u3002x\u306e\u7279\u5fb4\u306f\u5e7e\u3064\u3042\u3063\u3066\u3082\u826f\u3044\u306e\u3067\u3059\u304c\u3001\u30b0\u30e9\u30d5\u3067\u8aac\u660e\u3059\u308b\u305f\u3081\u3053\u306e\u30c7\u30fc\u30bf\u306ex\u306e\u7279\u5fb4\u306f\u4e00\u3064\u3060\u3051\u3067\u3059\u3002     x  y      0  -1    1  1    2  3    3  5      y\u3092\u6982\u7b97\u3059\u308b\u7dda\u5f62\u95a2\u6570\u3092\u6c42\u3081\u308d\u3068\u4eba\u9593\u304c\u8a00\u308f\u308c\u305f\u3089\u76f4\u611f\u7684\u306b\u5206\u304b\u308b\u3068\u601d\u3044\u307e\u3059\u3002   \u3053\u306e\u3088\u3046\u306b\u30b0\u30e9\u30d5\u306b\u3059\u308b\u3068\u5168\u3066\u306e\u30c7\u30fc\u30bf\u304c\u76f4\u7dda\u72b6\u306b\u4e26\u3093\u3067\u3044\u307e\u3059\u3002\u666e\u901a\u306e\u30c7\u30fc\u30bf\u3053\u3093\u306a\u306b\u30af\u30ea\u30fc\u30f3\u3067\u306f\u306a\u3044\u3067\u3059\u304c\u3001\u8aac\u660e\u3057\u6613\u3044\u306e\u3067\u7c21\u5358\u306a\u30c7\u30fc\u30bf\u3092\u9078\u3073\u307e\u3057\u305f\u3002  \u8a08\u7b97\u3059\u308b\u3068\u5206\u304b\u308b\u901a\u308a\u3001\u3053\u306e\u7dda\u5f62\u95a2\u6570\u306f    y = 2x - 1    \u3067\u3059\u3002  \u3053\u308c\u3092\u6570\u5f0f\u306b\u3059\u308b\u3068\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 y \u3068 h(x) \u306f\u540c\u3058\u610f\u5473\u3067\u3059\u3002 n \u306f\u7279\u5fb4\u306e\u6570\u3067\u3059\u3002    h(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_nx_n    \u4eca\u56de\u306e\u4f8b\u3067\u306fx\u306e\u7279\u5fb4\u304c\u4e00\u3064\u3057\u304b\u306a\u3044\u306e\u3067\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002    h(x) = \\theta_0 + \\theta_1x_1     \\theta_0 = -1 ,  \\theta_1 = 2 \u3067\u3059\u3002  \u3053\u306e\u6570\u5f0f\u306fdot product\u3067\u8868\u305b\u308b\u306e\u3067\u3059\u304c\u3001\u305d\u306e\u70ba\u306b\u306f \\theta \u3068 x \u3092\u540c\u3058\u9577\u3055\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002 \\theta_0 \u306f\u30a4\u30f3\u30bf\u30fc\u30bb\u30d7\u30c8\u306a\u306e\u3067\u3001 x_0 = 1 \u306b\u3057\u307e\u3059\u3002   \n\\begin{align}\nh(x) & = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_nx_n \\\\\n          &=  \\displaystyle\\sum_{i=0}^{n} \\theta_ix_i  \\\\\n           &= \\theta^Tx\n\\end{align}    x_1 = 3 \u3092\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002   \n\\begin{align}\nh(x) &=  \\theta^Tx \\\\\n&= \n\\begin{bmatrix}\n-1 & 2\n\\end{bmatrix}\n\\cdot\n\\begin{bmatrix}\n1 \\\\ 3\n\\end{bmatrix} \\\\\n&= -1 \\cdot 1 + 2 \\cdot 3 \\\\\n&= 5\n\\end{align}   x\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3067\u3059\u304c\u3001\u5168\u30b5\u30f3\u30d7\u30eb(X)\u3092\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u305f\u65b9\u304c\u697d\u306a\u306e\u3067\u3001\u4ee5\u4e0b\u306e\u6570\u5f0f\u3092\u4f7f\u3044\u307e\u3059\u3002m\u3092\u30b5\u30f3\u30d7\u30eb\u6570\u3068\u3059\u308b\u3068X\u304c m \\times n ,  \\theta \u304c n \\times 1 \u306a\u306e\u3067 h(X) \u304c m \\times 1 \u3068\u306a\u308a\u307e\u3059\u3002    h(X) = X\\theta    \u4f8b\u306e\u30c7\u30fc\u30bf\u3092\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002    \n\\begin{align} h(X) &= X\\theta \\\\ \n&= \\begin{bmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n1 & 2 \\\\\n1 & 3 \\\\\n\\end{bmatrix} \n\\cdot \n\\begin{bmatrix}-1 \\\\ 2\n\\end{bmatrix} \\\\ \n&= \n\\begin{bmatrix}\n-1 \\\\ 1 \\\\ 3 \\\\ 5\n\\end{bmatrix}\n\\end{align}   \u4e0a\u8a18\u306f\u6700\u9069\u306a \\theta \u3092\u4f7f\u3063\u3066\u8a08\u7b97\u3057\u305f\u3082\u306e\u3067\u3059\u304c\u3001\u76ee\u7684\u306f\u3053\u306e \\theta \u3092\u898b\u3064\u3051\u308b\u3053\u3068\u3067\u3059\u3002\u305d\u306e\u70ba\u306b\u306f\u307e\u305a \\theta \u3092\u9069\u5f53\u306b\u9078\u3073\u3001 h(x) \u304c y \u3068\u3069\u308c\u3060\u3051\u9055\u3046\u304b\u306b\u5fdc\u3058\u3066 \\theta \u3092\u4fee\u6b63\u3057\u3066\u3044\u304d\u307e\u3059\u3002  Andrew Ng\u306eLecture notes1\u306e4\u30da\u30fc\u30b8 \u306b\u6700\u9069\u5316\u306e\u8aac\u660e\u304c\u66f8\u304b\u308c\u3066\u3044\u307e\u3059\u3002\u5fae\u5206\u7a4d\u5206\u304c\u95a2\u308f\u308b\u90e8\u5206\u306a\u306e\u3067\u3053\u3053\u3067\u306e\u8aac\u660e\u306f\u5272\u611b\u3057\u307e\u3059\u3002 \\theta \u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3059\u308b\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002    \\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X     \\alpha \u306f learning rate \u3068\u547c\u3070\u308c\u308b\u3082\u306e\u3067\u3001\u3069\u308c\u3060\u3051\u65e9\u304f\u6700\u9069\u5316\u3059\u308b\u304b\u3092\u8a2d\u5b9a\u3057\u307e\u3059\u3002\u3053\u308c\u304c\u5c0f\u3055\u3059\u304e\u308b\u3068\u5b66\u7fd2\u304c\u9045\u304f\u3001\u5927\u304d\u3059\u304e\u308b\u3068converge(\u53ce\u675f)\u3057\u306a\u304f\u306a\u308a\u307e\u3059\u3002\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\u5b9f\u969b\u306b\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u884c\u3059\u308b\u3068\u7406\u89e3\u51fa\u6765\u308b\u3068\u601d\u3044\u307e\u3059\u3002  m\u3067\u5272\u308b\u7406\u7531\u306f\u3001\u30b5\u30f3\u30d7\u30eb\u6570\u306b\u3088\u308b\u30a8\u30e9\u30fc\u5024\u306e\u9055\u3044\u3092\u7121\u304f\u3059\u305f\u3081\u3067\u3059\u3002m\u304c\u306a\u3044\u3068\u30b5\u30f3\u30d7\u30eb\u6570\u306b\u5fdc\u3058\u3066 \\alpha \u3092\u5fae\u8abf\u6574\u3059\u308b\u3053\u3068\u306b\u306a\u308a\u5927\u5909\u3067\u3059\u3002",
            "title": "Linear Regression\u306e\u8aac\u660e"
        },
        {
            "location": "/section1/unit5/linear_regression/#exercises",
            "text": "\u3067\u306f\u30b3\u30fc\u30c9\u3092\u66f8\u3044\u3066\u3044\u304d\u307e\u3057\u3087\u3046\u3002 eta \u306flearning rate\u306e\u3053\u3068\u3067\u3059\u3002 fit \u3067\u306f\u307e\u305a x_0 \u3092\u8db3\u3057\u307e\u3059\u3002  class MyLinearRegression(object):\n    def __init__(self, eta=0.1, n_iter=50):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        return X\n\nX = np.array([[0], [1], [2], [3]])\ny = np.array([-1, 1, 3, 5])\nregr = MyLinearRegression()\nprint(regr.fit(X, y))  [[1 0]\n [1 1]\n [1 2]\n [1 3]]",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit5/linear_regression/#exercise-1",
            "text": "h(X) = X\\theta \u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit5/linear_regression/#exercise-2",
            "text": "\\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X \u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002 m \u3068 self.eta \u3092\u4f7f\u3063\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit5/linear_regression/#exercise-3",
            "text": "predict \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002Exercise1\u3068\u307b\u3068\u3093\u3069\u540c\u3058\u3067\u3059\u3002",
            "title": "Exercise 3"
        },
        {
            "location": "/section1/unit5/linear_regression/#exercise-4",
            "text": "Linear Regression\u306f\u5b8c\u6210\u3057\u305f\u3093\u3067\u3059\u304c\u3001\u4e00\u3064\u554f\u984c\u304c\u3042\u308a\u307e\u3059\u3002\u30b5\u30f3\u30d7\u30eb\u6570\u304c\u591a\u3044\u3068\u8a08\u7b97\u3059\u308b\u306e\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u5b66\u7fd2\u304c\u9045\u3044\u3067\u3059\u3002 Stochastic Gradient Descent (SGD)\u306f\u3053\u308c\u3092\u89e3\u6c7a\u3059\u308b\u70ba\u306b\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u8a08\u7b97\u3057\u305d\u306e\u90fd\u5ea6weight\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3057\u307e\u3059\u3002SGD\u306e\u6b20\u70b9\u306f\u30a8\u30e9\u30fc\u306e\u6700\u5c0f\u5024\u306bconverge\u306b\u3057\u306a\u3044\u3053\u3068\u3067\u3059\u304c\u3001\u5b9f\u969b\u306f\u305d\u3053\u307e\u3067\u5927\u304d\u306a\u554f\u984c\u3067\u306f\u3042\u308a\u307e\u305b\u3093\u3002  weight\u3092\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u3059\u308b\u30b3\u30fc\u30c9\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u306a\u306e\u3067m\u306f\u3082\u3046\u5fc5\u8981\u3042\u308a\u307e\u305b\u3093\u3002",
            "title": "Exercise 4"
        },
        {
            "location": "/section1/unit5/linear_regression/#diabetes-dataset",
            "text": "Diabetes Dataset \u3092\u4f7f\u3063\u3066\u307f\u307e\u3057\u305f\u3002\u7279\u5fb4\u304c\uff11\uff10\u500b\u3042\u308a\u307e\u3059\u304c\u3001\u8996\u899a\u5316\u3057\u305f\u3044\u306e\u3067\uff11\u3064\u3060\u3051\u4f7f\u3046\u3053\u3068\u306b\u3057\u307e\u3057\u305f\u3002\u662f\u975e\u8272\u3093\u306a\u7279\u5fb4\u3067\u8a66\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Diabetes Dataset"
        },
        {
            "location": "/section1/unit6/logistic_regression/",
            "text": "Logistic Regression\u306fClassification\u306e\u30e2\u30c7\u30eb\u3067\u3059\u3002Linear Regression\u3068\u975e\u5e38\u306b\u4f3c\u3066\u3044\u307e\u3059\u3002\n\n\nLogistic Regression\u306e\u8aac\u660e\n\n\n\u307e\u305a\u306fBinary Classification\uff08\uff12\u30af\u30e9\u30b9\uff09\u5c02\u7528\u306eLogistic Regression\u306e\u8aac\u660e\u3092\u3057\u307e\u3059\u3002\n\n__init__\n\u3068\nfit\n\u306e\u59cb\u3081\u306fLinear Regression\u3068\u5168\u304f\u540c\u3058\u30b3\u30fc\u30c9\u3067\u3059\u3002\n\n\n# s1_initial_code.py\n\nclass MyLogisticRegression(object):\n    def __init__(self, eta=0.1, n_iter=50):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.ones(X.shape[1])\n        m = X.shape[0]\n        return self\n\n\n\n\nLinear Regression\u3068\u540c\u3058\npredict\n\u3092\u4f7f\u3046\u3068\u3069\u3046\u306a\u308b\u3067\u3057\u3087\u3046\u304b\u3002\n\n\n    def predict(self, X):\n        return np.insert(X, 0, 1, axis=1).dot(self.w)\n\nX = np.array([[-2, 2],[-3, 0],[2, -1],[1, -4]])\ny = np.array([1,1,0,0])\nlogi = MyLogisticRegression().fit(X, y)\nprint(logi.predict(X))\n\n\n\n\n[ 1. -2.  2. -2.]\n\n\n\n\n\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306f\uff10\u304b\uff11\u3067\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u306e\u3067\u3001\u3053\u306e\u307e\u307e\u3067\u306f\u30c0\u30e1\u3067\u3059\u3088\u306d\u3002\u3053\u308c\u3092\u89e3\u6c7a\u3059\u308b\u70ba\u306b\nsigmoid function\n\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\n\n\n g(x) = \\frac{1}{1 + e^{-x}} \n\n\n\n\n\n\nsigmoid function\u306fx\u304c\n\\infty\n\u306b\u8fd1\u3065\u304f\u306b\u3064\u308c1\u306b\u8fd1\u3065\u304d\u3001\n-\\infty\n\u306b\u8fd1\u3065\u304f\u306b\u3064\u308c0\u306b\u8fd1\u3065\u304d\u307e\u3059\u3002\u3064\u307e\u308a\u3069\u3093\u306a\u5024\u30820~1\u306e\u9593\u306b\u53ce\u307e\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u78ba\u7387\u3068\u6349\u3048\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002\u3088\u3063\u3066\ng(x) >= 0.5\n\u306e\u5834\u5408\u306f1\u3001\ng(x) < 0.5\n\u306e\u5834\u5408\u306f0\u3068\u3057\u307e\u3059\u3002\n\n\n\u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u306e\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002Linear Regression\u3068\u5168\u304f\u540c\u3058\u306b\u898b\u3048\u307e\u3059\u3002\n\n\n\n\n \\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X \n\n\n\n\n\u3057\u304b\u3057Linear Regression\u3067\u306f\nh(x) = X\\theta\n\u306a\u306e\u306b\u5bfe\u3057\u3001Logistic Regression\u3067\u306f\nh(x) = g(X\\theta)\n\u3067\u3059\u3002Linear Regression\u3067\u306f\nh(x) = X\\theta\n\u304c\u3069\u308c\u3060\u3051\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5024\u3068\u305a\u308c\u3066\u3044\u308b\u304b\u304c\u30a8\u30e9\u30fc\u3067\u3057\u305f\u3002Logistic Regression\u3067\u306f\nh(x) = g(X\\theta)\n\u3001\u3064\u307e\u308aSigmoid\u3092\u901a\u3057\u305f\u5024\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3069\u308c\u3060\u3051\u305a\u308c\u3066\u3044\u308b\u304b\u3092\u30a8\u30e9\u30fc\u3068\u3057\u307e\u3059\u3002\n\n\n\u4f8b\u3048\u3070\u3001\nh(x)\n\u304c0.7\u3067\u30bf\u30fc\u30b2\u30c3\u30c8\u304c1\u3060\u3068\u3059\u308b\u3068\u3001\u30a8\u30e9\u30fc\u304c\n|1 - 0.7| = 0.3\n\u3042\u308b\u306e\u3067\u3001\u3053\u308c\u3092\u9811\u5f35\u3063\u30660\u306b\u3057\u3088\u3046\u3068\u3057\u307e\u3059\u3002\npredict\n\u3067\u306f0.5\u4ee5\u4e0a\u3042\u308c\u30701\u3068\u3059\u308b\u306e\u30670.7\u3092\u3053\u308c\u4ee5\u4e0a1\u306b\u8fd1\u3065\u3051\u306a\u304f\u3066\u3082\u7cbe\u5ea6\u306b\u306f\u5909\u308f\u3089\u306a\u3044\u3093\u3067\u3059\u304c\u3001\u6700\u9069\u5316\u306e\u969b\u306f\u7cbe\u5ea6\u306f\u5168\u304f\u6c17\u306b\u305b\u305a\u30a8\u30e9\u30fc\u3092\u5c11\u306a\u304f\u3057\u3088\u3046\u3068\u3057\u307e\u3059\u3002\n\n\nExercises\n\n\nExercise 1\n\n\nSigmoid function\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n g(x) = \\frac{1}{1 + e^{-x}} \n\n\n\n\n\u30a4\u30f3\u30d7\u30c3\u30c8\u304carray\u306a\u306e\u3067\u3001\u30eb\u30fc\u30d7\u3092\u4f7f\u308f\u305anumpy\u3067\u4e00\u6c17\u306b\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\n\n\nExercise 2\n\n\npredict\n\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002\ng(x) >= 0.5\n\u306e\u5834\u5408\u306f1\u3001\ng(x) < 0.5\n\u306e\u5834\u5408\u306f0\u3067\u3059\u3002\n\n\nExercise3\n\n\n\u6700\u5f8c\u306b\nfit\n\u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002Linear Regression\u3092\u53c2\u7167\u3059\u308c\u3070\u554f\u984c\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002\n_sigmoid\n\u3092\u5fd8\u308c\u305a\u306b\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002\n\n\nOne vs Rest\u3092\u4f7f\u3063\u305fMulticlass Classification\n\n\n\u4e0a\u8a18\u306fBinary Classification\u306b\u3057\u304b\u4f7f\u3046\u3053\u3068\u304c\u51fa\u6765\u307e\u305b\u3093\u3002Logistic Regression\u3067\u8907\u6570\u306e\u30af\u30e9\u30b9\u3092\u6271\u3046\u65b9\u6cd5\u306f\uff12\u3064\u3042\u308a\u307e\u3059\u3002\u4e00\u3064\u306f\"One vs Rest\"\u3068\u3044\u3046\u624b\u6cd5\u3067\u3059\u3002\u3053\u308c\u306fLogistic Regression\u306b\u9650\u3089\u305a\u3069\u3093\u306a\u30e2\u30c7\u30eb\u306b\u3082\u4f7f\u3046\u3053\u3068\u304c\u51fa\u6765\u307e\u3059\u3002\n\n\n\u65b9\u6cd5\u306f\u30b7\u30f3\u30d7\u30eb\u3067\u3001\u30af\u30e9\u30b9\u304c\uff13\u3064\u3042\u3063\u305f\u3089\uff13\u3064\u306eBinary Classifier\u3092\u4f5c\u308a\u307e\u3059\u3002\uff11\u3064\u76ee\u3067\u306f0\u306e\u30af\u30e9\u30b9\u30921\u3068\u3057\u3001\u305d\u308c\u4ee5\u5916\u306e\u30af\u30e9\u30b9\u30920\u306b\u3057\u307e\u3059\u3002\uff12\u3064\u76ee\u3001\uff13\u3064\u76ee\u3067\u3082\u540c\u3058\u6d41\u308c\u3067\u64ec\u4f3c\u7684\u306b\u30af\u30e9\u30b9\u30920\u30681\u306e\uff12\u3064\u3060\u3051\u306b\u3057\u307e\u3059\u3002\n\n\n\n\n\n\n\n\nClassifier \\ \u30af\u30e9\u30b9\n\n\n0\n\n\n1\n\n\n2\n\n\n\n\n\n\n\n\n\n\n\uff11\u3064\u76ee\n\n\n1\n\n\n0\n\n\n0\n\n\n\n\n\n\n\uff12\u3064\u76ee\n\n\n0\n\n\n1\n\n\n0\n\n\n\n\n\n\n\uff13\u3064\u76ee\n\n\n0\n\n\n0\n\n\n1\n\n\n\n\n\n\n\n\n# s5_exercise4.py\n\nclass LogisticRegressionOVR(object):\n    \"\"\"One vs Rest\"\"\"\n\n    def __init__(self, num_classes, eta=0.1, n_iter=50):\n        self.num_classes = num_classes\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.zeros((X.shape[1], self.num_classes))\n        m = X.shape[0]\n\n        for i in range(self.num_classes):\n            # y\u30921\u30680\u3060\u3051\u306b\u3059\u308b\n            y_copy = np.where(y == i, 1, 0)\n            w = np.ones(X.shape[1])\n\n            for j in range(self.n_iter):\n                output = X.dot(w)\n                errors = y_copy - self._sigmoid(output)\n                w += self.eta / m * errors.dot(X)\n\n                if j % 10 == 0:\n                    print(sum(errors**2))\n            self.w[:, i] = w\n\n        return self\n\n\n\n\n\u305d\u3057\u3066\npredict\n\u306e\u6642\u306b\uff13\u3064\u306eBinary Classifier\u3092\u5b9f\u884c\u3057\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u304c\u4e00\u756a\u9ad8\u3044\u3082\u306e\u3092\u63a1\u7528\u3057\u307e\u3059\u3002\n\n\nExercises\n\n\nExercise 4\n\n\npredict\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002matrix multiplication\u3068\nnp.argmax\n\u3092\u4f7f\u3048\u3070\u30eb\u30fc\u30d7\u3092\u5168\u304f\u4f7f\u308f\u305a\u306b\u66f8\u3051\u307e\u3059\u3002\n\n\nSoftmax\u3092\u4f7f\u3063\u305fMulticlass Classification\n\n\nOne vs Rest\u306f\u30af\u30e9\u30b9\u306e\u6570\u3060\u3051Binary Classifier\u3092\u5b66\u7fd2\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u305f\u3081\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002\u3088\u3063\u3066\u5b9f\u969bLogistic Regression\u3084Neural Network\u3067Multiclass Classification\u3092\u3059\u308b\u5834\u5408\u306f\u307b\u307c\u78ba\u5b9f\u306b\nSoftmax\n\u3068\u3044\u3046\u3082\u306e\u3092\u4f7f\u3044\u307e\u3059\u3002\n\n\nSoftmax\u3092\u8aac\u660e\u3059\u308b\u524d\u306bOne vs Rest\u3068\u5171\u901a\u3059\u308b\u30b3\u30fc\u30c9\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u52ff\u8ad6\nfit\n\u306f\u307e\u3060\u9014\u4e2d\u3067\u3059\u3002\n\n\n#s6_softmax_initial_code.py\n\nclass LogisticRegressionSoftmax(object):\n    def __init__(self, num_classes, eta=0.1, n_iter=50):\n        self.num_classes = num_classes\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.random.randn(X.shape[1], self.num_classes)\n        m = X.shape[0]\n        return self\n\n    def predict(self, X):\n        X = np.insert(X, 0, 1, axis=1)\n        return np.argmax(X.dot(self.w), axis=1)\n\niris = datasets.load_iris()\n\nx_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.4)\nlogi = LogisticRegressionSoftmax(len(np.unique(iris.target)), n_iter=500)\nlogi.fit(x_train, y_train)\nprint(logi.w.shape)\nprint(logi.predict(x_test[:2]))\n\n\n\n\nself.w\n\u306e\u30b5\u30a4\u30ba\u306fOne vs Rest\u3068\u540c\u3058\u304f(5, 3)\u3067\u3059\u3002weight\u306e\u521d\u671f\u5024\u306b\nnp.random.randn\n\u3092\u4f7f\u3063\u3066\u307e\u3059\u304c\u3001\nnp.zeros\n\u3067\u3082\nnp.ones\n\u3067\u3082\u69cb\u3044\u307e\u305b\u3093\u3002\u521d\u671f\u5024\u306b\u3088\u3063\u3066\u6700\u9069\u5316\u306e\u901f\u5ea6\u304c\u5909\u308f\u3063\u305f\u308a\u3057\u307e\u3059\u304c\u3001\u4eca\u306f\u305d\u3053\u307e\u3067\u6c17\u306b\u3057\u306a\u304f\u3066\u5927\u4e08\u592b\u3067\u3059\u3002\n\n\n(5, 3)\n[0 0]\n\n\n\n\n\u4ee5\u4e0b\u304c\nfit\n\u306e\u5b8c\u6210\u5f62\u3067\u3059\u3002\nX.dot(self.w)\n\u306e\u30b5\u30a4\u30ba\u306f(m, \u30af\u30e9\u30b9\u6570)\u3067\u3059\u3002\u3053\u308c\u306bsoftmax\u3092\u5f53\u3066\u3001\u5404\u30af\u30e9\u30b9\u306e\u78ba\u7387\u3092\u51fa\u3057\u307e\u3059\u3002\n\n\n# s7_exercise5.py\n\ndef fit(self, X, y):\n    X = np.insert(X, 0, 1, axis=1)\n    y = self._one_hot(y)\n    self.w = np.random.randn(X.shape[1], self.num_classes)\n    m = X.shape[0]\n\n    for i in range(self.n_iter):\n        output = self._softmax(X.dot(self.w))\n        errors = y - output\n        self.w += self.eta / m * X.T.dot(errors)\n\n        if i % 10 == 0:\n            print(self._cross_entropy(y, output))\n    return self\n\n\n\n\n\u4ee5\u4e0b\u304cSoftmax\u306e\u516c\u5f0f\u3067\u3059\u3002\n\n\n\n\n \\sigma(\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}} \n\n\n\n\n\u3053\u308c\u3092Sigmoid\u3068\u540c\u3058\u3088\u3046\u306b\u7dda\u5f62\u95a2\u6570\nX.dot(self.w)\n\u306e\u5f8c\u306b\u4f7f\u3044\u307e\u3059\u3002Sigmoid\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u304c\u6570\u5b57\u306a\u306e\u306b\u5bfe\u3057\u3001Softmax\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u306farray\u306b\u306a\u308a\u307e\u3059\uff08\u30b3\u30fc\u30c9\u3067\u306f\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u5ea6\u306b\u8a08\u7b97\u3059\u308b\u306e\u3067Sigmoid\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u3082array\u3067\u3059\u304c\u3001\u3053\u3053\u3067\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3067\u306e\u8a71\u3067\u3059\uff09\u3002\n\n\n\u5f0f\u3060\u3051\u898b\u3066\u3082\u30d4\u30f3\u3068\u6765\u306a\u3044\u3068\u601d\u3046\u306e\u3067\u5b9f\u969b\u306b\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\u4f8b\u3048\u3070\nX.dot(self.w)\n\u306e\uff11\u30b5\u30f3\u30d7\u30eb\u304c\n[2,1,-3]\n\u3060\u3068\u3057\u307e\u3059\u3002\n\n\n\u307e\u305a\u305d\u308c\u305e\u308c\u306e\u5206\u5b50\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002\n\n\n\n\n\n\\begin{align}\ne^2 &= 7.389 \\\\\ne^1 &= 2.718 \\\\\ne^{-3}&= 0.0498\n\\end{align}\n\n\n\n\n\n\u5206\u6bcd\u306f\u3053\u308c\u3089\u306e\u5408\u8a08\u3067\u3059\u3002\n\n\n\n\n 7.389 + 2.718 + 0.0498 = 10.157 \n\n\n\n\n\u305d\u3057\u3066\u305d\u308c\u305e\u308c\u3092\u3053\u306e\u5408\u8a08\u3067\u5272\u308c\u3070\u5b8c\u6210\u3067\u3059\u3002\n\n\n\n\n [7.389, 2.718, 0.0498] / 10.157 = [0.727,0.268,0.005] \n\n\n\n\nSoftmax\u306e\u5024\u306f\u5408\u8a08\u3059\u308b\u30681\u306b\u306a\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\u3002\u3064\u307e\u308a\u3053\u308c\u306f\u5404\u30af\u30e9\u30b9\u306e\u78ba\u7387\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u3082\u8a00\u3048\u307e\u3059\u3002\u300c72.7\uff05\u306e\u78ba\u7387\u3067\u30af\u30e9\u30b9\uff10\u3060\u308d\u3046\u300d\u3068\u3044\u3046\u3053\u3068\u3067\u3059\u306d\u3002\n\n\n\n\n 0.727 + 0.268 + 0.005 = 1 \n\n\n\n\n\u3053\u308c\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5dee\u5206\u3092\u7e2e\u3081\u3066\u3044\u304f\u306e\u3067\u3059\u304c\u3001\u305d\u306eloss function\u306b\u306f\ncross entropy\n\u3092\u4f7f\u3044\u307e\u3059\u3002p\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3001q\u304csoftmax\u5f8c\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u3068\u3059\u308b\u3068cross entropy\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002\n\n\n\n\n H(p, q) = -\\sum_x p(x)\\, \\log q(x) \n\n\n\n\nq\u304carray\u306a\u306e\u3067\u3001p\u3082array\u306b\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u305d\u306e\u70ba\u306b\none hot encoding\n\u3068\u3044\u3046\u624b\u6bb5\u3092\u4f7f\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070\u30af\u30e9\u30b9\u304c\u5168\u90e8\u3067\uff13\u3064\u3042\u308b\u3068\u3057\u3001\u30af\u30e9\u30b9\u304c0\u306e\u5834\u5408\u306f\n[1,0,0]\n\u3001\u30af\u30e9\u30b9\u304c2\u306e\u5834\u5408\u306f\n[0,0,1]\n\u3068\u306a\u308a\u307e\u3059\u3002\n\n\n\u3067\u306f\u4e0a\u8a18\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u304c0\u3060\u3068\u3059\u308b\u3068\u3001\np = [1,0,0]\n, \nq =[0.727,0.268,0.005] \n\u3068\u306a\u308b\u306e\u3067cross entropy\u306f\n\n\n\n\n\n\\begin{align}\n H(p,q) &= - (1 \\times log(0.727) + 0  \\times log(0.268) + 0 \\times log(0.005)) \\\\\n&= -(1 \\times -0.3188 + 0 + 0) \\\\\n&= 0.3188\n\\end{align}\n\n\n\n\n\n\n\np = [0,1,0]\n,  \np = [0,0,1]\n\u306e\u5834\u5408\u3082\u8a08\u7b97\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002\np\n\u3068\nq\n\u304c\u8fd1\u3044\u307b\u3069cross entropy\u306f\u5c0f\u3055\u304f\u306a\u308a\u307e\u3059\u3002\u306a\u306e\u3067\np = [1,0,0]\n\u306e\u6642\u304c\u4e00\u756a\u5c0f\u3055\u304f\u306a\u308b\u306f\u305a\u3067\u3059\u3002\n\n\nExercises\n\n\nfit\n\u306e\u90e8\u5206\u306f\u5fae\u5206\u7a4d\u5206\u3092\u8981\u3059\u308b\u3068\u3053\u308d\u3067\u3059\u3057Sigmoid\u306e\u6642\u3068\u307b\u3068\u3093\u3069\u5909\u308f\u3089\u306a\u3044\u306e\u3067\u4eca\u56de\u306f\u65e2\u306b\u5b8c\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002\n\n\nExercise 5\n\n\n_one_hot\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u30a4\u30f3\u30d7\u30c3\u30c8\u304carray\u306a\u306e\u3067\u5404\u6570\u5b57\u6bce\u306bone_hot_encoding\u3092\u4f5c\u3063\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 6\n\n\nsoftmax\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u307e\u305a\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u8a08\u7b97\u3057\u307e\u3059\u3002\nx\u304c\u5927\u304d\u3044\u3068\u6307\u6570\u304c\u7269\u51c4\u304f\u306a\u3063\u3066\u3057\u307e\u3044overflow\u3057\u3066\u3057\u307e\u3046\u3067\u3001\u5b9f\u969b\u306bsoftmax\u3092\u4f7f\u3046\u6642\u306f\nx -= np.max(x)\n\u3068\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066overflow\u3092\u9632\u304e\u307e\u3059\u3002\n\n\nExercise 7\n\n\n\u6b21\u306b\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u6c17\u306b\u8a08\u7b97\u3059\u308bsoftmax\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002overflow\u306e\u5bfe\u51e6\u3082\u66f8\u3044\u3066\u4e0b\u3055\u3044\u3002\n\n\nExercise 8\n\n\n_cross_entropy\n\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u3066\u4e0b\u3055\u3044\u3002\n\n\nReference\n\n\nSoftmax\u3068cross entropy\u306e\u8aac\u660e\u304c\u5206\u304b\u308a\u6613\u3044\u3067\u3059\u3002\nhttp://cs231n.github.io/linear-classify/#softmax",
            "title": "Logistic Regression"
        },
        {
            "location": "/section1/unit6/logistic_regression/#logistic-regression",
            "text": "\u307e\u305a\u306fBinary Classification\uff08\uff12\u30af\u30e9\u30b9\uff09\u5c02\u7528\u306eLogistic Regression\u306e\u8aac\u660e\u3092\u3057\u307e\u3059\u3002 __init__ \u3068 fit \u306e\u59cb\u3081\u306fLinear Regression\u3068\u5168\u304f\u540c\u3058\u30b3\u30fc\u30c9\u3067\u3059\u3002  # s1_initial_code.py\n\nclass MyLogisticRegression(object):\n    def __init__(self, eta=0.1, n_iter=50):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.ones(X.shape[1])\n        m = X.shape[0]\n        return self  Linear Regression\u3068\u540c\u3058 predict \u3092\u4f7f\u3046\u3068\u3069\u3046\u306a\u308b\u3067\u3057\u3087\u3046\u304b\u3002      def predict(self, X):\n        return np.insert(X, 0, 1, axis=1).dot(self.w)\n\nX = np.array([[-2, 2],[-3, 0],[2, -1],[1, -4]])\ny = np.array([1,1,0,0])\nlogi = MyLogisticRegression().fit(X, y)\nprint(logi.predict(X))  [ 1. -2.  2. -2.]  \u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306f\uff10\u304b\uff11\u3067\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\u306e\u3067\u3001\u3053\u306e\u307e\u307e\u3067\u306f\u30c0\u30e1\u3067\u3059\u3088\u306d\u3002\u3053\u308c\u3092\u89e3\u6c7a\u3059\u308b\u70ba\u306b sigmoid function \u3092\u4f7f\u3044\u307e\u3059\u3002    g(x) = \\frac{1}{1 + e^{-x}}     sigmoid function\u306fx\u304c \\infty \u306b\u8fd1\u3065\u304f\u306b\u3064\u308c1\u306b\u8fd1\u3065\u304d\u3001 -\\infty \u306b\u8fd1\u3065\u304f\u306b\u3064\u308c0\u306b\u8fd1\u3065\u304d\u307e\u3059\u3002\u3064\u307e\u308a\u3069\u3093\u306a\u5024\u30820~1\u306e\u9593\u306b\u53ce\u307e\u308a\u307e\u3059\u3002\u3053\u308c\u3092\u78ba\u7387\u3068\u6349\u3048\u308b\u3053\u3068\u3082\u51fa\u6765\u307e\u3059\u3002\u3088\u3063\u3066 g(x) >= 0.5 \u306e\u5834\u5408\u306f1\u3001 g(x) < 0.5 \u306e\u5834\u5408\u306f0\u3068\u3057\u307e\u3059\u3002  \u30a2\u30c3\u30d7\u30c7\u30fc\u30c8\u306e\u6570\u5f0f\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002Linear Regression\u3068\u5168\u304f\u540c\u3058\u306b\u898b\u3048\u307e\u3059\u3002    \\theta := \\theta + \\frac{\\alpha}{m} (y - h(x))X    \u3057\u304b\u3057Linear Regression\u3067\u306f h(x) = X\\theta \u306a\u306e\u306b\u5bfe\u3057\u3001Logistic Regression\u3067\u306f h(x) = g(X\\theta) \u3067\u3059\u3002Linear Regression\u3067\u306f h(x) = X\\theta \u304c\u3069\u308c\u3060\u3051\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5024\u3068\u305a\u308c\u3066\u3044\u308b\u304b\u304c\u30a8\u30e9\u30fc\u3067\u3057\u305f\u3002Logistic Regression\u3067\u306f h(x) = g(X\\theta) \u3001\u3064\u307e\u308aSigmoid\u3092\u901a\u3057\u305f\u5024\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u304c\u3069\u308c\u3060\u3051\u305a\u308c\u3066\u3044\u308b\u304b\u3092\u30a8\u30e9\u30fc\u3068\u3057\u307e\u3059\u3002  \u4f8b\u3048\u3070\u3001 h(x) \u304c0.7\u3067\u30bf\u30fc\u30b2\u30c3\u30c8\u304c1\u3060\u3068\u3059\u308b\u3068\u3001\u30a8\u30e9\u30fc\u304c |1 - 0.7| = 0.3 \u3042\u308b\u306e\u3067\u3001\u3053\u308c\u3092\u9811\u5f35\u3063\u30660\u306b\u3057\u3088\u3046\u3068\u3057\u307e\u3059\u3002 predict \u3067\u306f0.5\u4ee5\u4e0a\u3042\u308c\u30701\u3068\u3059\u308b\u306e\u30670.7\u3092\u3053\u308c\u4ee5\u4e0a1\u306b\u8fd1\u3065\u3051\u306a\u304f\u3066\u3082\u7cbe\u5ea6\u306b\u306f\u5909\u308f\u3089\u306a\u3044\u3093\u3067\u3059\u304c\u3001\u6700\u9069\u5316\u306e\u969b\u306f\u7cbe\u5ea6\u306f\u5168\u304f\u6c17\u306b\u305b\u305a\u30a8\u30e9\u30fc\u3092\u5c11\u306a\u304f\u3057\u3088\u3046\u3068\u3057\u307e\u3059\u3002",
            "title": "Logistic Regression\u306e\u8aac\u660e"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercises",
            "text": "",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-1",
            "text": "Sigmoid function\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002    g(x) = \\frac{1}{1 + e^{-x}}    \u30a4\u30f3\u30d7\u30c3\u30c8\u304carray\u306a\u306e\u3067\u3001\u30eb\u30fc\u30d7\u3092\u4f7f\u308f\u305anumpy\u3067\u4e00\u6c17\u306b\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise 1"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-2",
            "text": "predict \u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002 g(x) >= 0.5 \u306e\u5834\u5408\u306f1\u3001 g(x) < 0.5 \u306e\u5834\u5408\u306f0\u3067\u3059\u3002",
            "title": "Exercise 2"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise3",
            "text": "\u6700\u5f8c\u306b fit \u3092\u5b8c\u6210\u3055\u305b\u307e\u3057\u3087\u3046\u3002Linear Regression\u3092\u53c2\u7167\u3059\u308c\u3070\u554f\u984c\u306a\u3044\u3068\u601d\u3044\u307e\u3059\u3002 _sigmoid \u3092\u5fd8\u308c\u305a\u306b\u4f7f\u3044\u307e\u3057\u3087\u3046\u3002",
            "title": "Exercise3"
        },
        {
            "location": "/section1/unit6/logistic_regression/#one-vs-restmulticlass-classification",
            "text": "\u4e0a\u8a18\u306fBinary Classification\u306b\u3057\u304b\u4f7f\u3046\u3053\u3068\u304c\u51fa\u6765\u307e\u305b\u3093\u3002Logistic Regression\u3067\u8907\u6570\u306e\u30af\u30e9\u30b9\u3092\u6271\u3046\u65b9\u6cd5\u306f\uff12\u3064\u3042\u308a\u307e\u3059\u3002\u4e00\u3064\u306f\"One vs Rest\"\u3068\u3044\u3046\u624b\u6cd5\u3067\u3059\u3002\u3053\u308c\u306fLogistic Regression\u306b\u9650\u3089\u305a\u3069\u3093\u306a\u30e2\u30c7\u30eb\u306b\u3082\u4f7f\u3046\u3053\u3068\u304c\u51fa\u6765\u307e\u3059\u3002  \u65b9\u6cd5\u306f\u30b7\u30f3\u30d7\u30eb\u3067\u3001\u30af\u30e9\u30b9\u304c\uff13\u3064\u3042\u3063\u305f\u3089\uff13\u3064\u306eBinary Classifier\u3092\u4f5c\u308a\u307e\u3059\u3002\uff11\u3064\u76ee\u3067\u306f0\u306e\u30af\u30e9\u30b9\u30921\u3068\u3057\u3001\u305d\u308c\u4ee5\u5916\u306e\u30af\u30e9\u30b9\u30920\u306b\u3057\u307e\u3059\u3002\uff12\u3064\u76ee\u3001\uff13\u3064\u76ee\u3067\u3082\u540c\u3058\u6d41\u308c\u3067\u64ec\u4f3c\u7684\u306b\u30af\u30e9\u30b9\u30920\u30681\u306e\uff12\u3064\u3060\u3051\u306b\u3057\u307e\u3059\u3002     Classifier \\ \u30af\u30e9\u30b9  0  1  2      \uff11\u3064\u76ee  1  0  0    \uff12\u3064\u76ee  0  1  0    \uff13\u3064\u76ee  0  0  1     # s5_exercise4.py\n\nclass LogisticRegressionOVR(object):\n    \"\"\"One vs Rest\"\"\"\n\n    def __init__(self, num_classes, eta=0.1, n_iter=50):\n        self.num_classes = num_classes\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.zeros((X.shape[1], self.num_classes))\n        m = X.shape[0]\n\n        for i in range(self.num_classes):\n            # y\u30921\u30680\u3060\u3051\u306b\u3059\u308b\n            y_copy = np.where(y == i, 1, 0)\n            w = np.ones(X.shape[1])\n\n            for j in range(self.n_iter):\n                output = X.dot(w)\n                errors = y_copy - self._sigmoid(output)\n                w += self.eta / m * errors.dot(X)\n\n                if j % 10 == 0:\n                    print(sum(errors**2))\n            self.w[:, i] = w\n\n        return self  \u305d\u3057\u3066 predict \u306e\u6642\u306b\uff13\u3064\u306eBinary Classifier\u3092\u5b9f\u884c\u3057\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u304c\u4e00\u756a\u9ad8\u3044\u3082\u306e\u3092\u63a1\u7528\u3057\u307e\u3059\u3002",
            "title": "One vs Rest\u3092\u4f7f\u3063\u305fMulticlass Classification"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercises_1",
            "text": "",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-4",
            "text": "predict \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002matrix multiplication\u3068 np.argmax \u3092\u4f7f\u3048\u3070\u30eb\u30fc\u30d7\u3092\u5168\u304f\u4f7f\u308f\u305a\u306b\u66f8\u3051\u307e\u3059\u3002",
            "title": "Exercise 4"
        },
        {
            "location": "/section1/unit6/logistic_regression/#softmaxmulticlass-classification",
            "text": "One vs Rest\u306f\u30af\u30e9\u30b9\u306e\u6570\u3060\u3051Binary Classifier\u3092\u5b66\u7fd2\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u305f\u3081\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u3002\u3088\u3063\u3066\u5b9f\u969bLogistic Regression\u3084Neural Network\u3067Multiclass Classification\u3092\u3059\u308b\u5834\u5408\u306f\u307b\u307c\u78ba\u5b9f\u306b Softmax \u3068\u3044\u3046\u3082\u306e\u3092\u4f7f\u3044\u307e\u3059\u3002  Softmax\u3092\u8aac\u660e\u3059\u308b\u524d\u306bOne vs Rest\u3068\u5171\u901a\u3059\u308b\u30b3\u30fc\u30c9\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u52ff\u8ad6 fit \u306f\u307e\u3060\u9014\u4e2d\u3067\u3059\u3002  #s6_softmax_initial_code.py\n\nclass LogisticRegressionSoftmax(object):\n    def __init__(self, num_classes, eta=0.1, n_iter=50):\n        self.num_classes = num_classes\n        self.eta = eta\n        self.n_iter = n_iter\n\n    def fit(self, X, y):\n        X = np.insert(X, 0, 1, axis=1)\n        self.w = np.random.randn(X.shape[1], self.num_classes)\n        m = X.shape[0]\n        return self\n\n    def predict(self, X):\n        X = np.insert(X, 0, 1, axis=1)\n        return np.argmax(X.dot(self.w), axis=1)\n\niris = datasets.load_iris()\n\nx_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.4)\nlogi = LogisticRegressionSoftmax(len(np.unique(iris.target)), n_iter=500)\nlogi.fit(x_train, y_train)\nprint(logi.w.shape)\nprint(logi.predict(x_test[:2]))  self.w \u306e\u30b5\u30a4\u30ba\u306fOne vs Rest\u3068\u540c\u3058\u304f(5, 3)\u3067\u3059\u3002weight\u306e\u521d\u671f\u5024\u306b np.random.randn \u3092\u4f7f\u3063\u3066\u307e\u3059\u304c\u3001 np.zeros \u3067\u3082 np.ones \u3067\u3082\u69cb\u3044\u307e\u305b\u3093\u3002\u521d\u671f\u5024\u306b\u3088\u3063\u3066\u6700\u9069\u5316\u306e\u901f\u5ea6\u304c\u5909\u308f\u3063\u305f\u308a\u3057\u307e\u3059\u304c\u3001\u4eca\u306f\u305d\u3053\u307e\u3067\u6c17\u306b\u3057\u306a\u304f\u3066\u5927\u4e08\u592b\u3067\u3059\u3002  (5, 3)\n[0 0]  \u4ee5\u4e0b\u304c fit \u306e\u5b8c\u6210\u5f62\u3067\u3059\u3002 X.dot(self.w) \u306e\u30b5\u30a4\u30ba\u306f(m, \u30af\u30e9\u30b9\u6570)\u3067\u3059\u3002\u3053\u308c\u306bsoftmax\u3092\u5f53\u3066\u3001\u5404\u30af\u30e9\u30b9\u306e\u78ba\u7387\u3092\u51fa\u3057\u307e\u3059\u3002  # s7_exercise5.py\n\ndef fit(self, X, y):\n    X = np.insert(X, 0, 1, axis=1)\n    y = self._one_hot(y)\n    self.w = np.random.randn(X.shape[1], self.num_classes)\n    m = X.shape[0]\n\n    for i in range(self.n_iter):\n        output = self._softmax(X.dot(self.w))\n        errors = y - output\n        self.w += self.eta / m * X.T.dot(errors)\n\n        if i % 10 == 0:\n            print(self._cross_entropy(y, output))\n    return self  \u4ee5\u4e0b\u304cSoftmax\u306e\u516c\u5f0f\u3067\u3059\u3002    \\sigma(\\mathbf{z})_j = \\frac{e^{z_j}}{\\sum_{k=1}^K e^{z_k}}    \u3053\u308c\u3092Sigmoid\u3068\u540c\u3058\u3088\u3046\u306b\u7dda\u5f62\u95a2\u6570 X.dot(self.w) \u306e\u5f8c\u306b\u4f7f\u3044\u307e\u3059\u3002Sigmoid\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u304c\u6570\u5b57\u306a\u306e\u306b\u5bfe\u3057\u3001Softmax\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u306farray\u306b\u306a\u308a\u307e\u3059\uff08\u30b3\u30fc\u30c9\u3067\u306f\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u5ea6\u306b\u8a08\u7b97\u3059\u308b\u306e\u3067Sigmoid\u306e\u30a4\u30f3\u30d7\u30c3\u30c8\u3082array\u3067\u3059\u304c\u3001\u3053\u3053\u3067\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3067\u306e\u8a71\u3067\u3059\uff09\u3002  \u5f0f\u3060\u3051\u898b\u3066\u3082\u30d4\u30f3\u3068\u6765\u306a\u3044\u3068\u601d\u3046\u306e\u3067\u5b9f\u969b\u306b\u8a08\u7b97\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n\u4f8b\u3048\u3070 X.dot(self.w) \u306e\uff11\u30b5\u30f3\u30d7\u30eb\u304c [2,1,-3] \u3060\u3068\u3057\u307e\u3059\u3002  \u307e\u305a\u305d\u308c\u305e\u308c\u306e\u5206\u5b50\u3092\u8a08\u7b97\u3057\u307e\u3057\u3087\u3046\u3002   \n\\begin{align}\ne^2 &= 7.389 \\\\\ne^1 &= 2.718 \\\\\ne^{-3}&= 0.0498\n\\end{align}   \u5206\u6bcd\u306f\u3053\u308c\u3089\u306e\u5408\u8a08\u3067\u3059\u3002    7.389 + 2.718 + 0.0498 = 10.157    \u305d\u3057\u3066\u305d\u308c\u305e\u308c\u3092\u3053\u306e\u5408\u8a08\u3067\u5272\u308c\u3070\u5b8c\u6210\u3067\u3059\u3002    [7.389, 2.718, 0.0498] / 10.157 = [0.727,0.268,0.005]    Softmax\u306e\u5024\u306f\u5408\u8a08\u3059\u308b\u30681\u306b\u306a\u308b\u3053\u3068\u304c\u5206\u304b\u308a\u307e\u3059\u3002\u3064\u307e\u308a\u3053\u308c\u306f\u5404\u30af\u30e9\u30b9\u306e\u78ba\u7387\u3092\u8868\u3057\u3066\u3044\u308b\u3068\u3082\u8a00\u3048\u307e\u3059\u3002\u300c72.7\uff05\u306e\u78ba\u7387\u3067\u30af\u30e9\u30b9\uff10\u3060\u308d\u3046\u300d\u3068\u3044\u3046\u3053\u3068\u3067\u3059\u306d\u3002    0.727 + 0.268 + 0.005 = 1    \u3053\u308c\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\u306e\u5dee\u5206\u3092\u7e2e\u3081\u3066\u3044\u304f\u306e\u3067\u3059\u304c\u3001\u305d\u306eloss function\u306b\u306f cross entropy \u3092\u4f7f\u3044\u307e\u3059\u3002p\u304c\u30bf\u30fc\u30b2\u30c3\u30c8\u3001q\u304csoftmax\u5f8c\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u3068\u3059\u308b\u3068cross entropy\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3067\u3059\u3002    H(p, q) = -\\sum_x p(x)\\, \\log q(x)    q\u304carray\u306a\u306e\u3067\u3001p\u3082array\u306b\u3057\u306a\u3051\u308c\u3070\u306a\u308a\u307e\u305b\u3093\u3002\u305d\u306e\u70ba\u306b one hot encoding \u3068\u3044\u3046\u624b\u6bb5\u3092\u4f7f\u3044\u307e\u3059\u3002\u4f8b\u3048\u3070\u30af\u30e9\u30b9\u304c\u5168\u90e8\u3067\uff13\u3064\u3042\u308b\u3068\u3057\u3001\u30af\u30e9\u30b9\u304c0\u306e\u5834\u5408\u306f [1,0,0] \u3001\u30af\u30e9\u30b9\u304c2\u306e\u5834\u5408\u306f [0,0,1] \u3068\u306a\u308a\u307e\u3059\u3002  \u3067\u306f\u4e0a\u8a18\u306e\u30a2\u30a6\u30c8\u30d7\u30c3\u30c8\u306e\u30bf\u30fc\u30b2\u30c3\u30c8\u304c0\u3060\u3068\u3059\u308b\u3068\u3001 p = [1,0,0] ,  q =[0.727,0.268,0.005]  \u3068\u306a\u308b\u306e\u3067cross entropy\u306f   \n\\begin{align}\n H(p,q) &= - (1 \\times log(0.727) + 0  \\times log(0.268) + 0 \\times log(0.005)) \\\\\n&= -(1 \\times -0.3188 + 0 + 0) \\\\\n&= 0.3188\n\\end{align}    p = [0,1,0] ,   p = [0,0,1] \u306e\u5834\u5408\u3082\u8a08\u7b97\u3057\u3066\u307f\u3066\u4e0b\u3055\u3044\u3002 p \u3068 q \u304c\u8fd1\u3044\u307b\u3069cross entropy\u306f\u5c0f\u3055\u304f\u306a\u308a\u307e\u3059\u3002\u306a\u306e\u3067 p = [1,0,0] \u306e\u6642\u304c\u4e00\u756a\u5c0f\u3055\u304f\u306a\u308b\u306f\u305a\u3067\u3059\u3002",
            "title": "Softmax\u3092\u4f7f\u3063\u305fMulticlass Classification"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercises_2",
            "text": "fit \u306e\u90e8\u5206\u306f\u5fae\u5206\u7a4d\u5206\u3092\u8981\u3059\u308b\u3068\u3053\u308d\u3067\u3059\u3057Sigmoid\u306e\u6642\u3068\u307b\u3068\u3093\u3069\u5909\u308f\u3089\u306a\u3044\u306e\u3067\u4eca\u56de\u306f\u65e2\u306b\u5b8c\u6210\u3055\u308c\u3066\u3044\u307e\u3059\u3002",
            "title": "Exercises"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-5",
            "text": "_one_hot \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u30a4\u30f3\u30d7\u30c3\u30c8\u304carray\u306a\u306e\u3067\u5404\u6570\u5b57\u6bce\u306bone_hot_encoding\u3092\u4f5c\u3063\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 5"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-6",
            "text": "softmax\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u307e\u305a\u306f\uff11\u30b5\u30f3\u30d7\u30eb\u3065\u3064\u8a08\u7b97\u3057\u307e\u3059\u3002\nx\u304c\u5927\u304d\u3044\u3068\u6307\u6570\u304c\u7269\u51c4\u304f\u306a\u3063\u3066\u3057\u307e\u3044overflow\u3057\u3066\u3057\u307e\u3046\u3067\u3001\u5b9f\u969b\u306bsoftmax\u3092\u4f7f\u3046\u6642\u306f x -= np.max(x) \u3068\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066overflow\u3092\u9632\u304e\u307e\u3059\u3002",
            "title": "Exercise 6"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-7",
            "text": "\u6b21\u306b\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u6c17\u306b\u8a08\u7b97\u3059\u308bsoftmax\u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002overflow\u306e\u5bfe\u51e6\u3082\u66f8\u3044\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 7"
        },
        {
            "location": "/section1/unit6/logistic_regression/#exercise-8",
            "text": "_cross_entropy \u3092\u66f8\u304d\u307e\u3057\u3087\u3046\u3002\u5168\u30b5\u30f3\u30d7\u30eb\u4e00\u5ea6\u306b\u8a08\u7b97\u3057\u3066\u4e0b\u3055\u3044\u3002",
            "title": "Exercise 8"
        },
        {
            "location": "/section1/unit6/logistic_regression/#reference",
            "text": "Softmax\u3068cross entropy\u306e\u8aac\u660e\u304c\u5206\u304b\u308a\u6613\u3044\u3067\u3059\u3002\nhttp://cs231n.github.io/linear-classify/#softmax",
            "title": "Reference"
        }
    ]
}