<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <title>k-Nearest Neighbors - Machine Learning engineer Training Program</title>
  

  <link rel="shortcut icon" href="../../../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../../css/highlight.css">

  
  <script>
    // Current page data
    var mkdocs_page_name = "k-Nearest Neighbors";
    var mkdocs_page_input_path = "section1/unit1/k-nn.md";
    var mkdocs_page_url = "/section1/unit1/k-nn/";
  </script>
  
  <script src="../../../js/jquery-2.1.1.min.js"></script>
  <script src="../../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../../js/highlight.pack.js"></script>
  <script src="../../../js/theme.js"></script> 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../../.." class="icon icon-home"> Machine Learning engineer Training Program</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../../..">Home</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Traditional Machine Learning</span></li>

        
            
    <ul class="subnav">
    <li><span>Unit1</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../introduction/">Introduction</a>
        
    </li>

        
            
    <li class="toctree-l1 current">
        <a class="current" href="./">k-Nearest Neighbors</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#k-nn">k-NNの説明</a></li>
                
            
                <li class="toctree-l3"><a href="#k-nn_1">k-NNを手で計算してみよう</a></li>
                
            
                <li class="toctree-l3"><a href="#exercises">Exercises</a></li>
                
                    <li><a class="toctree-l4" href="#scikit-learn-style">Scikit-learn Style</a></li>
                
                    <li><a class="toctree-l4" href="#the-starter-code">The Starter Code</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-1">Exercise 1</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-2">Exercise 2</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-3">Exercise 3</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-4">Exercise 4</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-5">Exercise 5</a></li>
                
                    <li><a class="toctree-l4" href="#exercise-6">Exercise 6</a></li>
                
            
                <li class="toctree-l3"><a href="#iris-flower-dataset">Iris Flower Dataset</a></li>
                
            
            </ul>
        
    </li>

        
    </ul>

        
            
    <ul class="subnav">
    <li><span>Unit2</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../unit2/supervised_learning/">Supervised Learning</a>
        
    </li>

        
    </ul>

        
            
    <ul class="subnav">
    <li><span>Unit3</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../unit3/naive_bayes/">Naive Bayes</a>
        
    </li>

        
    </ul>

        
            
    <ul class="subnav">
    <li><span>Unit4</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../unit4/k-means/">K-Means Clustering</a>
        
    </li>

        
    </ul>

        
            
    <ul class="subnav">
    <li><span>Unit5</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../unit5/linear_regression/">Linear Regression</a>
        
    </li>

        
    </ul>

        
            
    <ul class="subnav">
    <li><span>Unit6</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../../unit6/logistic_regression/">Logistic Regression</a>
        
    </li>

        
    </ul>

        
    </ul>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../..">Machine Learning engineer Training Program</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../..">Docs</a> &raquo;</li>
    
      
        
          <li>Traditional Machine Learning &raquo;</li>
        
      
        
          <li>Unit1 &raquo;</li>
        
      
    
    <li>k-Nearest Neighbors</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/itandi/mltp" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>k-Nearest Neighbors(k-NN)は一番簡単に理解出来るSupervised Learningのモデルです。</p>
<h2 id="k-nn">k-NNの説明</h2>
<p>以下の図は、住所とその人が一人暮らしかどうかの関係を表しています。ルームシェアは一人暮らし以外と考えて下さい。住所は緯度と経度を使っています。東京の緯度と経度はこのデータと全然違いますが、このグラフが東京だと仮定してみましょう。</p>
<p><img alt="scatter" src="../../../img/unit1/scatter.png" /></p>
<p>南西には一人暮らしが多く、北東にはルームシェアが多いことが分かります。</p>
<p>ではこのデータを元に、緯度と経度からその人が一人暮らしかどうか予測したいとしましょう。k-NNがどうやって予測するかというと、その値の隣人(Neighbor)を見て予測します。エリアによって一人暮らしが多く住んでいたりルームシェアが多かったりするので、隣人を見て予測するのは悪くない方法です。</p>
<p>ちなみにk-NNには場所のデータだけでなくどんなデータでも使えます。実際一人暮らしかどうか予測するには間取りや賃料の方が役に立ちますよね。ただk-NNのコンセプトを理解するために住所が一番分かり易いため今回は住所を使っています。</p>
<p>更に、これはk-NNに限ったことではないのですが、Featureが２つでなければいけないわけでもありません。１つでも良いし１００個でも良いです。</p>
<p>k-NNは隣人を何人参考にするかパラメータを設定します。k-NNのkがそのパラメータのことです。なのでk=1であれば最も近い人を参考に、k=3であれば最も近い３人を見て多い方を採用します。</p>
<h2 id="k-nn_1">k-NNを手で計算してみよう</h2>
<p>上記の例を使ってk-NNを手で計算します。これが出来ればコードを書くのは簡単です。今まで「隣人」や「近い」という単語をカジュアルに使っていましたが、近似値は<em>Manhattan Distance</em>か<em>Euclidean Distance</em>を使います。Manhattan Distanceはそれぞれの軸（この場合xとy）の差異の絶対値を足したもので、Euclidean Distanceは２点を直線で結んだ時の距離です。Manhattan Distanceの方が計算が楽なのでまずこれを使いましょう。</p>
<p>
<script type="math/tex; mode=display"> d(p, q) = \displaystyle\sum_{i=1}^{n} |p_i - q_i| </script>
</p>
<p>では中心に一番近い赤の点(-1, -1)と右のTest sample(1, 0)の距離を計算してみましょう。</p>
<p>
<script type="math/tex; mode=display"> |-1 - 1| + |-1 - 0| = 2 + 1 = 3 </script>
</p>
<p>このようにそれぞれのTest sample毎に全Training sampleとの距離を計算します。その後それを距離が近い順に並べ、kの分だけ取り、その中で多いクラスを採用します。</p>
<p>Test sample(1, 0)のケースで言うと、k=3の場合(1, 1), (2, 2), (-1, -1)が最も近い３つです。その中でルームシェアが２つなので、ルームシェアと予測します。タイを避ける為kには奇数を使います。</p>
<h1 id="exercises">Exercises</h1>
<p>コードはここにあります。
<a href="https://github.com/itandi/mltp">https://github.com/itandi/mltp</a></p>
<h2 id="scikit-learn-style">Scikit-learn Style</h2>
<p>Exerciseではk-NNをnumpyで書いてもらいますが、APIは<a href="http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">scikit-learn</a>と同じにしています。scikit-learnはどのモデルでもAPIが同じなので非常に使いやすいです。以下の簡単な例を見てみましょう。</p>
<pre><code class="python">import numpy as np
from sklearn.neighbors import KNeighborsClassifier

## Inputは2d array(N, number of features)
x_train = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
## Targetは1d array(N, )
y_train = np.array([1,1,1,0,0,0])

## モデルのinitialization.
neighbor = KNeighborsClassifier()
## fitでモデルの学習
neighbor.fit(x_train, y_train)

## predictは複数のデータを取るので2d arrayを渡す
x_test = np.array([[1, 0], [-2, -2]])
print(neighbor.predict(x_test))
</code></pre>

<p>scikit-learnではMLのモデルを<em>Estimator</em>と呼んでいて、Estimatorはクラスになっています。まずEstimatorをinitializeし、<code>fit</code>でモデルの学習をします。予測したい時は<code>predict</code>を呼びます。</p>
<h2 id="the-starter-code">The Starter Code</h2>
<p>以下がStarter codeです。k-NNは他のモデルと違い<code>fit</code>では何もせず単に<code>x</code>と<code>y</code>を保存するだけです。<code>_predict_one</code>で1 sample毎に処理をします。今は毎回1をreturnしています。</p>
<pre><code class="python">import numpy as np

class MyKNeighborsClassifier(object):
    def __init__(self, n_neighbors=5):
        self.n_neighbors = n_neighbors

    def fit(self, x, y):
        self.x = x
        self.y = y
        return self

    def _predict_one(self, test):
        return 1

    def predict(self, x):
        return [self._predict_one(i) for i in x]

x = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
y = np.array([1,1,1,0,0,0])
neighbor = MyKNeighborsClassifier()
neighbor.fit(x, y)
print(neighbor.predict(np.array([[1, 0], [-2, -2]])))
</code></pre>

<p>Exerciseの答えは次のExerciseに書いてあります。</p>
<h2 id="exercise-1">Exercise 1</h2>
<p>最初に距離を測るメソッド<code>_distance</code>を書きましょう。Manhattan Distanceを使います。</p>
<h2 id="exercise-2">Exercise 2</h2>
<p>distanceを計算したら小さい順にソートし、<code>self.n_neighbors</code>の数だけ取ります。
その後<code>_compute_weights</code>でweightを計算します。weightは上では説明しませんでしたが、各データの重要度のようなものです。まずは<em>uniform weights</em>を計算します。これは上でやったのと同じ方法で、全データ同じ比重を持つという意味です。つまりdistanceに関わらず1をreturnすれば全データ同じ比重になります。例えば <code>top_k_distances</code>が<code>[1, 2, 3, -4]</code>だったら<code>[1,1,1,1]</code>をreturnします。</p>
<pre><code class="python">def _predict_one(self, test):
    distances = np.array([self._distance(x, test) for x in self.x])
    top_k = np.argsort(distances)[:self.n_neighbors]
    top_k_ys = self.y[top_k]
    top_k_distances = distances[top_k]
    top_k_weights = self._compute_weights(top_k_distances)
</code></pre>

<h2 id="exercise-3">Exercise 3</h2>
<p>このExerciseで基本的なアルゴリズムはもう完成します！先ほど計算した<code>top_k_weights</code>を元に、weightが一番大きいクラスをreturnしましょう。</p>
<h2 id="exercise-4">Exercise 4</h2>
<p>今のアルゴリズムだと単純にトップKの大多数を取りますが、以下の場合はどうでしょう？</p>
<pre><code class="python">X = np.array([[1, 1], [4, 4], [5, 5]])
y = np.array([1,0,0])
neighbor = MyKNeighborsClassifier(n_neighbors=3).fit(X, y)
print(neighbor._predict_one(np.array([0, 0])))
</code></pre>

<p><img alt="scatter2" src="../../../img/unit1/scatter2.png" /></p>
<p>一番近いのは赤ですが、青が２つあるためそっちを採用してしまいます。数だけでなく距離も考慮に入れられたら良いですよね。</p>
<p>その為には距離のinverse(1/d)を使います。</p>
<p><code>__init__</code>に<code>weights</code>が追加されています。</p>
<pre><code class="python">def __init__(self, n_neighbors=5, weights='uniform'):
    self.n_neighbors = n_neighbors
    self.weights = weights
</code></pre>

<p><code>_compute_weights</code>を完成させて下さい。</p>
<h2 id="exercise-5">Exercise 5</h2>
<p>次にEuclidean Distanceを書きましょう。数式は以下の通りです。</p>
<p>
<script type="math/tex; mode=display"> d(p, q) = \sqrt{\displaystyle\sum_{i=1}^{n} (p_i - q_i)^2} </script>
</p>
<p><code>__init__</code>には<code>p</code>が追加されています。scikit-learnと同じくデフォルトはEuclidean Distanceです。</p>
<pre><code class="python">def __init__(self, n_neighbors=5, weights='uniform', p=2):
    self.n_neighbors = n_neighbors
    self.weights = weights
    self.p = p
</code></pre>

<p><code>_distance</code>を完成させて下さい。</p>
<h2 id="exercise-6">Exercise 6</h2>
<p>最後に<code>score</code>メソッドを書きます。<code>score</code> はk-NNに関わらずどのEstimatorにもあり、classifierの場合はmean accuracy（精度）をreturnします。</p>
<h1 id="iris-flower-dataset">Iris Flower Dataset</h1>
<p>scikit-learnには幾つかの有名なData setが入っています。<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris flower data set</a>は３つの花の種類を４つの特徴から成り立っています。<code>model_selection</code>モジュールに入ってる<code>train_test_split</code>でtraining dataとtest dataを6:4に分けます。</p>
<pre><code class="python">from sklearn import datasets
from sklearn.model_selection import train_test_split
from s8_final import MyKNeighborsClassifier

iris = datasets.load_iris()

x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=.4)
neighbor = MyKNeighborsClassifier(n_neighbors=5, weights='uniform', p=2)
neighbor.fit(x_train, y_train)
print(neighbor.score(x_train, y_train))
print(neighbor.score(x_test, y_test))
</code></pre>

<p>Iris flowerはかなりクリーンなデータなのでデフォルトでも高い精度が簡単に出ます。<code>n_neighbors</code>,<code>weights</code>,<code>p</code>をいじって変化を見てみましょう。</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../../unit2/supervised_learning/" class="btn btn-neutral float-right" title="Supervised Learning">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../introduction/" class="btn btn-neutral" title="Introduction"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/itandi/mltp" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../introduction/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../../unit2/supervised_learning/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
